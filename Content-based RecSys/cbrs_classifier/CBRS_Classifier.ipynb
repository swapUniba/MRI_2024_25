{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Let's silence the warnings\n",
        "\n"
      ],
      "metadata": {
        "id": "Cxh4rbT7FxqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "TZu1uBe32c_X"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "AdwJBtfHA6ee"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PwKJtklVmcyT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download data"
      ],
      "metadata": {
        "id": "wl1g-XtbAz0y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download of data\n",
        "\n",
        "We download two CSV files:\n",
        "\n",
        "1. **`ratings.csv`**: A CSV file likely containing user ratings or evaluations for items, potentially for use in a recommendation or classification system.\n",
        "2. **`metadata.csv`**: A CSV file probably containing metadata related to the items or users in the `ratings.csv`.\n",
        "\n",
        "The `-O` option in `curl` ensures the files are saved with their original filenames in the current working directory.\n",
        "\n"
      ],
      "metadata": {
        "id": "5RpXiPTKGM-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://raw.githubusercontent.com/giuspillo/MRI-24-25_CBRS/refs/heads/main/cbrs_classifier/data/ratings.csv\n",
        "!curl -O https://raw.githubusercontent.com/giuspillo/MRI-24-25_CBRS/refs/heads/main/cbrs_classifier/data/metadata.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83Seqw3cA1bV",
        "outputId": "24c2ac88-3fae-457a-d514-c56d34a8c824"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 20.5M  100 20.5M    0     0  12.4M      0  0:00:01  0:00:01 --:--:-- 12.4M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2135k  100 2135k    0     0  1709k      0  0:00:01  0:00:01 --:--:-- 1709k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data related to ratings and metadata"
      ],
      "metadata": {
        "id": "dRwcQmGjA-g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data as Pandas\n",
        "\n",
        "This cell loads the two CSV files downloaded earlier into pandas DataFrames:\n",
        "\n",
        "1. **`ratings`**: This DataFrame loads the `ratings.csv` file, which contains user-item ratings \\(from 1 ro 5\\).\n",
        "2. **`metadata`**: This DataFrame loads the `metadata.csv` file, which holds additional information about the items or users referenced in the `ratings` file.\n"
      ],
      "metadata": {
        "id": "H0fEbqA4GZCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data we are interest in\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "metadata = pd.read_csv('metadata.csv')"
      ],
      "metadata": {
        "id": "n5ZW_TfCmi-d"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the ratings are formatted and which information it contains"
      ],
      "metadata": {
        "id": "EIXjpVHHGpcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'In total we have {len(ratings)} ratings')\n",
        "ratings.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "MO5UzWiLmvP0",
        "outputId": "e22b89c4-92cd-44de-cb5b-691b7ac9c581"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In total we have 998034 ratings\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  movie_id  rating  timestamp\n",
              "0        1      1193       5  978300760\n",
              "1        1       661       3  978302109\n",
              "2        1       914       3  978301968\n",
              "3        1      3408       4  978300275\n",
              "4        1      2355       5  978824291"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c85d780-be9d-465b-a2c1-49628195eb26\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>movie_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c85d780-be9d-465b-a2c1-49628195eb26')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c85d780-be9d-465b-a2c1-49628195eb26 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c85d780-be9d-465b-a2c1-49628195eb26');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e60609b1-8908-403b-8ea1-4ed49c14a430\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e60609b1-8908-403b-8ea1-4ed49c14a430')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e60609b1-8908-403b-8ea1-4ed49c14a430 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ratings"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell identifies the user with the highest number of interactions in the `ratings` dataset:\n",
        "\n",
        "1. **`interaction_counts`**: Calculates the number of interactions per user by counting the occurrences of each unique `user_id` in the `ratings` DataFrame using the `value_counts()` method.\n",
        "\n",
        "2. **`most_active_user`**: Identifies the user ID with the maximum number of interactions using the `idxmax()` function, which returns the index of the highest value.\n",
        "\n",
        "3. **`max_interactions`**: Retrieves the maximum number of interactions for the most active user using the `max()` function.\n",
        "\n"
      ],
      "metadata": {
        "id": "_F2HV1NOG3Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's find the user with the highest number of interactions - just for fun\n",
        "interaction_counts = ratings['user_id'].value_counts()\n",
        "most_active_user = interaction_counts.idxmax()\n",
        "max_interactions = interaction_counts.max()\n",
        "print(f\"The most active user is {most_active_user} with {max_interactions} interactions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iQmakSp3h4T",
        "outputId": "a09f6ea4-dddb-4eff-8b04-dc64e0a2c36e"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most active user is 4169 with 2306 interactions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of the Code\n",
        "\n",
        "This cell explores the distribution of user interactions in the `ratings` dataset by focusing on users with a specific range of interactions:\n",
        "\n",
        "1. **Filter Users by Interaction Count**:\n",
        "   - **`bet_int_users`**: Filters the `interaction_counts` DataFrame to include only users with more than 100 and fewer than 300 interactions using a conditional statement.\n",
        "   - The result is reset with `reset_index()` to create a new DataFrame for easier handling.\n",
        "\n",
        "2. **Count Users in Range**:\n",
        "   - The number of users in the specified range is determined using `len(bet_int_users)`.\n",
        "   - This count is printed to indicate how many users fall within the range of 100â€“300 interactions.\n",
        "\n",
        "3. **Retrieve Specific User Details**:\n",
        "   - Selects the first user from the filtered list and prints their ID.\n",
        "   - Retrieves and prints their exact interaction count from the filtered DataFrame.\n"
      ],
      "metadata": {
        "id": "qa9uUf6RHNIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Other curiosity: how many users have a number of interactions between 100 and 300?\n",
        "bet_int_users = interaction_counts[(interaction_counts > 100) & (interaction_counts < 300)].reset_index()\n",
        "print(f\"There are {len(bet_int_users)} users with interactions between 100 and 300\")\n",
        "\n",
        "user_id = list(bet_int_users['user_id'])[0]\n",
        "print(f\"The first one of them is user {user_id} with {bet_int_users[bet_int_users['user_id'] == user_id]['count'].values[0]} interactions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doiarNP972Bc",
        "outputId": "361bea93-9fd6-45af-fad5-43a9cc2082c3"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1948 users with interactions between 100 and 300\n",
            "The first one of them is user 4593 with 299 interactions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's see which information is encoded in the metadata file"
      ],
      "metadata": {
        "id": "lUag0llxHZ5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"In total we have {len(metadata)} movies\")\n",
        "metadata.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "OM8yjouAmw7E",
        "outputId": "891f3231-54ba-4094-c230-5a749e685d4e"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In total we have 3859 movies\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movie_id                                name                        genres  \\\n",
              "0         1                    Toy Story (1995)   Animation|Children's|Comedy   \n",
              "1         2                      Jumanji (1995)  Adventure|Children's|Fantasy   \n",
              "2         3             Grumpier Old Men (1995)                Comedy|Romance   \n",
              "3         4            Waiting to Exhale (1995)                  Comedy|Drama   \n",
              "4         5  Father of the Bride Part II (1995)                        Comedy   \n",
              "\n",
              "                                            overview  \n",
              "0  A little boy named Andy loves to be in his roo...  \n",
              "1  After being trapped in a jungle board game for...  \n",
              "2  Things don't seem to change much in Wabasha Co...  \n",
              "3  This story based on the best selling novel by ...  \n",
              "4  In this sequel to \"Father of the Bride\"  Georg...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-69882b22-5430-4309-bed6-33758bc9f31c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>name</th>\n",
              "      <th>genres</th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "      <td>A little boy named Andy loves to be in his roo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children's|Fantasy</td>\n",
              "      <td>After being trapped in a jungle board game for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "      <td>Things don't seem to change much in Wabasha Co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "      <td>This story based on the best selling novel by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>In this sequel to \"Father of the Bride\"  Georg...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69882b22-5430-4309-bed6-33758bc9f31c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-69882b22-5430-4309-bed6-33758bc9f31c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-69882b22-5430-4309-bed6-33758bc9f31c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc495036-05b0-4af7-a0bd-b174836bafbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc495036-05b0-4af7-a0bd-b174836bafbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc495036-05b0-4af7-a0bd-b174836bafbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata",
              "summary": "{\n  \"name\": \"metadata\",\n  \"rows\": 3859,\n  \"fields\": [\n    {\n      \"column\": \"movie_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1147,\n        \"min\": 1,\n        \"max\": 3952,\n        \"num_unique_values\": 3859,\n        \"samples\": [\n          1931,\n          1283,\n          2748\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3859,\n        \"samples\": [\n          \"Mutiny on the Bounty (1935)\",\n          \"High Noon (1952)\",\n          \"Allan Quartermain and the Lost City of Gold (1987)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genres\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 300,\n        \"samples\": [\n          \"Horror|Mystery|Thriller\",\n          \"Action|Comedy|Sci-Fi|Thriller\",\n          \"Children's|Comedy|Western\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3825,\n        \"samples\": [\n          \"In the small English village of Midwich everybody and everything falls into a deep  mysterious sleep for several hours in the middle of the day. Some months later every woman capable of child bearing is pregnant and the children that are born out of these pregnancies seem to grow very fast and they all have the same blond hair and strange  penetrating eyes that make people do things they don't want to do. \",\n          \"Mike is released from psychiatry  when he agrees with the doctors that the terrible happenings in his past were just in his imagination. But once he's free  he contacts Redge and they team up to hunt down and eliminate the \\\"Tall Man\\\"  who plunders the graveyards and steals the corpses with help of his terrible dwarfs. A beautiful strange girl starts to appear in Mike's dreams. He assumes she's in danger and needs their help   will they find her before the Tall Man can do her any harm  \",\n          \"It's the early twentieth century Sweden. Adolescent siblings Alexander and Fanny Ekdahl lead a relatively joyous and exuberant life with their well off extended paternal family  led by the family matriarch  their grandmother  Helena Ekdahl. The openness of the family culture is exemplified by Helena's now deceased husband ending up becoming best friends with one of her lovers  a Jewish puppet maker named Isak Jacobi  and their Uncle Gustav Adolf's open liaison with one of the family maids  Maj  who everyone in the family adores  even Gustav Adolf's wife  Alma. Between the siblings  Alexander in particular has inherited the family's love of storytelling  his parents and his grandmother who are actors and who manage their own theater. Things change for Alexander and Fanny when their father  Oscar  dies shortly after Christmas 1907. Although she truly does believe she loves him  the children's mother  Emilie  decides to marry Bishop Edvard Verg  rus  who she first met as the officiate at Oscar's funeral. She also wants a father figure for the children. Going into the marriage  Emilie has inclinations that it will be a much different life than she had with the Ekdahls  but is not prepared for the harsh  austere and strict life Edvard rules with an iron fist. Emilie  Alexander and Fanny end up being prisoners in the bishop's stark and humorless house. As Alexander butts head with his stepfather and tries to learn how to keep to his own principles while obeying Edvard  Emilie tries to figure out a way to regain her and her children's own destiny  as Edvard will not consent to divorce  and her \\\"desertion\\\" in the eyes of the law means that Alexander and Fanny would become his wards. \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binarize the ratings\n",
        "\n",
        "- 1, 2 ,3 ratings become 0s (dislike)\n",
        "- 4, 5 ratings become 1s (like)"
      ],
      "metadata": {
        "id": "385Ham2QHfU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new column with 1 or 0 based on the rating\n",
        "ratings['bin_rat'] = (ratings['rating'] >= 4).astype(int)"
      ],
      "metadata": {
        "id": "I8Hs6DYamy6N"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's count how many 0s and 1s we have"
      ],
      "metadata": {
        "id": "UCp7rkmwH5J9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show how many 1s and 0s the dataset now has\n",
        "ratings['bin_rat'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "4czza5LcnPzN",
        "outputId": "175344f2-546c-4725-c73e-c57f68c6c21b"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bin_rat\n",
              "1    573759\n",
              "0    424275\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bin_rat</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>573759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>424275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fuse ratings and metadata\n",
        "\n",
        "We merge the `metadata` and `ratings` DataFrames and analyze the preferences (likes and dislikes) of a specific user (identified earlier as `user_id`):\n",
        "\n",
        "1. **Merging the DataFrames**:\n",
        "   - **`df`**: The `metadata` DataFrame (which contains movie details) is merged with the `ratings` DataFrame (which contains user ratings) on the common `movie_id` column. The merged DataFrame is then sorted by `user_id` in ascending order for easier analysis.\n",
        "\n",
        "2. **Identifying Likes and Dislikes**:\n",
        "   - **`user_like`**: Filters the merged DataFrame to extract the movie names (`'name'`) where the specified user (with ID `user_id`) has given a positive rating (`'bin_rat' == 1`), indicating a like.\n",
        "   - **`user_dislike`**: Similarly, filters for the movie names where the user has given a negative rating (`'bin_rat' == 0`), indicating a dislike.\n",
        "\n",
        "3. **Displaying the Results**:\n",
        "   - The first 5 liked movies are displayed as a pandas Series using the `display()` function.\n",
        "   - A complete list of the liked movies is printed.\n",
        "   - The first 5 disliked movies are displayed similarly, and a list of all disliked movies is printed.\n"
      ],
      "metadata": {
        "id": "oGxhRxuFIBtz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge movies and ratings pandas and show user 0 like and dislikes\n",
        "df = pd.merge(metadata, ratings, on='movie_id').sort_values(by=['user_id'], ascending=True)\n",
        "\n",
        "# get a list of the titles of user 1 likes and a list of user 1 dislikes\n",
        "user_like = df[(df['user_id'] == user_id) & (df['bin_rat'] == 1)]['name']\n",
        "user_dislike = df[(df['user_id'] == user_id) & (df['bin_rat'] == 0)]['name']\n",
        "\n",
        "# display the first likes as pandas...\n",
        "display((user_like.head(5)))\n",
        "# ... or list\n",
        "print(f'user {user_id} likes the following {len(user_like.to_list())} movies: {user_like.tolist()}')\n",
        "\n",
        "# display the first DISlikes as pandas...\n",
        "display((user_dislike.head(5)))\n",
        "# ... or list\n",
        "print(f'user {user_id} doesn\\'t like the following {len(user_dislike.to_list())} movies: {user_dislike.tolist()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "RXTucSFWnQs8",
        "outputId": "e478d11b-dfa1-43c9-933f-0f7115a5e6ad"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "84365     Santa Clause, The (1994)\n",
              "394883        Crucible, The (1996)\n",
              "404917               Grease (1978)\n",
              "563489       Doctor Zhivago (1965)\n",
              "916253      Odd Couple, The (1968)\n",
              "Name: name, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84365</th>\n",
              "      <td>Santa Clause, The (1994)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394883</th>\n",
              "      <td>Crucible, The (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404917</th>\n",
              "      <td>Grease (1978)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563489</th>\n",
              "      <td>Doctor Zhivago (1965)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>916253</th>\n",
              "      <td>Odd Couple, The (1968)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user 4593 likes the following 134 movies: ['Santa Clause, The (1994)', 'Crucible, The (1996)', 'Grease (1978)', 'Doctor Zhivago (1965)', 'Odd Couple, The (1968)', 'Babe: Pig in the City (1998)', 'Being John Malkovich (1999)', 'Dancing at Lughnasa (1998)', 'Koyaanisqatsi (1983)', 'Lovers of the Arctic Circle, The (Los Amantes del CÃ­rculo Polar) (1998)', 'Golden Bowl, The (2000)', 'As Good As It Gets (1997)', 'Castle, The (1997)', 'Restoration (1995)', 'Bowfinger (1999)', 'Night on Earth (1991)', 'Best in Show (2000)', 'Central Station (Central do Brasil) (1998)', 'All About My Mother (Todo Sobre Mi Madre) (1999)', 'Piano, The (1993)', 'Dead Man Walking (1995)', 'Sunshine (1999)', 'Remains of the Day, The (1993)', 'Analyze This (1999)', 'Four Weddings and a Funeral (1994)', 'Crying Game, The (1992)', 'Dog Day Afternoon (1975)', 'Maya Lin: A Strong Clear Vision (1994)', 'Hilary and Jackie (1998)', 'Babe (1995)', 'Gladiator (2000)', 'Three Colors: Red (1994)', 'Chariots of Fire (1981)', 'Patriot, The (2000)', 'Waking Ned Devine (1998)', 'Eyes of Tammy Faye, The (2000)', \"Schindler's List (1993)\", 'Grapes of Wrath, The (1940)', 'Annie Hall (1977)', 'Full Monty, The (1997)', 'Maurice (1987)', 'Affair of Love, An (Une Liaison Pornographique) (1999)', 'Girl, Interrupted (1999)', \"What's Eating Gilbert Grape (1993)\", 'Snow Falling on Cedars (1999)', 'Waiting for Guffman (1996)', 'Election (1999)', 'Nurse Betty (2000)', 'Butterfly (La Lengua de las Mariposas) (2000)', 'Kolya (1996)', 'Roger & Me (1989)', 'Shakespeare in Love (1998)', 'Madness of King George, The (1994)', \"Sophie's Choice (1982)\", 'Silence of the Lambs, The (1991)', 'Once Upon a Time... When We Were Colored (1995)', 'Sweet and Lowdown (1999)', 'Howards End (1992)', \"Ulee's Gold (1997)\", 'Talented Mr. Ripley, The (1999)', 'Places in the Heart (1984)', 'Anatomy of a Murder (1959)', 'English Patient, The (1996)', 'High Fidelity (2000)', 'Glory (1989)', \"Boys Don't Cry (1999)\", 'Manhattan (1979)', 'Searching for Bobby Fischer (1993)', 'Hamlet (2000)', 'Ideal Husband, An (1999)', 'Wings of the Dove, The (1997)', 'Straight Story, The (1999)', 'Contender, The (2000)', 'Mrs. Dalloway (1997)', 'Matewan (1987)', 'Fish Called Wanda, A (1988)', 'Braveheart (1995)', 'Cinema Paradiso (1988)', 'Kundun (1997)', \"Miller's Crossing (1990)\", 'Don Juan DeMarco (1995)', 'Music of the Heart (1999)', 'Shawshank Redemption, The (1994)', \"Antonia's Line (Antonia) (1995)\", 'Wilde (1997)', 'East-West (Est-ouest) (1999)', 'Last Picture Show, The (1971)', 'Fargo (1996)', 'Fanny and Alexander (1982)', 'Trip to Bountiful, The (1985)', 'Topsy-Turvy (1999)', 'Mulan (1998)', 'Big Kahuna, The (2000)', 'Manon of the Spring (Manon des sources) (1986)', 'Graduate, The (1967)', 'Sense and Sensibility (1995)', 'Oscar and Lucinda (a.k.a. Oscar & Lucinda) (1997)', 'Emma (1996)', 'American Beauty (1999)', 'Deer Hunter, The (1978)', 'My Life as a Dog (Mitt liv som hund) (1985)', 'Meet the Parents (2000)', 'Being There (1979)', 'Little Women (1994)', 'Almost Famous (2000)', 'Color of Paradise, The (Rang-e Khoda) (1999)', 'Spitfire Grill, The (1996)', 'Breaker Morant (1980)', 'Tender Mercies (1983)', 'Price Above Rubies, A (1998)', 'Paris, Texas (1984)', 'Saving Private Ryan (1998)', 'Return of the Pink Panther, The (1974)', 'Mansfield Park (1999)', 'Reds (1981)', 'And the Band Played On (1993)', 'Unbearable Lightness of Being, The (1988)', 'Sixth Sense, The (1999)', 'When Harry Met Sally... (1989)', 'Aladdin (1992)', 'Groundhog Day (1993)', 'Elizabeth (1998)', 'Crimes and Misdemeanors (1989)', 'Gandhi (1982)', 'Nelly & Monsieur Arnaud (1995)', 'Celebration, The (Festen) (1998)', 'Girl on the Bridge, The (La Fille sur le Pont) (1999)', 'Bananas (1971)', 'Thin Blue Line, The (1988)', 'History of the World: Part I (1981)', 'Winslow Boy, The (1998)', 'Room with a View, A (1986)', 'Usual Suspects, The (1995)', 'Benny & Joon (1993)']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "924827      East is East (1999)\n",
              "418056             Evita (1996)\n",
              "164984            Batman (1989)\n",
              "742997              Dick (1999)\n",
              "135949    Mrs. Doubtfire (1993)\n",
              "Name: name, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>924827</th>\n",
              "      <td>East is East (1999)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418056</th>\n",
              "      <td>Evita (1996)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164984</th>\n",
              "      <td>Batman (1989)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742997</th>\n",
              "      <td>Dick (1999)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135949</th>\n",
              "      <td>Mrs. Doubtfire (1993)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user 4593 doesn't like the following 165 movies: ['East is East (1999)', 'Evita (1996)', 'Batman (1989)', 'Dick (1999)', 'Mrs. Doubtfire (1993)', 'Truman Show, The (1998)', 'Wonder Boys (2000)', 'Back to the Future (1985)', 'Private Benjamin (1980)', 'Bodyguard, The (1992)', 'Airplane! (1980)', 'Frequency (2000)', 'Peggy Sue Got Married (1986)', 'Immortal Beloved (1994)', 'Nine Months (1995)', 'Working Girl (1988)', 'Fabulous Baker Boys, The (1989)', 'Space Cowboys (2000)', 'Erin Brockovich (2000)', 'Manhattan Murder Mystery (1993)', 'Gods and Monsters (1998)', 'Hideous Kinky (1998)', 'Chicken Run (2000)', 'Little Big Man (1970)', 'Good Will Hunting (1997)', 'Insider, The (1999)', 'Honey, I Shrunk the Kids (1989)', 'Horse Whisperer, The (1998)', 'Your Friends and Neighbors (1998)', 'What Dreams May Come (1998)', 'Ed Wood (1994)', 'Back to the Future Part II (1989)', 'Mass Appeal (1984)', 'Orlando (1993)', 'Notting Hill (1999)', 'Breaking Away (1979)', 'Blues Brothers, The (1980)', 'Driving Miss Daisy (1989)', 'Jackie Brown (1997)', 'Michael (1996)', 'Celebrity (1998)', 'Simon Birch (1998)', 'Buffalo 66 (1998)', 'Heathers (1989)', 'End of the Affair, The (1999)', 'Crimes of the Heart (1986)', 'Lock, Stock & Two Smoking Barrels (1998)', 'Dogma (1999)', 'Thelma & Louise (1991)', 'Prince of Tides, The (1991)', 'Sex, Lies, and Videotape (1989)', 'Metroland (1997)', 'October Sky (1999)', 'Desperately Seeking Susan (1985)', 'Michael Collins (1996)', 'Ghosts of Mississippi (1996)', 'Jakob the Liar (1999)', 'Far and Away (1992)', 'G.I. Jane (1997)', 'Pleasantville (1998)', 'Secret Garden, The (1993)', 'Ghost Dog: The Way of the Samurai (1999)', 'Fried Green Tomatoes (1991)', 'Mr. Mom (1983)', 'Sister Act (1992)', 'Ghost (1990)', 'Shampoo (1975)', 'Outbreak (1995)', 'Victor/Victoria (1982)', 'Even Cowgirls Get the Blues (1993)', 'Messenger: The Story of Joan of Arc, The (1999)', 'Elephant Man, The (1980)', 'Purple Rose of Cairo, The (1985)', 'Arthur (1981)', 'How Stella Got Her Groove Back (1998)', 'Down Periscope (1996)', 'Perfect Storm, The (2000)', 'Bull Durham (1988)', 'Tao of Steve, The (2000)', 'Welcome to the Dollhouse (1995)', 'Jean de Florette (1986)', 'Raiders of the Lost Ark (1981)', 'Romeo and Juliet (1968)', 'Mission: Impossible 2 (2000)', 'This Is Spinal Tap (1984)', 'Death Becomes Her (1992)', 'Next Stop, Wonderland (1998)', 'Hoosiers (1986)', 'Dances with Wolves (1990)', \"Jesus' Son (1999)\", 'Edward Scissorhands (1990)', 'Kramer Vs. Kramer (1979)', 'Parent Trap, The (1998)', 'Last Temptation of Christ, The (1988)', 'Cold Comfort Farm (1995)', 'Cocoon (1985)', 'Clueless (1995)', 'Sommersby (1993)', 'Stripes (1981)', 'River Runs Through It, A (1992)', 'My Favorite Martian (1999)', \"My Best Friend's Wedding (1997)\", 'Tom & Viv (1994)', 'Sleepy Hollow (1999)', 'One True Thing (1998)', 'Hope Floats (1998)', 'Other Sister, The (1999)', 'Tea with Mussolini (1999)', 'Back to the Future Part III (1990)', 'Mickey Blue Eyes (1999)', 'On Golden Pond (1981)', 'Close Encounters of the Third Kind (1977)', 'Women on the Verge of a Nervous Breakdown (1988)', 'Dead Poets Society (1989)', 'Pulp Fiction (1994)', \"Guess Who's Coming to Dinner (1967)\", 'Dumb & Dumber (1994)', 'Joy Luck Club, The (1993)', 'Hairspray (1988)', \"Prizzi's Honor (1985)\", 'Pretty in Pink (1986)', 'Bullets Over Broadway (1994)', 'Stuart Little (1999)', 'Gods Must Be Crazy, The (1980)', \"Butcher's Wife, The (1991)\", 'Living Out Loud (1998)', 'Amadeus (1984)', 'Ordinary People (1980)', 'Walk on the Moon, A (1999)', 'Home Alone (1990)', 'Father of the Bride Part II (1995)', 'Great Expectations (1998)', 'Radio Days (1987)', 'Pretty Woman (1990)', 'Blue Velvet (1986)', 'Forget Paris (1995)', 'Primary Colors (1998)', 'Titanic (1997)', 'Awakenings (1990)', 'Dolores Claiborne (1994)', 'Right Stuff, The (1983)', 'Raising Arizona (1987)', 'Thousand Acres, A (1997)', 'Scent of a Woman (1992)', 'Shine (1996)', 'Atlantic City (1980)', 'Opposite of Sex, The (1998)', 'Like Water for Chocolate (Como agua para chocolate) (1992)', 'Blair Witch Project, The (1999)', 'Inspector Gadget (1999)', 'Waiting to Exhale (1995)', 'Get Shorty (1995)', '2001: A Space Odyssey (1968)', 'Fantasia 2000 (1999)', 'Princess Bride, The (1987)', 'Virgin Suicides, The (1999)', 'Waterworld (1995)', 'Civil Action, A (1998)', 'Midnight in the Garden of Good and Evil (1997)', 'Stepmom (1998)', \"You've Got Mail (1998)\", 'Thin Red Line, The (1998)', 'Anna and the King (1999)', 'E.T. the Extra-Terrestrial (1982)', 'Grumpy Old Men (1993)']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just a curiosity: how many people liked and disliked star wars?"
      ],
      "metadata": {
        "id": "YTKMyG5gIPaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "like_sw = df[(df['name'] == 'Star Wars: Episode IV - A New Hope (1977)') & (df['bin_rat'] == 1)].shape[0]\n",
        "dislike_sw = df[(df['name'] == 'Star Wars: Episode IV - A New Hope (1977)') & (df['bin_rat'] == 0)].shape[0]\n",
        "\n",
        "print(f\"{like_sw} users liked Star Wars while {dislike_sw} users didn't like it\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoMxhbMLnuRb",
        "outputId": "8163f5c3-1955-4ead-e106-61b8874fd837"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2622 users liked Star Wars while 369 users didn't like it\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check some descriptions - we use Star Wars (pefforza)"
      ],
      "metadata": {
        "id": "ou7CvldCIRbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first we find the id of star wars\n",
        "metadata[metadata['name'] == 'Star Wars: Episode IV - A New Hope (1977)']['overview']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "GrloYqXOOKCv",
        "outputId": "ccbefebe-ed4e-4a1c-d24b-688c17205097"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "257    The Imperial Forces  under orders from cruel D...\n",
              "Name: overview, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>The Imperial Forces  under orders from cruel D...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's get the value of this df\n",
        "overview = metadata[metadata['name'] == 'Star Wars: Episode IV - A New Hope (1977)']['overview'].values[0]"
      ],
      "metadata": {
        "id": "C_-Y2zwx3pKw"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We count the number of missing overview, and, to avoid problems in the computations, we replace NaN values with empty strings"
      ],
      "metadata": {
        "id": "zQER-7cUIWPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# how many overview are missing?\n",
        "print(metadata['overview'].isna().sum())\n",
        "\n",
        "# let's fix this by replacing these overview with a dummy string\n",
        "# (it can be the empty string, a blank, 'pippo', 'pluto', 'colui che egli')\n",
        "metadata['overview'] = metadata['overview'].fillna('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7ey8Z0236bO",
        "outputId": "adebc847-91a0-4640-97db-d43e4ae330a0"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning movie embeddings through TF-IDF\n",
        "\n",
        "This cell performs the process of representing each movie by an embedding using the TF-IDF (Term Frequency-Inverse Document Frequency) technique. The goal is to transform the textual data (in this case, the movie overviews) into numerical vectors that capture the importance of words across different movies.\n",
        "\n",
        "1. **Importing Required Libraries**:\n",
        "   - `TfidfVectorizer`: From `sklearn.feature_extraction.text`, it is used to convert a collection of text documents into a matrix of TF-IDF features.\n",
        "   - `nltk`: The Natural Language Toolkit (NLTK) is used to download a list of stopwords (common words like \"the\", \"is\", etc. that are typically removed from text analysis).\n",
        "   \n",
        "2. **Downloading Stopwords**:\n",
        "   - The list of English stopwords is downloaded using NLTKâ€™s `stopwords.words('english')`. These words will be ignored during the TF-IDF calculation.\n",
        "\n",
        "3. **Initializing the Vectorizer**:\n",
        "   - A `TfidfVectorizer` is initialized with the stop words set to the list from NLTK. It will ignore common English words that do not carry significant meaning in the context of text analysis.\n",
        "\n",
        "4. **Computing the TF-IDF Matrix**:\n",
        "   - **`tfidf_matrix`**: The `fit_transform()` function is applied to the `overview` column of the `metadata` DataFrame, which contains textual descriptions of each movie. This results in a sparse matrix representing the TF-IDF values for each term in each movie's overview.\n",
        "\n",
        "5. **Converting the Matrix to a DataFrame**:\n",
        "   - **`tfidf_features`**: The sparse matrix is converted into a dense format using `toarray()` and then into a pandas DataFrame for easier inspection. The DataFrame's rows represent movies (indexed by `movie_id`), and the columns represent the terms from the overviews.\n",
        "\n",
        "6. **Displaying the TF-IDF Features**:\n",
        "   - The shape of the TF-IDF matrix (number of movies and terms) is printed for an overview.\n",
        "   - The resulting `tfidf_features` DataFrame is displayed, showing the TF-IDF values for each movie and word in the overviews.\n"
      ],
      "metadata": {
        "id": "PAaYv-0tItvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we represent each movie as an embedding, by exploiting the genres we have stored in the movies.csv file, and we use the tf-idf technique\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords list\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(stopwords.words('english'))\n",
        "\n",
        "# init vectorizer\n",
        "# possible parameter: max_features=n. it considers only the top-n popular words\n",
        "# currently, we do not set it, try by yourself :)\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "\n",
        "# Compute TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform(metadata['overview'])\n",
        "print(tfidf_matrix.shape)\n",
        "\n",
        "# Convert the sparse matrix to a DataFrame for better visualization\n",
        "tfidf_features = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out(), index=metadata['movie_id'])\n",
        "\n",
        "print(\"Tf-idf Features:\")\n",
        "display(tfidf_features)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "0Vu6Pc7CrYfa",
        "outputId": "986558f6-6a63-4a27-f0db-a5b028ba5b53"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3859, 24526)\n",
            "Tf-idf Features:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           00  000  007  00h  00pm  05pm   10  100  1000  105  ...  zorin  \\\n",
              "movie_id                                                       ...          \n",
              "1         0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "2         0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "3         0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "4         0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "5         0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "...       ...  ...  ...  ...   ...   ...  ...  ...   ...  ...  ...    ...   \n",
              "3948      0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "3949      0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "3950      0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "3951      0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "3952      0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0   0.0  0.0  ...    0.0   \n",
              "\n",
              "          zorro  zquez  zucco  zuckerman  zuko  zulu  zundel  zuoqian  zyto  \n",
              "movie_id                                                                     \n",
              "1           0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "2           0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "3           0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "4           0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "5           0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "...         ...    ...    ...        ...   ...   ...     ...      ...   ...  \n",
              "3948        0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "3949        0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "3950        0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "3951        0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "3952        0.0    0.0    0.0        0.0   0.0   0.0     0.0      0.0   0.0  \n",
              "\n",
              "[3859 rows x 24526 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18d30a54-8453-4cf6-917c-d3d0a2f1b074\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>007</th>\n",
              "      <th>00h</th>\n",
              "      <th>00pm</th>\n",
              "      <th>05pm</th>\n",
              "      <th>10</th>\n",
              "      <th>100</th>\n",
              "      <th>1000</th>\n",
              "      <th>105</th>\n",
              "      <th>...</th>\n",
              "      <th>zorin</th>\n",
              "      <th>zorro</th>\n",
              "      <th>zquez</th>\n",
              "      <th>zucco</th>\n",
              "      <th>zuckerman</th>\n",
              "      <th>zuko</th>\n",
              "      <th>zulu</th>\n",
              "      <th>zundel</th>\n",
              "      <th>zuoqian</th>\n",
              "      <th>zyto</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movie_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3948</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3949</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3950</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3951</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3952</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3859 rows Ã— 24526 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18d30a54-8453-4cf6-917c-d3d0a2f1b074')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18d30a54-8453-4cf6-917c-d3d0a2f1b074 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18d30a54-8453-4cf6-917c-d3d0a2f1b074');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb8fd32f-860e-43c9-8033-93a79a0cb895\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb8fd32f-860e-43c9-8033-93a79a0cb895')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb8fd32f-860e-43c9-8033-93a79a0cb895 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_813e3d65-28ce-4469-9950-43b68215d469\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('tfidf_features')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_813e3d65-28ce-4469-9950-43b68215d469 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('tfidf_features');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tfidf_features"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of the Code\n",
        "\n",
        "This cell computes the similarity between movies using **cosine similarity**, a measure of similarity between two non-zero vectors that calculates the cosine of the angle between them. In this case, the vectors represent the TF-IDF embeddings of movie overviews.\n",
        "\n",
        "1. **Importing Cosine Similarity**:\n",
        "   - The `cosine_similarity` function from `sklearn.metrics.pairwise` is imported. This function will be used to compute the pairwise cosine similarity between all movies based on their TF-IDF embeddings.\n",
        "\n",
        "2. **Computing the Similarity Matrix**:\n",
        "   - **`similarity_matrix`**: The `cosine_similarity()` function is applied to the `tfidf_matrix` computed previously. This generates a square matrix where each element `(i, j)` represents the cosine similarity between the `i`-th and `j`-th movies.\n",
        "\n",
        "3. **Matrix Shape**:\n",
        "   - The shape of the `similarity_matrix` is printed to confirm the number of movies being compared. The matrix will be a square matrix with dimensions equal to the number of movies in the dataset.\n"
      ],
      "metadata": {
        "id": "DjfYCOl8JMR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just for fun, let's find the most similar movie to star wars\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# First, we need to compute the similarity matrix using cosine similarity\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "print(similarity_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csn43JSIvAHH",
        "outputId": "4c78f98f-4b8f-44af-a6e0-832c04b028f9"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3859, 3859)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Find similar movies to Star Wars Episode IV\n",
        "\n",
        "In order to find the most similar movies to \"Star Wars\" (represented by its movie ID), we compute the cosine similarity scores between it and all other movies.\n",
        "\n",
        "1. **Input: Movie ID of \"Star Wars\"**:\n",
        "   - **`item_id`**: The movie ID for \"Star Wars\" is set to 260. This is the movie for which we want to find the most similar movies.\n",
        "\n",
        "2. **Finding the Index of the Movie**:\n",
        "   - **`item_index`**: The index of the movie in the `tfidf_features` DataFrame is found using the `get_loc()` method, which retrieves the position of the movie ID in the DataFrame's index.\n",
        "\n",
        "3. **Computing Similarity Scores**:\n",
        "   - **`similarity_scores`**: The cosine similarity values for the selected movie (i.e., \"Star Wars\") are extracted from the `similarity_matrix`. The `similarity_matrix[item_index]` gives the similarity scores between \"Star Wars\" and all other movies.\n",
        "   - The scores are then enumerated into a list of tuples where each tuple contains the movie index and the corresponding similarity score.\n",
        "\n",
        "4. **Displaying Similarity Scores**:\n",
        "   - The unsorted list of movie-similarity score pairs is printed. This list includes the similarity scores between \"Star Wars\" and every other movie, which can be further processed to identify the most similar ones.\n"
      ],
      "metadata": {
        "id": "Iz2bxencJVwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: Movie ID of Star Wars to find similar movies\n",
        "item_id = 260\n",
        "\n",
        "# Find the corresponding index of the movie ID in tfidf_features\n",
        "item_index = tfidf_features.index.get_loc(item_id)\n",
        "\n",
        "# Compute similarity scores for the given movie\n",
        "# It will contain pairs in the format (id_matrix, sim_score)\n",
        "similarity_scores = list(enumerate(similarity_matrix[item_index]))\n",
        "print('Movie-similarity score pairs (not sorted)')\n",
        "print(similarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWkjmCivBCQK",
        "outputId": "42609aaa-f346-48a1-8c4f-ce93908864b2"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie-similarity score pairs (not sorted)\n",
            "[(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.005611259521416583), (6, 0.005438556469947753), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 0.0), (12, 0.0), (13, 0.0), (14, 0.020513331429116138), (15, 0.019995212297021628), (16, 0.0), (17, 0.01934702244621565), (18, 0.0), (19, 0.008713596376681952), (20, 0.0), (21, 0.0), (22, 0.0), (23, 0.0), (24, 0.0), (25, 0.0), (26, 0.013276764834495514), (27, 0.0), (28, 0.0), (29, 0.024059512435648148), (30, 0.0), (31, 0.0), (32, 0.0), (33, 0.0), (34, 0.0), (35, 0.0051105447999713486), (36, 0.006348626965806443), (37, 0.0), (38, 0.007639667146395728), (39, 0.0), (40, 0.021127327939290914), (41, 0.0), (42, 0.0), (43, 0.0), (44, 0.0), (45, 0.0), (46, 0.011680379906654527), (47, 0.0), (48, 0.004338957731692339), (49, 0.006763629390154573), (50, 0.0), (51, 0.0), (52, 0.0), (53, 0.0), (54, 0.0), (55, 0.0), (56, 0.0), (57, 0.004724119319047174), (58, 0.0), (59, 0.0), (60, 0.0031183166973559394), (61, 0.0), (62, 0.0), (63, 0.0), (64, 0.005733518740979196), (65, 0.0), (66, 0.0), (67, 0.00707590069107236), (68, 0.0), (69, 0.013263045534816022), (70, 0.0), (71, 0.007734305080969812), (72, 0.0), (73, 0.0), (74, 0.0), (75, 0.025854895666663352), (76, 0.0), (77, 0.0), (78, 0.0), (79, 0.0), (80, 0.0), (81, 0.0), (82, 0.0), (83, 0.006423199007022055), (84, 0.0), (85, 0.0), (86, 0.005249344494505807), (87, 0.016875116290740646), (88, 0.0), (89, 0.034103807051222304), (90, 0.0), (91, 0.013904823190005846), (92, 0.004589610937995691), (93, 0.0), (94, 0.013220742745680787), (95, 0.0), (96, 0.0), (97, 0.0), (98, 0.0), (99, 0.00428310183180643), (100, 0.0), (101, 0.0), (102, 0.0), (103, 0.0), (104, 0.0), (105, 0.019170767432015005), (106, 0.0), (107, 0.0), (108, 0.04055364647476116), (109, 0.0), (110, 0.003604870526258632), (111, 0.0), (112, 0.0), (113, 0.0), (114, 0.0), (115, 0.0), (116, 0.0), (117, 0.0), (118, 0.0), (119, 0.009239100246494101), (120, 0.008237300686574177), (121, 0.0), (122, 0.022020894824123914), (123, 0.0), (124, 0.0), (125, 0.014885005189665543), (126, 0.0), (127, 0.0), (128, 0.0057361704222008226), (129, 0.0), (130, 0.0), (131, 0.0), (132, 0.0), (133, 0.014832155317054934), (134, 0.0), (135, 0.0), (136, 0.0), (137, 0.0), (138, 0.015731887874006072), (139, 0.0), (140, 0.0), (141, 0.0), (142, 0.0), (143, 0.0), (144, 0.03358299439648683), (145, 0.003945866001189277), (146, 0.0), (147, 0.007513611100309499), (148, 0.0), (149, 0.0), (150, 0.0), (151, 0.015879197814512903), (152, 0.011927370265836196), (153, 0.0), (154, 0.0072841940849866366), (155, 0.0), (156, 0.0037339160939698817), (157, 0.0), (158, 0.01147038076464546), (159, 0.01666877240911804), (160, 0.0), (161, 0.013485677656472706), (162, 0.009339377311456615), (163, 0.0035710137066014506), (164, 0.01155768814090946), (165, 0.0), (166, 0.0), (167, 0.0052434726880116085), (168, 0.0), (169, 0.0), (170, 0.0), (171, 0.03662723785033928), (172, 0.0), (173, 0.0), (174, 0.0), (175, 0.0), (176, 0.0), (177, 0.003534108635771168), (178, 0.0), (179, 0.00773514288833975), (180, 0.002754742238789424), (181, 0.0), (182, 0.03427389462234283), (183, 0.0), (184, 0.0), (185, 0.0), (186, 0.0), (187, 0.0), (188, 0.005400606466759352), (189, 0.0), (190, 0.0), (191, 0.005577065037387603), (192, 0.0), (193, 0.0), (194, 0.008658591850714891), (195, 0.0), (196, 0.03196190259031823), (197, 0.0026461938183043815), (198, 0.0), (199, 0.0), (200, 0.0), (201, 0.003468976874765784), (202, 0.01793110399779748), (203, 0.0), (204, 0.0), (205, 0.0035476587292154822), (206, 0.01776114095554666), (207, 0.01624232852524783), (208, 0.0), (209, 0.0), (210, 0.0), (211, 0.0), (212, 0.0), (213, 0.006724209364223501), (214, 0.01623372684088141), (215, 0.008906812520451144), (216, 0.007271509476898464), (217, 0.0), (218, 0.0), (219, 0.0), (220, 0.006433065515251853), (221, 0.0), (222, 0.0), (223, 0.0), (224, 0.005611907019575541), (225, 0.008054338367536698), (226, 0.010501637946258056), (227, 0.014019264122158228), (228, 0.06032442937679674), (229, 0.0), (230, 0.0), (231, 0.00767475757552825), (232, 0.005406973400267277), (233, 0.0), (234, 0.0), (235, 0.011034518268868383), (236, 0.0), (237, 0.0), (238, 0.0), (239, 0.0), (240, 0.0), (241, 0.0), (242, 0.032491753951403746), (243, 0.0), (244, 0.0), (245, 0.006897341009663337), (246, 0.010269528024909231), (247, 0.008666784067993955), (248, 0.0075249593111964275), (249, 0.008288544046735607), (250, 0.0), (251, 0.0), (252, 0.0), (253, 0.0), (254, 0.007239791014722917), (255, 0.06712046678403279), (256, 0.0), (257, 0.9999999999999999), (258, 0.0), (259, 0.03282804338151579), (260, 0.010936560555822416), (261, 0.0), (262, 0.0), (263, 0.0), (264, 0.0), (265, 0.0), (266, 0.0), (267, 0.0), (268, 0.0), (269, 0.0), (270, 0.018564365011848043), (271, 0.0), (272, 0.0), (273, 0.007870788222112632), (274, 0.0), (275, 0.008390438023964868), (276, 0.0), (277, 0.0), (278, 0.0), (279, 0.0069159457238887195), (280, 0.0), (281, 0.00634836617167658), (282, 0.0), (283, 0.0), (284, 0.010419558066834662), (285, 0.0), (286, 0.0), (287, 0.0), (288, 0.0), (289, 0.006514522798309562), (290, 0.0), (291, 0.0), (292, 0.0), (293, 0.006215489384698668), (294, 0.0), (295, 0.00757553401880439), (296, 0.0), (297, 0.0), (298, 0.0), (299, 0.0), (300, 0.0), (301, 0.0), (302, 0.0), (303, 0.0), (304, 0.0), (305, 0.0), (306, 0.0), (307, 0.0), (308, 0.0), (309, 0.0), (310, 0.03116223171264484), (311, 0.0), (312, 0.017106006621484388), (313, 0.0), (314, 0.0), (315, 0.0), (316, 0.0), (317, 0.0), (318, 0.0), (319, 0.029962167575930183), (320, 0.0), (321, 0.0), (322, 0.007430934708667289), (323, 0.0), (324, 0.014780936447917864), (325, 0.03768084334267056), (326, 0.0), (327, 0.0), (328, 0.0), (329, 0.0), (330, 0.0), (331, 0.0), (332, 0.011966208381215922), (333, 0.004065450807284318), (334, 0.0), (335, 0.0), (336, 0.0), (337, 0.0), (338, 0.0), (339, 0.00828724179874585), (340, 0.0), (341, 0.0), (342, 0.0), (343, 0.008032530894868078), (344, 0.0), (345, 0.0), (346, 0.0), (347, 0.005352689217472357), (348, 0.0), (349, 0.0), (350, 0.0), (351, 0.005602568742588214), (352, 0.0), (353, 0.0), (354, 0.0), (355, 0.0), (356, 0.022162648716183304), (357, 0.0), (358, 0.0), (359, 0.007047618560897853), (360, 0.02310142000135587), (361, 0.007073259782373109), (362, 0.0), (363, 0.0), (364, 0.012885120724534646), (365, 0.0), (366, 0.0), (367, 0.0), (368, 0.0), (369, 0.0), (370, 0.005663758608161805), (371, 0.0), (372, 0.0), (373, 0.0), (374, 0.0), (375, 0.0), (376, 0.007509621993603237), (377, 0.0), (378, 0.01012036487469311), (379, 0.0), (380, 0.0), (381, 0.0), (382, 0.03498125912275193), (383, 0.011711817666193487), (384, 0.00500276841826758), (385, 0.005624205823505264), (386, 0.019602114271672057), (387, 0.0), (388, 0.0), (389, 0.0), (390, 0.010716624624233801), (391, 0.0), (392, 0.0), (393, 0.0), (394, 0.0), (395, 0.0), (396, 0.016025602167931367), (397, 0.0), (398, 0.008281619690312998), (399, 0.0), (400, 0.0), (401, 0.0), (402, 0.003566613927869583), (403, 0.0), (404, 0.0), (405, 0.0), (406, 0.0), (407, 0.0), (408, 0.0), (409, 0.019553238107607302), (410, 0.0), (411, 0.0), (412, 0.009439881587753815), (413, 0.0), (414, 0.018223223678890874), (415, 0.0), (416, 0.005275952850572301), (417, 0.012858109649876541), (418, 0.0), (419, 0.0), (420, 0.0), (421, 0.0), (422, 0.0), (423, 0.013549351486775099), (424, 0.0), (425, 0.0), (426, 0.005278560053613567), (427, 0.0), (428, 0.006205031680479512), (429, 0.0), (430, 0.021155361553963015), (431, 0.0), (432, 0.0), (433, 0.005622168500699815), (434, 0.007966876496142208), (435, 0.0), (436, 0.006488443587331896), (437, 0.0), (438, 0.003706341171217156), (439, 0.0), (440, 0.004565250447504982), (441, 0.0), (442, 0.0), (443, 0.011860495113883505), (444, 0.005600489740039469), (445, 0.0), (446, 0.0), (447, 0.0), (448, 0.0), (449, 0.0), (450, 0.007643444670381008), (451, 0.0), (452, 0.0), (453, 0.0), (454, 0.0), (455, 0.0), (456, 0.0043119064376113845), (457, 0.0), (458, 0.0), (459, 0.0), (460, 0.0), (461, 0.022200838092431178), (462, 0.06934650192307547), (463, 0.0), (464, 0.0), (465, 0.0), (466, 0.0), (467, 0.017998241167092078), (468, 0.0), (469, 0.0), (470, 0.0), (471, 0.005642404975067953), (472, 0.0), (473, 0.0), (474, 0.0), (475, 0.005668120984058578), (476, 0.0), (477, 0.0), (478, 0.022265615613812427), (479, 0.0), (480, 0.00932799029614577), (481, 0.010049828809772995), (482, 0.008225656345308517), (483, 0.02369030876171032), (484, 0.0), (485, 0.0), (486, 0.0), (487, 0.03300883621493249), (488, 0.005363255292723171), (489, 0.0), (490, 0.0), (491, 0.0), (492, 0.0), (493, 0.0), (494, 0.0), (495, 0.007398737672521938), (496, 0.0), (497, 0.0), (498, 0.0), (499, 0.00892861379676273), (500, 0.0), (501, 0.0), (502, 0.0), (503, 0.007921053590417159), (504, 0.004679852324637821), (505, 0.0), (506, 0.046245407387482784), (507, 0.004854600728130943), (508, 0.0), (509, 0.0), (510, 0.018599835753391893), (511, 0.0), (512, 0.0), (513, 0.014176200257978862), (514, 0.0), (515, 0.0), (516, 0.0026301584722075275), (517, 0.005891940417154006), (518, 0.016696504038780945), (519, 0.00692097060702739), (520, 0.0), (521, 0.0), (522, 0.0), (523, 0.0), (524, 0.005634828050499352), (525, 0.0), (526, 0.0), (527, 0.0), (528, 0.0), (529, 0.015260993564531863), (530, 0.0), (531, 0.0), (532, 0.0), (533, 0.007028072293763663), (534, 0.0), (535, 0.011772521251956724), (536, 0.0), (537, 0.0), (538, 0.0), (539, 0.0), (540, 0.0), (541, 0.0), (542, 0.0), (543, 0.0), (544, 0.010508713428834896), (545, 0.0), (546, 0.0), (547, 0.005496671192422925), (548, 0.016156195578160795), (549, 0.0), (550, 0.03609685450163774), (551, 0.004086422988566992), (552, 0.0), (553, 0.0), (554, 0.0), (555, 0.0), (556, 0.0), (557, 0.0), (558, 0.0), (559, 0.01585532013528309), (560, 0.0), (561, 0.006587680066157494), (562, 0.0), (563, 0.010514906878750492), (564, 0.01651554438474592), (565, 0.0), (566, 0.0), (567, 0.016618851238554395), (568, 0.02679219714067607), (569, 0.0), (570, 0.006925534301907231), (571, 0.0), (572, 0.0), (573, 0.0), (574, 0.08321747918144712), (575, 0.0), (576, 0.0), (577, 0.0), (578, 0.0), (579, 0.0), (580, 0.012718354101395381), (581, 0.005352488035635765), (582, 0.04640025589284035), (583, 0.0), (584, 0.0), (585, 0.0), (586, 0.0), (587, 0.0056056951978934524), (588, 0.037832752003878964), (589, 0.005396593325691649), (590, 0.0), (591, 0.006573771680918668), (592, 0.0), (593, 0.0), (594, 0.0), (595, 0.012546793507481705), (596, 0.0), (597, 0.0), (598, 0.0), (599, 0.0), (600, 0.0), (601, 0.0), (602, 0.0), (603, 0.020179946668680716), (604, 0.011827251773288316), (605, 0.0), (606, 0.0), (607, 0.0), (608, 0.0), (609, 0.0), (610, 0.0), (611, 0.0), (612, 0.0), (613, 0.0), (614, 0.0), (615, 0.0), (616, 0.0), (617, 0.0), (618, 0.0), (619, 0.0), (620, 0.02169372618294079), (621, 0.0), (622, 0.0), (623, 0.0), (624, 0.009860405701775442), (625, 0.0), (626, 0.0), (627, 0.0), (628, 0.0), (629, 0.0), (630, 0.0), (631, 0.013667610022913222), (632, 0.016638303825169846), (633, 0.024046758419329885), (634, 0.0), (635, 0.0), (636, 0.0), (637, 0.0), (638, 0.0), (639, 0.03838266340042399), (640, 0.0), (641, 0.007240373670983657), (642, 0.025502261470470695), (643, 0.0), (644, 0.01540728926394705), (645, 0.01515772191519906), (646, 0.0), (647, 0.008382651577880772), (648, 0.0), (649, 0.0), (650, 0.0), (651, 0.0), (652, 0.0), (653, 0.005793816367065599), (654, 0.006158183227032408), (655, 0.0), (656, 0.0), (657, 0.0), (658, 0.0), (659, 0.0), (660, 0.0), (661, 0.0), (662, 0.0), (663, 0.0), (664, 0.026942642119014266), (665, 0.003816963351666015), (666, 0.0), (667, 0.0), (668, 0.0), (669, 0.0), (670, 0.0), (671, 0.0), (672, 0.0), (673, 0.0), (674, 0.0), (675, 0.0), (676, 0.008414273558490667), (677, 0.03140133039531247), (678, 0.0), (679, 0.0), (680, 0.02626088355505017), (681, 0.0), (682, 0.0), (683, 0.0218408972404161), (684, 0.0), (685, 0.013651961705678388), (686, 0.0), (687, 0.0), (688, 0.005285959747266833), (689, 0.0), (690, 0.0), (691, 0.0), (692, 0.0), (693, 0.0), (694, 0.0), (695, 0.0), (696, 0.004291454828844404), (697, 0.0), (698, 0.0), (699, 0.007654335531366955), (700, 0.015317750049345318), (701, 0.0), (702, 0.018019088133791657), (703, 0.0), (704, 0.0), (705, 0.0), (706, 0.0), (707, 0.0), (708, 0.02143798297019318), (709, 0.0), (710, 0.0), (711, 0.0), (712, 0.011986317272031517), (713, 0.0), (714, 0.0), (715, 0.0), (716, 0.0), (717, 0.006405500071730205), (718, 0.0), (719, 0.0), (720, 0.005706321911839517), (721, 0.016966444314181955), (722, 0.0), (723, 0.0), (724, 0.0), (725, 0.0037008036879541697), (726, 0.0), (727, 0.0), (728, 0.0), (729, 0.0065143935458500495), (730, 0.0), (731, 0.012438943440290715), (732, 0.006129436559822793), (733, 0.0), (734, 0.0), (735, 0.00881253061319214), (736, 0.0069982180432355484), (737, 0.008160112803224383), (738, 0.0), (739, 0.0), (740, 0.0), (741, 0.0), (742, 0.004464264325952677), (743, 0.0), (744, 0.005247780902364746), (745, 0.0), (746, 0.0), (747, 0.0), (748, 0.0), (749, 0.007375209789550198), (750, 0.0), (751, 0.00830526617795416), (752, 0.0), (753, 0.0), (754, 0.0), (755, 0.0), (756, 0.0), (757, 0.0), (758, 0.0), (759, 0.0), (760, 0.007055739711617612), (761, 0.0), (762, 0.0), (763, 0.0), (764, 0.01674726922960685), (765, 0.005749580309847509), (766, 0.009827807958482804), (767, 0.010794013034286195), (768, 0.0), (769, 0.006197467132464888), (770, 0.008864332113258785), (771, 0.005594940103971286), (772, 0.0), (773, 0.0), (774, 0.0), (775, 0.0), (776, 0.0), (777, 0.0), (778, 0.0), (779, 0.0), (780, 0.015566637635910898), (781, 0.0065252993890491315), (782, 0.0), (783, 0.007186927785491542), (784, 0.009438746589106591), (785, 0.0), (786, 0.010493178586945817), (787, 0.006073623402671105), (788, 0.0), (789, 0.0), (790, 0.007733991075313942), (791, 0.0), (792, 0.011829541723834379), (793, 0.0), (794, 0.0), (795, 0.005823232270583433), (796, 0.009077239915265498), (797, 0.0), (798, 0.0), (799, 0.0), (800, 0.0), (801, 0.0), (802, 0.0), (803, 0.0), (804, 0.0), (805, 0.0), (806, 0.0), (807, 0.0), (808, 0.0), (809, 0.0), (810, 0.007527887684558096), (811, 0.0), (812, 0.0), (813, 0.0), (814, 0.0), (815, 0.01790813220111722), (816, 0.0), (817, 0.0), (818, 0.0), (819, 0.0), (820, 0.0), (821, 0.0), (822, 0.0), (823, 0.0), (824, 0.0037981241068281886), (825, 0.0), (826, 0.0), (827, 0.0), (828, 0.0), (829, 0.0), (830, 0.0), (831, 0.0), (832, 0.003947180104169665), (833, 0.007232054504489379), (834, 0.0), (835, 0.0), (836, 0.0), (837, 0.0), (838, 0.0), (839, 0.0), (840, 0.0), (841, 0.0), (842, 0.0), (843, 0.0), (844, 0.0), (845, 0.0), (846, 0.015458740715339914), (847, 0.0), (848, 0.0), (849, 0.0), (850, 0.007284801014462942), (851, 0.01627183752837716), (852, 0.03556066936660281), (853, 0.0), (854, 0.0), (855, 0.011117824622845272), (856, 0.0), (857, 0.007312213232788182), (858, 0.0), (859, 0.0), (860, 0.009779088806748859), (861, 0.0), (862, 0.006371150930233828), (863, 0.0037721773155154417), (864, 0.0), (865, 0.12776183015002765), (866, 0.010787886049599623), (867, 0.0), (868, 0.004610030045162432), (869, 0.0), (870, 0.0), (871, 0.0), (872, 0.006056442441269355), (873, 0.0), (874, 0.004056521407230442), (875, 0.0), (876, 0.0), (877, 0.0), (878, 0.006900818464299356), (879, 0.0), (880, 0.0), (881, 0.0024059185491105773), (882, 0.002217048218210588), (883, 0.0), (884, 0.009517101225964069), (885, 0.0), (886, 0.016413038373275506), (887, 0.006259075620779108), (888, 0.011272434782115447), (889, 0.0), (890, 0.0), (891, 0.019462854728729908), (892, 0.0), (893, 0.0), (894, 0.0), (895, 0.0047978785882822166), (896, 0.023002745090155163), (897, 0.0), (898, 0.032140923948720965), (899, 0.05937161781971309), (900, 0.04195910563370074), (901, 0.008935010232570083), (902, 0.006544970470658108), (903, 0.007176610012500201), (904, 0.0), (905, 0.013141434440953871), (906, 0.0), (907, 0.0), (908, 0.0), (909, 0.0), (910, 0.0), (911, 0.014521091025824159), (912, 0.011697598654815382), (913, 0.008681973704940376), (914, 0.0), (915, 0.014894977180796432), (916, 0.004848221303775953), (917, 0.0), (918, 0.0), (919, 0.0), (920, 0.0), (921, 0.0), (922, 0.010998244987796788), (923, 0.022627341510225222), (924, 0.0), (925, 0.0), (926, 0.014731501198121864), (927, 0.0), (928, 0.0), (929, 0.0), (930, 0.0), (931, 0.0), (932, 0.0), (933, 0.00469478885461223), (934, 0.0), (935, 0.003223661358816785), (936, 0.0030497173559712763), (937, 0.0), (938, 0.0030221507158634626), (939, 0.008824091948333052), (940, 0.0), (941, 0.08127429536911791), (942, 0.0), (943, 0.0), (944, 0.004714823287349396), (945, 0.008873809044217142), (946, 0.0), (947, 0.0), (948, 0.0), (949, 0.0), (950, 0.0), (951, 0.0), (952, 0.017050332160865992), (953, 0.0), (954, 0.0025279630866817566), (955, 0.0), (956, 0.0), (957, 0.008151027636548056), (958, 0.0), (959, 0.01006684167084286), (960, 0.0), (961, 0.0), (962, 0.0), (963, 0.0), (964, 0.0), (965, 0.0), (966, 0.0), (967, 0.0), (968, 0.0), (969, 0.0), (970, 0.0), (971, 0.0), (972, 0.0), (973, 0.0), (974, 0.0), (975, 0.03319871942601911), (976, 0.0), (977, 0.0), (978, 0.0), (979, 0.0), (980, 0.01602784914693705), (981, 0.0), (982, 0.0), (983, 0.0), (984, 0.0), (985, 0.004085840367249405), (986, 0.0), (987, 0.0), (988, 0.0), (989, 0.0), (990, 0.004837100988067164), (991, 0.0), (992, 0.0), (993, 0.0), (994, 0.0), (995, 0.0), (996, 0.0), (997, 0.0), (998, 0.0), (999, 0.0), (1000, 0.0), (1001, 0.0), (1002, 0.01545916095453806), (1003, 0.011640685475809398), (1004, 0.0), (1005, 0.0), (1006, 0.007529162305000255), (1007, 0.0), (1008, 0.024363344075086068), (1009, 0.0), (1010, 0.0), (1011, 0.0), (1012, 0.0056381770690748755), (1013, 0.0), (1014, 0.0), (1015, 0.0), (1016, 0.030646626774665574), (1017, 0.03375581773829743), (1018, 0.0), (1019, 0.0), (1020, 0.0), (1021, 0.0), (1022, 0.0), (1023, 0.0), (1024, 0.010836712633270202), (1025, 0.0), (1026, 0.008789134649493841), (1027, 0.003982048716773452), (1028, 0.004716051298193099), (1029, 0.0), (1030, 0.0), (1031, 0.007756066108469966), (1032, 0.0), (1033, 0.008785450166381912), (1034, 0.0), (1035, 0.0), (1036, 0.0), (1037, 0.006133848969648392), (1038, 0.0), (1039, 0.007843933897592113), (1040, 0.0), (1041, 0.0), (1042, 0.0), (1043, 0.006212521027408386), (1044, 0.035345962606676995), (1045, 0.0), (1046, 0.0), (1047, 0.0), (1048, 0.0), (1049, 0.0), (1050, 0.0), (1051, 0.0), (1052, 0.0), (1053, 0.0), (1054, 0.0046354613506258335), (1055, 0.0), (1056, 0.0), (1057, 0.0016860560171941814), (1058, 0.0), (1059, 0.0), (1060, 0.0), (1061, 0.0040699166538774355), (1062, 0.009418960977863513), (1063, 0.0), (1064, 0.01879795941623079), (1065, 0.028749909115346473), (1066, 0.0), (1067, 0.0), (1068, 0.0), (1069, 0.0071783639397943215), (1070, 0.0), (1071, 0.0), (1072, 0.011722288298196276), (1073, 0.0), (1074, 0.0), (1075, 0.0), (1076, 0.0), (1077, 0.0), (1078, 0.0), (1079, 0.0), (1080, 0.0), (1081, 0.0), (1082, 0.0), (1083, 0.0), (1084, 0.0), (1085, 0.0), (1086, 0.0), (1087, 0.0), (1088, 0.0), (1089, 0.006237305490121149), (1090, 0.0077700096937030885), (1091, 0.0), (1092, 0.0), (1093, 0.0), (1094, 0.0), (1095, 0.012776958492778137), (1096, 0.0), (1097, 0.02527070720523414), (1098, 0.0), (1099, 0.0), (1100, 0.0), (1101, 0.0), (1102, 0.0), (1103, 0.0), (1104, 0.009954654768557046), (1105, 0.0), (1106, 0.0), (1107, 0.0), (1108, 0.017505719817744674), (1109, 0.014210582335090274), (1110, 0.0), (1111, 0.0), (1112, 0.0), (1113, 0.0), (1114, 0.0), (1115, 0.0), (1116, 0.012463871902761664), (1117, 0.0), (1118, 0.0), (1119, 0.013055878813478007), (1120, 0.0), (1121, 0.0), (1122, 0.0), (1123, 0.004802390627553834), (1124, 0.0), (1125, 0.01199087410510521), (1126, 0.0), (1127, 0.0), (1128, 0.0), (1129, 0.0), (1130, 0.00432839679996409), (1131, 0.0), (1132, 0.0), (1133, 0.0), (1134, 0.0), (1135, 0.0), (1136, 0.0), (1137, 0.0), (1138, 0.0), (1139, 0.0), (1140, 0.0), (1141, 0.0), (1142, 0.0), (1143, 0.0), (1144, 0.0), (1145, 0.0), (1146, 0.0), (1147, 0.0), (1148, 0.0), (1149, 0.017200900768158715), (1150, 0.0), (1151, 0.0), (1152, 0.0054634071094949955), (1153, 0.0), (1154, 0.0), (1155, 0.0), (1156, 0.0), (1157, 0.0), (1158, 0.0), (1159, 0.010775149020004742), (1160, 0.01203186872569012), (1161, 0.0), (1162, 0.0), (1163, 0.010926011457603262), (1164, 0.006186157245574783), (1165, 0.0), (1166, 0.0), (1167, 0.00776110877863237), (1168, 0.0), (1169, 0.00615013139635874), (1170, 0.0), (1171, 0.4335392852988003), (1172, 0.03877990992127391), (1173, 0.013451831654137329), (1174, 0.0), (1175, 0.043192960065587885), (1176, 0.0031069731874763516), (1177, 0.0), (1178, 0.0), (1179, 0.01978654935671029), (1180, 0.0), (1181, 0.0), (1182, 0.006052172952420899), (1183, 0.0), (1184, 0.4726571038951565), (1185, 0.010767889127932003), (1186, 0.005798417478353447), (1187, 0.0), (1188, 0.0), (1189, 0.0029638351795246193), (1190, 0.0), (1191, 0.0), (1192, 0.02518306313351727), (1193, 0.0), (1194, 0.01217017583986895), (1195, 0.0), (1196, 0.0), (1197, 0.03896545835598053), (1198, 0.0), (1199, 0.0), (1200, 0.008394760459145173), (1201, 0.0), (1202, 0.0), (1203, 0.0), (1204, 0.0), (1205, 0.0), (1206, 0.0), (1207, 0.0), (1208, 0.0), (1209, 0.005079506402160132), (1210, 0.0), (1211, 0.0), (1212, 0.0), (1213, 0.0), (1214, 0.027264506109820476), (1215, 0.0), (1216, 0.0), (1217, 0.0), (1218, 0.0), (1219, 0.0), (1220, 0.006723907731329832), (1221, 0.005326366887846234), (1222, 0.0), (1223, 0.009212883757355277), (1224, 0.0), (1225, 0.0), (1226, 0.0), (1227, 0.0), (1228, 0.0), (1229, 0.0), (1230, 0.0), (1231, 0.0), (1232, 0.0), (1233, 0.0), (1234, 0.0), (1235, 0.0), (1236, 0.0), (1237, 0.0), (1238, 0.011891641017823093), (1239, 0.006823627894497174), (1240, 0.0), (1241, 0.0), (1242, 0.0), (1243, 0.0), (1244, 0.0), (1245, 0.0), (1246, 0.0), (1247, 0.0), (1248, 0.07953463431301931), (1249, 0.0), (1250, 0.007409430213853835), (1251, 0.0), (1252, 0.0), (1253, 0.006633878874136815), (1254, 0.012007457956468542), (1255, 0.0053184476313096135), (1256, 0.004940208457584938), (1257, 0.0), (1258, 0.0), (1259, 0.005973346920340082), (1260, 0.0), (1261, 0.009546791944830876), (1262, 0.0), (1263, 0.0), (1264, 0.0), (1265, 0.006873389708426587), (1266, 0.0), (1267, 0.0), (1268, 0.01567844334672536), (1269, 0.00489709108532292), (1270, 0.02213877944086232), (1271, 0.0), (1272, 0.0), (1273, 0.005172465161981587), (1274, 0.0), (1275, 0.0), (1276, 0.013624533905705363), (1277, 0.004354864420691472), (1278, 0.0), (1279, 0.0), (1280, 0.0), (1281, 0.0), (1282, 0.0), (1283, 0.0), (1284, 0.0), (1285, 0.0), (1286, 0.0), (1287, 0.0), (1288, 0.0), (1289, 0.0), (1290, 0.0), (1291, 0.0), (1292, 0.0), (1293, 0.0), (1294, 0.007320347350278475), (1295, 0.02301047550797293), (1296, 0.0), (1297, 0.0), (1298, 0.003636110184406601), (1299, 0.0), (1300, 0.0), (1301, 0.030918154741722423), (1302, 0.0), (1303, 0.006894584002155678), (1304, 0.0), (1305, 0.0), (1306, 0.0), (1307, 0.0), (1308, 0.008940828444755685), (1309, 0.005954456375067472), (1310, 0.006486051068628447), (1311, 0.0), (1312, 0.0), (1313, 0.0), (1314, 0.0), (1315, 0.004167772369015169), (1316, 0.0), (1317, 0.0), (1318, 0.0), (1319, 0.0), (1320, 0.0), (1321, 0.005306600608674815), (1322, 0.021464492201802115), (1323, 0.0), (1324, 0.0), (1325, 0.0), (1326, 0.020592768818460797), (1327, 0.0), (1328, 0.011505793459029065), (1329, 0.0), (1330, 0.0), (1331, 0.017289595358154258), (1332, 0.011023334583205755), (1333, 0.006428964967565002), (1334, 0.0), (1335, 0.0), (1336, 0.01636382908427584), (1337, 0.0), (1338, 0.02374264523879642), (1339, 0.04838283309302201), (1340, 0.0), (1341, 0.014767854002798862), (1342, 0.08412621888340621), (1343, 0.0), (1344, 0.0), (1345, 0.02287662316353779), (1346, 0.003091636807131516), (1347, 0.017551237178234626), (1348, 0.0), (1349, 0.006086452056644323), (1350, 0.0), (1351, 0.010751795735810102), (1352, 0.0), (1353, 0.0), (1354, 0.024571353310207406), (1355, 0.0), (1356, 0.0), (1357, 0.0), (1358, 0.008420147360727902), (1359, 0.0), (1360, 0.0), (1361, 0.017163704529228246), (1362, 0.007227232476711827), (1363, 0.01743539953061415), (1364, 0.0), (1365, 0.008017242181347478), (1366, 0.0), (1367, 0.0), (1368, 0.002683089623961543), (1369, 0.0), (1370, 0.024332478496510317), (1371, 0.0), (1372, 0.0), (1373, 0.018055950412287542), (1374, 0.0), (1375, 0.013556981051823798), (1376, 0.0), (1377, 0.010590442083959355), (1378, 0.0), (1379, 0.0), (1380, 0.0), (1381, 0.0), (1382, 0.0), (1383, 0.0), (1384, 0.022752744098900834), (1385, 0.0040260107853035436), (1386, 0.0), (1387, 0.0), (1388, 0.01216491963123185), (1389, 0.0), (1390, 0.0), (1391, 0.00854732000860831), (1392, 0.0), (1393, 0.006658185860082496), (1394, 0.0), (1395, 0.0), (1396, 0.0), (1397, 0.006458920451338799), (1398, 0.02825396405680565), (1399, 0.011225351127834345), (1400, 0.0), (1401, 0.013908130976205949), (1402, 0.0), (1403, 0.0), (1404, 0.0), (1405, 0.012802593348574995), (1406, 0.0), (1407, 0.0), (1408, 0.0), (1409, 0.0), (1410, 0.015582108584265423), (1411, 0.0), (1412, 0.023503270496583295), (1413, 0.0), (1414, 0.007858869851040139), (1415, 0.0), (1416, 0.0), (1417, 0.0), (1418, 0.0), (1419, 0.0), (1420, 0.006710298153830251), (1421, 0.0), (1422, 0.0), (1423, 0.004346566166386799), (1424, 0.004801537422380331), (1425, 0.0), (1426, 0.01247785426565598), (1427, 0.0), (1428, 0.00759230389858989), (1429, 0.004267610981135474), (1430, 0.0), (1431, 0.0), (1432, 0.0), (1433, 0.014395465622951957), (1434, 0.0), (1435, 0.0364483886542064), (1436, 0.0), (1437, 0.0), (1438, 0.0), (1439, 0.010763428001266638), (1440, 0.004686458949372772), (1441, 0.0), (1442, 0.0), (1443, 0.0), (1444, 0.0), (1445, 0.0), (1446, 0.0), (1447, 0.0), (1448, 0.0), (1449, 0.0), (1450, 0.007270614045130107), (1451, 0.0), (1452, 0.0), (1453, 0.00642086028479576), (1454, 0.0), (1455, 0.008809015615345086), (1456, 0.0), (1457, 0.0), (1458, 0.0), (1459, 0.0), (1460, 0.0), (1461, 0.006598221861011813), (1462, 0.0), (1463, 0.0), (1464, 0.0), (1465, 0.0), (1466, 0.03035418182213344), (1467, 0.0), (1468, 0.005058220123218859), (1469, 0.0), (1470, 0.0), (1471, 0.0), (1472, 0.00455876461826439), (1473, 0.0), (1474, 0.00569443232767384), (1475, 0.0), (1476, 0.02744080645953486), (1477, 0.0), (1478, 0.0), (1479, 0.0), (1480, 0.014011219733436962), (1481, 0.0), (1482, 0.0), (1483, 0.022417475312741512), (1484, 0.0), (1485, 0.005234799167327875), (1486, 0.012735356268559445), (1487, 0.005934569629303429), (1488, 0.021165882475484815), (1489, 0.005438473478853049), (1490, 0.005341324392234845), (1491, 0.010948313965903657), (1492, 0.0), (1493, 0.0), (1494, 0.0), (1495, 0.0), (1496, 0.004684821664608216), (1497, 0.004381220946069948), (1498, 0.0), (1499, 0.0), (1500, 0.0), (1501, 0.0), (1502, 0.0035543287833602363), (1503, 0.0), (1504, 0.0), (1505, 0.0), (1506, 0.004772477156162541), (1507, 0.010236861006605463), (1508, 0.0), (1509, 0.0), (1510, 0.0), (1511, 0.0), (1512, 0.004039350470341846), (1513, 0.0), (1514, 0.0), (1515, 0.012641127999026914), (1516, 0.0), (1517, 0.010686917727590058), (1518, 0.0), (1519, 0.0), (1520, 0.0), (1521, 0.0), (1522, 0.0), (1523, 0.0086606588733715), (1524, 0.0), (1525, 0.0), (1526, 0.005326155536610958), (1527, 0.021634700677442727), (1528, 0.04345899938090852), (1529, 0.0), (1530, 0.0), (1531, 0.006471359769190146), (1532, 0.01775968236883901), (1533, 0.0), (1534, 0.0), (1535, 0.0294625443880471), (1536, 0.0), (1537, 0.003197434569290144), (1538, 0.0), (1539, 0.0047487443208204085), (1540, 0.0), (1541, 0.009258572711604206), (1542, 0.0), (1543, 0.011702486908363398), (1544, 0.0), (1545, 0.0), (1546, 0.017203078794943816), (1547, 0.0), (1548, 0.0), (1549, 0.006466210908556227), (1550, 0.004934702594661469), (1551, 0.0), (1552, 0.0), (1553, 0.0), (1554, 0.0), (1555, 0.0326610746253405), (1556, 0.0), (1557, 0.014939880862665638), (1558, 0.007129510906532589), (1559, 0.0), (1560, 0.006787852747005994), (1561, 0.0), (1562, 0.0), (1563, 0.00792753151857476), (1564, 0.015168325778729619), (1565, 0.0), (1566, 0.006516496217208473), (1567, 0.01164448488468943), (1568, 0.0), (1569, 0.0), (1570, 0.0), (1571, 0.0), (1572, 0.0), (1573, 0.0), (1574, 0.004094717056406003), (1575, 0.0), (1576, 0.0), (1577, 0.005377287229757622), (1578, 0.0), (1579, 0.0), (1580, 0.004923443546834534), (1581, 0.0), (1582, 0.009036707303832077), (1583, 0.0), (1584, 0.0), (1585, 0.0), (1586, 0.0), (1587, 0.0), (1588, 0.0), (1589, 0.0), (1590, 0.0), (1591, 0.0), (1592, 0.0), (1593, 0.0), (1594, 0.0), (1595, 0.0), (1596, 0.0), (1597, 0.0), (1598, 0.0), (1599, 0.0), (1600, 0.0), (1601, 0.04746997295787472), (1602, 0.0), (1603, 0.009704595204950654), (1604, 0.0), (1605, 0.0), (1606, 0.014427340214121932), (1607, 0.0), (1608, 0.008066677509680265), (1609, 0.0), (1610, 0.02333880970618626), (1611, 0.0), (1612, 0.007419852241614347), (1613, 0.0), (1614, 0.0), (1615, 0.0), (1616, 0.0), (1617, 0.0), (1618, 0.0), (1619, 0.0), (1620, 0.0), (1621, 0.009391791150199641), (1622, 0.0), (1623, 0.0), (1624, 0.024252038727138714), (1625, 0.0), (1626, 0.0), (1627, 0.006780374395656515), (1628, 0.0), (1629, 0.010599996212291803), (1630, 0.001939181845863038), (1631, 0.0), (1632, 0.0), (1633, 0.0), (1634, 0.022295583970512244), (1635, 0.015456016431888878), (1636, 0.013201953292455729), (1637, 0.0), (1638, 0.0), (1639, 0.0), (1640, 0.0116742054298402), (1641, 0.0), (1642, 0.006924572786796971), (1643, 0.0), (1644, 0.0), (1645, 0.0), (1646, 0.0), (1647, 0.0), (1648, 0.0), (1649, 0.0), (1650, 0.00938241974370928), (1651, 0.0), (1652, 0.0050327597863022), (1653, 0.0), (1654, 0.0), (1655, 0.0), (1656, 0.0), (1657, 0.007153536515475913), (1658, 0.0), (1659, 0.0), (1660, 0.0), (1661, 0.0), (1662, 0.02935122613537266), (1663, 0.0), (1664, 0.00855190726126686), (1665, 0.0), (1666, 0.0), (1667, 0.00640666213952978), (1668, 0.0), (1669, 0.015388261373566622), (1670, 0.0), (1671, 0.0), (1672, 0.023185792260629334), (1673, 0.0), (1674, 0.0), (1675, 0.0), (1676, 0.0), (1677, 0.020745677293203903), (1678, 0.0), (1679, 0.008365133488769123), (1680, 0.0), (1681, 0.0), (1682, 0.0), (1683, 0.0), (1684, 0.008566909608389829), (1685, 0.0041394897871573424), (1686, 0.03272567462820667), (1687, 0.007813452855198263), (1688, 0.0), (1689, 0.0), (1690, 0.0), (1691, 0.0), (1692, 0.0), (1693, 0.017913462023270956), (1694, 0.0), (1695, 0.0), (1696, 0.0), (1697, 0.004185777226561897), (1698, 0.0), (1699, 0.0), (1700, 0.006714247841640055), (1701, 0.0), (1702, 0.0), (1703, 0.004682372716604562), (1704, 0.0), (1705, 0.0), (1706, 0.0), (1707, 0.0), (1708, 0.0), (1709, 0.011321690492866836), (1710, 0.004509483113243224), (1711, 0.0), (1712, 0.0), (1713, 0.007933611887169354), (1714, 0.02199209509688069), (1715, 0.0), (1716, 0.0), (1717, 0.0), (1718, 0.0), (1719, 0.0), (1720, 0.0), (1721, 0.0), (1722, 0.0), (1723, 0.0), (1724, 0.0), (1725, 0.0), (1726, 0.0), (1727, 0.00845511525114065), (1728, 0.0), (1729, 0.0), (1730, 0.0), (1731, 0.017320854074195695), (1732, 0.005144503020204793), (1733, 0.0), (1734, 0.0), (1735, 0.0), (1736, 0.0), (1737, 0.0), (1738, 0.0), (1739, 0.013802584057645206), (1740, 0.0), (1741, 0.0), (1742, 0.0), (1743, 0.0), (1744, 0.004687175464132055), (1745, 0.005120124738192812), (1746, 0.0), (1747, 0.0), (1748, 0.0), (1749, 0.0), (1750, 0.0), (1751, 0.013722952583133465), (1752, 0.0), (1753, 0.013656844652272284), (1754, 0.0), (1755, 0.0), (1756, 0.0), (1757, 0.0), (1758, 0.0), (1759, 0.0), (1760, 0.0), (1761, 0.0), (1762, 0.0), (1763, 0.0), (1764, 0.0), (1765, 0.0075078261788102205), (1766, 0.07012974824437315), (1767, 0.0), (1768, 0.0), (1769, 0.0055219537948491566), (1770, 0.0), (1771, 0.0), (1772, 0.0), (1773, 0.0), (1774, 0.007004227825557203), (1775, 0.0), (1776, 0.0), (1777, 0.0022319547925259463), (1778, 0.0), (1779, 0.0), (1780, 0.0), (1781, 0.0), (1782, 0.0), (1783, 0.0), (1784, 0.0), (1785, 0.0), (1786, 0.0), (1787, 0.0), (1788, 0.009274808231809874), (1789, 0.0), (1790, 0.0), (1791, 0.0), (1792, 0.0), (1793, 0.0), (1794, 0.0), (1795, 0.0), (1796, 0.0), (1797, 0.0), (1798, 0.013935151000577317), (1799, 0.0), (1800, 0.0), (1801, 0.0), (1802, 0.0), (1803, 0.0), (1804, 0.008908141156181788), (1805, 0.0), (1806, 0.0), (1807, 0.0), (1808, 0.0), (1809, 0.0), (1810, 0.020015549120875886), (1811, 0.0), (1812, 0.004577985608862231), (1813, 0.0), (1814, 0.009037223940353702), (1815, 0.0), (1816, 0.0), (1817, 0.0), (1818, 0.0), (1819, 0.016956188408029708), (1820, 0.0045140713062855), (1821, 0.0), (1822, 0.0), (1823, 0.005226298229602726), (1824, 0.0), (1825, 0.005988807521765569), (1826, 0.0), (1827, 0.013246332375853917), (1828, 0.0072024521259535365), (1829, 0.0), (1830, 0.0), (1831, 0.0), (1832, 0.0), (1833, 0.0), (1834, 0.0), (1835, 0.0), (1836, 0.003937543142370319), (1837, 0.0), (1838, 0.0), (1839, 0.0), (1840, 0.0), (1841, 0.0), (1842, 0.0), (1843, 0.0), (1844, 0.0), (1845, 0.0), (1846, 0.0), (1847, 0.010816052745889742), (1848, 0.0), (1849, 0.007550813553129756), (1850, 0.0), (1851, 0.021149662931399665), (1852, 0.0), (1853, 0.0), (1854, 0.0), (1855, 0.013020866381849086), (1856, 0.0), (1857, 0.003268230668441239), (1858, 0.0), (1859, 0.01757104637249673), (1860, 0.02685610701880966), (1861, 0.0), (1862, 0.0), (1863, 0.0), (1864, 0.002881528802092692), (1865, 0.0), (1866, 0.0), (1867, 0.0), (1868, 0.01853453985434288), (1869, 0.0), (1870, 0.0), (1871, 0.00795944364073004), (1872, 0.024183208627803827), (1873, 0.0066572865626993594), (1874, 0.0), (1875, 0.0), (1876, 0.0), (1877, 0.0), (1878, 0.007282897018943128), (1879, 0.0), (1880, 0.002811345917837276), (1881, 0.0), (1882, 0.0), (1883, 0.012962055371077022), (1884, 0.025041911094168916), (1885, 0.0), (1886, 0.012482571579819168), (1887, 0.0), (1888, 0.0), (1889, 0.0), (1890, 0.0), (1891, 0.0), (1892, 0.0), (1893, 0.0), (1894, 0.0), (1895, 0.0), (1896, 0.0), (1897, 0.0), (1898, 0.0), (1899, 0.0), (1900, 0.0), (1901, 0.004068534584665548), (1902, 0.0), (1903, 0.0), (1904, 0.0), (1905, 0.0), (1906, 0.006340998563912193), (1907, 0.0), (1908, 0.0), (1909, 0.0), (1910, 0.0), (1911, 0.0), (1912, 0.0), (1913, 0.0), (1914, 0.0049208134105300175), (1915, 0.019749758272553163), (1916, 0.01086112235500147), (1917, 0.014413294985196206), (1918, 0.01811602756493729), (1919, 0.0), (1920, 0.019445352102312484), (1921, 0.003082144401699755), (1922, 0.0), (1923, 0.0), (1924, 0.0), (1925, 0.009433236054348076), (1926, 0.007799620741033124), (1927, 0.0), (1928, 0.0), (1929, 0.0), (1930, 0.0), (1931, 0.0), (1932, 0.0), (1933, 0.0), (1934, 0.0), (1935, 0.006320554377721991), (1936, 0.0), (1937, 0.0), (1938, 0.0), (1939, 0.0), (1940, 0.0), (1941, 0.006943200572936879), (1942, 0.0), (1943, 0.006472455478188765), (1944, 0.0), (1945, 0.0), (1946, 0.0), (1947, 0.0), (1948, 0.0), (1949, 0.0), (1950, 0.010050995209681), (1951, 0.0), (1952, 0.0), (1953, 0.0035323955778219437), (1954, 0.007541035188645141), (1955, 0.024937069320020353), (1956, 0.0), (1957, 0.009713219460987526), (1958, 0.0), (1959, 0.009194685046056644), (1960, 0.0), (1961, 0.005688348559455236), (1962, 0.0), (1963, 0.0), (1964, 0.0), (1965, 0.0), (1966, 0.01749606525641491), (1967, 0.0), (1968, 0.0), (1969, 0.0), (1970, 0.0), (1971, 0.0), (1972, 0.014991949926289692), (1973, 0.0), (1974, 0.0), (1975, 0.0), (1976, 0.0051914587354045345), (1977, 0.015231591378924495), (1978, 0.0), (1979, 0.0), (1980, 0.0), (1981, 0.0), (1982, 0.0), (1983, 0.00926214151843019), (1984, 0.0), (1985, 0.0), (1986, 0.0), (1987, 0.0), (1988, 0.0), (1989, 0.0), (1990, 0.0), (1991, 0.0), (1992, 0.006357302361514787), (1993, 0.005772333392065918), (1994, 0.0), (1995, 0.0), (1996, 0.0), (1997, 0.0), (1998, 0.014103130816463529), (1999, 0.0), (2000, 0.00626069493089036), (2001, 0.028774112041316146), (2002, 0.01047706711042863), (2003, 0.01667161035890709), (2004, 0.0), (2005, 0.016510365671350266), (2006, 0.026307377918065627), (2007, 0.0052357297034881616), (2008, 0.029566331833328255), (2009, 0.0), (2010, 0.006121644980063669), (2011, 0.0), (2012, 0.08853496379109525), (2013, 0.0), (2014, 0.0), (2015, 0.00646649393681551), (2016, 0.0), (2017, 0.017456768183957017), (2018, 0.018181083660686048), (2019, 0.006324108015824677), (2020, 0.0), (2021, 0.012497054916090853), (2022, 0.0), (2023, 0.0), (2024, 0.00565042895653039), (2025, 0.0), (2026, 0.0), (2027, 0.0), (2028, 0.010614856534959152), (2029, 0.0), (2030, 0.0029122050171427), (2031, 0.009878481070559492), (2032, 0.0), (2033, 0.0), (2034, 0.0), (2035, 0.0), (2036, 0.0), (2037, 0.0), (2038, 0.006221157426077961), (2039, 0.0), (2040, 0.0), (2041, 0.006101957471574332), (2042, 0.0), (2043, 0.015653306876623602), (2044, 0.0), (2045, 0.005130604861693407), (2046, 0.0028458399819489373), (2047, 0.0), (2048, 0.0), (2049, 0.0), (2050, 0.0), (2051, 0.0), (2052, 0.0), (2053, 0.0), (2054, 0.0), (2055, 0.005089310740732768), (2056, 0.021467110776141992), (2057, 0.0), (2058, 0.0), (2059, 0.04128639855564124), (2060, 0.0), (2061, 0.0), (2062, 0.003259722213640732), (2063, 0.0), (2064, 0.0), (2065, 0.0), (2066, 0.0), (2067, 0.018451781051451878), (2068, 0.0262392459601609), (2069, 0.023788010689282917), (2070, 0.013403695504922522), (2071, 0.003912718463647222), (2072, 0.023299858207074906), (2073, 0.0), (2074, 0.0), (2075, 0.0), (2076, 0.0), (2077, 0.0), (2078, 0.0), (2079, 0.0), (2080, 0.0), (2081, 0.0), (2082, 0.0), (2083, 0.004261906390458905), (2084, 0.0), (2085, 0.0), (2086, 0.0), (2087, 0.0), (2088, 0.0), (2089, 0.0), (2090, 0.006551790880646048), (2091, 0.0), (2092, 0.02205422576979468), (2093, 0.0), (2094, 0.0), (2095, 0.0), (2096, 0.0), (2097, 0.011890290985424472), (2098, 0.026896487770479236), (2099, 0.006777106260342535), (2100, 0.047733350277797265), (2101, 0.007261624980587736), (2102, 0.005325128965845557), (2103, 0.0), (2104, 0.0), (2105, 0.0), (2106, 0.006152812051303181), (2107, 0.0), (2108, 0.0), (2109, 0.0), (2110, 0.030685067080327262), (2111, 0.025349714051174543), (2112, 0.004260404499583125), (2113, 0.0), (2114, 0.0), (2115, 0.0), (2116, 0.005273158844801471), (2117, 0.0), (2118, 0.0), (2119, 0.0), (2120, 0.0), (2121, 0.0), (2122, 0.0), (2123, 0.0), (2124, 0.005757767059919408), (2125, 0.0), (2126, 0.009867555240786724), (2127, 0.0), (2128, 0.0), (2129, 0.018802090446634927), (2130, 0.0), (2131, 0.0), (2132, 0.0), (2133, 0.0), (2134, 0.0), (2135, 0.0), (2136, 0.0), (2137, 0.00651611016984089), (2138, 0.0), (2139, 0.010775165035850524), (2140, 0.0), (2141, 0.0), (2142, 0.0), (2143, 0.0), (2144, 0.0), (2145, 0.0), (2146, 0.009810158586214025), (2147, 0.009465436134026919), (2148, 0.011563468701874444), (2149, 0.0), (2150, 0.011840128696457715), (2151, 0.006216510807572469), (2152, 0.0), (2153, 0.0), (2154, 0.0), (2155, 0.0), (2156, 0.004643818556080035), (2157, 0.0), (2158, 0.0), (2159, 0.0), (2160, 0.00824346117964331), (2161, 0.0), (2162, 0.0), (2163, 0.013196504229718525), (2164, 0.0), (2165, 0.0), (2166, 0.0), (2167, 0.018682846435487715), (2168, 0.0), (2169, 0.0), (2170, 0.0), (2171, 0.0), (2172, 0.007980144475795124), (2173, 0.0), (2174, 0.0), (2175, 0.012051925880761236), (2176, 0.007053619662018794), (2177, 0.0), (2178, 0.003392651862650304), (2179, 0.010429994907306181), (2180, 0.0), (2181, 0.0), (2182, 0.0), (2183, 0.007328772997411325), (2184, 0.0), (2185, 0.0), (2186, 0.0), (2187, 0.0), (2188, 0.021843422134395003), (2189, 0.0077129906990642755), (2190, 0.011177148398687404), (2191, 0.014407135131107588), (2192, 0.0), (2193, 0.006379231453870931), (2194, 0.006061111392751756), (2195, 0.0), (2196, 0.0), (2197, 0.0), (2198, 0.0), (2199, 0.008621586226580305), (2200, 0.028130310989619742), (2201, 0.0), (2202, 0.0), (2203, 0.0), (2204, 0.0), (2205, 0.0), (2206, 0.0), (2207, 0.0), (2208, 0.0), (2209, 0.03230514023348792), (2210, 0.007033270731750586), (2211, 0.009300958973717206), (2212, 0.009266722884730242), (2213, 0.024952250417530887), (2214, 0.007013249237856822), (2215, 0.02080643162501402), (2216, 0.0), (2217, 0.0039618058100654345), (2218, 0.008502823897662982), (2219, 0.0), (2220, 0.0), (2221, 0.005031538510151806), (2222, 0.0), (2223, 0.026450784946702215), (2224, 0.008975592151988178), (2225, 0.0), (2226, 0.0), (2227, 0.0), (2228, 0.0), (2229, 0.0), (2230, 0.0), (2231, 0.0), (2232, 0.0), (2233, 0.0), (2234, 0.0), (2235, 0.0), (2236, 0.0), (2237, 0.0), (2238, 0.012332093182878891), (2239, 0.047780390419612746), (2240, 0.0), (2241, 0.0), (2242, 0.007967804052808591), (2243, 0.0), (2244, 0.0), (2245, 0.0), (2246, 0.005496029320543659), (2247, 0.0), (2248, 0.0), (2249, 0.0), (2250, 0.0), (2251, 0.0), (2252, 0.0), (2253, 0.0), (2254, 0.0), (2255, 0.009096849527862707), (2256, 0.0), (2257, 0.008836429290698113), (2258, 0.0), (2259, 0.0), (2260, 0.0), (2261, 0.0), (2262, 0.0), (2263, 0.030599836502333375), (2264, 0.01684411437675714), (2265, 0.004152587063998201), (2266, 0.0), (2267, 0.008966552407927571), (2268, 0.0), (2269, 0.0), (2270, 0.003899578497613767), (2271, 0.004601699646872485), (2272, 0.0), (2273, 0.0), (2274, 0.0), (2275, 0.0), (2276, 0.0), (2277, 0.0), (2278, 0.0), (2279, 0.0), (2280, 0.0), (2281, 0.0), (2282, 0.0), (2283, 0.0), (2284, 0.0), (2285, 0.0), (2286, 0.0), (2287, 0.0), (2288, 0.0), (2289, 0.010636612683414903), (2290, 0.009332039543581057), (2291, 0.0), (2292, 0.007090082672804298), (2293, 0.0), (2294, 0.0), (2295, 0.0), (2296, 0.016579032404088073), (2297, 0.013342136762637057), (2298, 0.00637820972940698), (2299, 0.007904612056306303), (2300, 0.0), (2301, 0.0), (2302, 0.0), (2303, 0.0), (2304, 0.0), (2305, 0.0072734502721952315), (2306, 0.0), (2307, 0.0), (2308, 0.009031839527171834), (2309, 0.02501228382788036), (2310, 0.0), (2311, 0.006774424580200782), (2312, 0.04590321001998637), (2313, 0.0), (2314, 0.012525677864579924), (2315, 0.0), (2316, 0.0), (2317, 0.03326900245016859), (2318, 0.009046102762100793), (2319, 0.02966705260460522), (2320, 0.014987675674795916), (2321, 0.006147594443754179), (2322, 0.0), (2323, 0.0), (2324, 0.0), (2325, 0.0), (2326, 0.017715399165542944), (2327, 0.0), (2328, 0.0), (2329, 0.0), (2330, 0.0), (2331, 0.0), (2332, 0.0), (2333, 0.0), (2334, 0.004911323079697703), (2335, 0.0), (2336, 0.0), (2337, 0.00810361544391826), (2338, 0.0), (2339, 0.0), (2340, 0.0), (2341, 0.006184969960728809), (2342, 0.0), (2343, 0.0), (2344, 0.0), (2345, 0.009331871198563524), (2346, 0.009158538991766257), (2347, 0.060294998631532634), (2348, 0.0), (2349, 0.008584726831788918), (2350, 0.0), (2351, 0.007346172932841923), (2352, 0.0), (2353, 0.007984432481537703), (2354, 0.0), (2355, 0.0), (2356, 0.0), (2357, 0.0), (2358, 0.006376577970236017), (2359, 0.006442780392502726), (2360, 0.0), (2361, 0.0), (2362, 0.0), (2363, 0.0), (2364, 0.0), (2365, 0.006935781601976215), (2366, 0.0), (2367, 0.0), (2368, 0.0), (2369, 0.006024897514420538), (2370, 0.0), (2371, 0.00353291355152895), (2372, 0.011318729524152011), (2373, 0.02734528914751876), (2374, 0.0), (2375, 0.004387108211071946), (2376, 0.008885753527489116), (2377, 0.0), (2378, 0.0), (2379, 0.00484145007611151), (2380, 0.006756290925229068), (2381, 0.0), (2382, 0.0), (2383, 0.0059290437200938614), (2384, 0.0), (2385, 0.0), (2386, 0.0), (2387, 0.0), (2388, 0.0), (2389, 0.005748126722757461), (2390, 0.0), (2391, 0.0), (2392, 0.0), (2393, 0.010389693929364079), (2394, 0.0), (2395, 0.0), (2396, 0.0), (2397, 0.004673571541286747), (2398, 0.0), (2399, 0.008878040473984225), (2400, 0.0), (2401, 0.0), (2402, 0.0), (2403, 0.0), (2404, 0.0), (2405, 0.0), (2406, 0.0), (2407, 0.0), (2408, 0.0), (2409, 0.0), (2410, 0.0), (2411, 0.006517515163655668), (2412, 0.0), (2413, 0.0), (2414, 0.0), (2415, 0.006825757091113645), (2416, 0.019049586411597156), (2417, 0.0), (2418, 0.0), (2419, 0.0), (2420, 0.013738669759004736), (2421, 0.0), (2422, 0.0), (2423, 0.0), (2424, 0.0), (2425, 0.012437747914194051), (2426, 0.0), (2427, 0.0), (2428, 0.0), (2429, 0.0), (2430, 0.0), (2431, 0.0), (2432, 0.023949975579054886), (2433, 0.0), (2434, 0.0), (2435, 0.0), (2436, 0.0), (2437, 0.013124235284024014), (2438, 0.0), (2439, 0.008080581338748997), (2440, 0.0), (2441, 0.013546521476861178), (2442, 0.0), (2443, 0.011503004283445984), (2444, 0.0), (2445, 0.005940623934216363), (2446, 0.0), (2447, 0.0), (2448, 0.0), (2449, 0.0), (2450, 0.0), (2451, 0.0), (2452, 0.0), (2453, 0.0), (2454, 0.0), (2455, 0.0), (2456, 0.005856570998576544), (2457, 0.015985095711392526), (2458, 0.035176030278638214), (2459, 0.0), (2460, 0.024330296524584155), (2461, 0.0), (2462, 0.0), (2463, 0.01320203992706862), (2464, 0.015827346584241616), (2465, 0.022335967333187528), (2466, 0.0), (2467, 0.014586190172716224), (2468, 0.0), (2469, 0.0), (2470, 0.00873440886228914), (2471, 0.0), (2472, 0.0), (2473, 0.0), (2474, 0.0), (2475, 0.008223341952591242), (2476, 0.0), (2477, 0.0), (2478, 0.0), (2479, 0.0), (2480, 0.0), (2481, 0.0), (2482, 0.005119162676645514), (2483, 0.0), (2484, 0.0), (2485, 0.0), (2486, 0.02928471513776311), (2487, 0.006809591934478753), (2488, 0.035781422779649096), (2489, 0.0), (2490, 0.0), (2491, 0.0), (2492, 0.0), (2493, 0.0), (2494, 0.005924782300667394), (2495, 0.0), (2496, 0.014537738670259648), (2497, 0.015513307766738356), (2498, 0.0), (2499, 0.0), (2500, 0.0), (2501, 0.0), (2502, 0.011577729933573897), (2503, 0.0), (2504, 0.0), (2505, 0.02310059204562111), (2506, 0.0), (2507, 0.010281993413538125), (2508, 0.0), (2509, 0.008219463005668047), (2510, 0.008138316632241713), (2511, 0.0), (2512, 0.011025984339411137), (2513, 0.01059828880204496), (2514, 0.0), (2515, 0.0), (2516, 0.0), (2517, 0.0), (2518, 0.0), (2519, 0.0), (2520, 0.006937684521332948), (2521, 0.0), (2522, 0.0), (2523, 0.006637001666154812), (2524, 0.0), (2525, 0.0), (2526, 0.011716938057874037), (2527, 0.017743768315407183), (2528, 0.004656713323850006), (2529, 0.01413890711445427), (2530, 0.0), (2531, 0.0), (2532, 0.005188868336316064), (2533, 0.0), (2534, 0.0), (2535, 0.0), (2536, 0.0), (2537, 0.0), (2538, 0.004398300917890288), (2539, 0.0138324566663505), (2540, 0.0), (2541, 0.0), (2542, 0.0), (2543, 0.019405872943719264), (2544, 0.0), (2545, 0.0), (2546, 0.0), (2547, 0.009542625700791637), (2548, 0.03362495929795323), (2549, 0.041629718772970746), (2550, 0.0), (2551, 0.06541532509609614), (2552, 0.049221093951288604), (2553, 0.06795390810632497), (2554, 0.0), (2555, 0.0), (2556, 0.012032558613813865), (2557, 0.004550814174134015), (2558, 0.0), (2559, 0.0), (2560, 0.0073868240764874684), (2561, 0.0), (2562, 0.0), (2563, 0.0), (2564, 0.006633128571661469), (2565, 0.003961232232349236), (2566, 0.006659200631061852), (2567, 0.0), (2568, 0.0), (2569, 0.0), (2570, 0.0), (2571, 0.0), (2572, 0.0), (2573, 0.0), (2574, 0.0), (2575, 0.006173285954991821), (2576, 0.0), (2577, 0.0), (2578, 0.0), (2579, 0.0), (2580, 0.0), (2581, 0.0), (2582, 0.0), (2583, 0.022266878422479146), (2584, 0.01659687218755994), (2585, 0.01503331286970673), (2586, 0.0), (2587, 0.026426163592699507), (2588, 0.0), (2589, 0.012408008720611532), (2590, 0.0), (2591, 0.008651713803651052), (2592, 0.0), (2593, 0.0), (2594, 0.006428073168545911), (2595, 0.011194713105533136), (2596, 0.0), (2597, 0.004562554470402003), (2598, 0.027972754613240527), (2599, 0.0), (2600, 0.0), (2601, 0.0), (2602, 0.013467272878474379), (2603, 0.004391474043134215), (2604, 0.005995791854428744), (2605, 0.0), (2606, 0.0), (2607, 0.0), (2608, 0.0), (2609, 0.0), (2610, 0.0035548599793437615), (2611, 0.0), (2612, 0.020865958644728795), (2613, 0.005128130894940209), (2614, 0.0), (2615, 0.04012955945871065), (2616, 0.0), (2617, 0.007479844663314732), (2618, 0.004649869676002422), (2619, 0.0), (2620, 0.0), (2621, 0.0), (2622, 0.0), (2623, 0.02304107629812137), (2624, 0.0), (2625, 0.0), (2626, 0.008617868039253067), (2627, 0.017138589122315126), (2628, 0.007847433399653898), (2629, 0.0), (2630, 0.012971341627121803), (2631, 0.04495911726888441), (2632, 0.0), (2633, 0.0), (2634, 0.0), (2635, 0.0), (2636, 0.005289233438701245), (2637, 0.011106411650426744), (2638, 0.001755195872660516), (2639, 0.0), (2640, 0.0), (2641, 0.006959652666693826), (2642, 0.0), (2643, 0.004313776943376451), (2644, 0.017948057275266684), (2645, 0.0), (2646, 0.0), (2647, 0.007813236885385476), (2648, 0.0), (2649, 0.0), (2650, 0.0), (2651, 0.0), (2652, 0.0), (2653, 0.0), (2654, 0.00949368013426538), (2655, 0.0), (2656, 0.0), (2657, 0.0), (2658, 0.0), (2659, 0.0), (2660, 0.0), (2661, 0.0), (2662, 0.0), (2663, 0.0), (2664, 0.0), (2665, 0.0), (2666, 0.0), (2667, 0.019724934245307343), (2668, 0.0), (2669, 0.0), (2670, 0.004309225897572107), (2671, 0.0), (2672, 0.0), (2673, 0.0), (2674, 0.0), (2675, 0.0), (2676, 0.0), (2677, 0.0), (2678, 0.0), (2679, 0.0), (2680, 0.0), (2681, 0.0), (2682, 0.0), (2683, 0.005073941871673406), (2684, 0.0), (2685, 0.0), (2686, 0.0), (2687, 0.0066248476505824695), (2688, 0.006652291375703643), (2689, 0.0), (2690, 0.0), (2691, 0.0), (2692, 0.0), (2693, 0.0), (2694, 0.004905174488579673), (2695, 0.0), (2696, 0.0), (2697, 0.0), (2698, 0.006256459659069577), (2699, 0.008786155046840298), (2700, 0.0), (2701, 0.009881684882413505), (2702, 0.0), (2703, 0.0), (2704, 0.0), (2705, 0.0), (2706, 0.0), (2707, 0.0), (2708, 0.0), (2709, 0.0), (2710, 0.0), (2711, 0.0), (2712, 0.010045180464081411), (2713, 0.003142186690299459), (2714, 0.0), (2715, 0.011929320549619466), (2716, 0.012971452779988787), (2717, 0.005493106392921144), (2718, 0.0), (2719, 0.0), (2720, 0.0), (2721, 0.0), (2722, 0.0), (2723, 0.014474680955350941), (2724, 0.0), (2725, 0.0), (2726, 0.014435254426761893), (2727, 0.004944362789393175), (2728, 0.0), (2729, 0.009872828302890392), (2730, 0.01816848045072999), (2731, 0.016839949475275607), (2732, 0.0), (2733, 0.0), (2734, 0.0), (2735, 0.0), (2736, 0.02383981735460432), (2737, 0.0), (2738, 0.0), (2739, 0.0), (2740, 0.0), (2741, 0.0), (2742, 0.0), (2743, 0.017160465497729798), (2744, 0.004430214270395812), (2745, 0.0), (2746, 0.0), (2747, 0.0), (2748, 0.0), (2749, 0.0), (2750, 0.0), (2751, 0.0), (2752, 0.0), (2753, 0.0), (2754, 0.0), (2755, 0.0), (2756, 0.0), (2757, 0.0), (2758, 0.0), (2759, 0.0), (2760, 0.008853443676328402), (2761, 0.0), (2762, 0.0), (2763, 0.0), (2764, 0.0), (2765, 0.0), (2766, 0.0), (2767, 0.0), (2768, 0.007304728137775272), (2769, 0.0), (2770, 0.0), (2771, 0.03653843573450408), (2772, 0.0), (2773, 0.024641707611562785), (2774, 0.0), (2775, 0.0), (2776, 0.0), (2777, 0.01896888787428283), (2778, 0.0049688985138716035), (2779, 0.0), (2780, 0.0), (2781, 0.00523780749547895), (2782, 0.0), (2783, 0.0), (2784, 0.0), (2785, 0.0), (2786, 0.0), (2787, 0.0), (2788, 0.009023285100567519), (2789, 0.006876456027460586), (2790, 0.007238811111307489), (2791, 0.011589722728762875), (2792, 0.0), (2793, 0.0), (2794, 0.007002948447293258), (2795, 0.008083370000555841), (2796, 0.0), (2797, 0.0), (2798, 0.0), (2799, 0.0), (2800, 0.009847005637804282), (2801, 0.0), (2802, 0.0), (2803, 0.011044415114858359), (2804, 0.0), (2805, 0.0), (2806, 0.0), (2807, 0.031493917440462024), (2808, 0.0), (2809, 0.0), (2810, 0.005031197618244999), (2811, 0.013817790904797424), (2812, 0.0), (2813, 0.029847393504972366), (2814, 0.0), (2815, 0.0), (2816, 0.01787143516514499), (2817, 0.009747482342166765), (2818, 0.0), (2819, 0.0), (2820, 0.0), (2821, 0.004187001166308433), (2822, 0.0), (2823, 0.0), (2824, 0.0), (2825, 0.0), (2826, 0.02208657418039337), (2827, 0.008145184638962149), (2828, 0.003036217505697796), (2829, 0.0), (2830, 0.0), (2831, 0.0), (2832, 0.0), (2833, 0.004709632123014222), (2834, 0.002665623091686762), (2835, 0.01186329893410005), (2836, 0.024451731505438685), (2837, 0.0), (2838, 0.03870551474056575), (2839, 0.007911452076306008), (2840, 0.0), (2841, 0.0), (2842, 0.0059519487959520875), (2843, 0.0), (2844, 0.0), (2845, 0.0), (2846, 0.006026601600728128), (2847, 0.0), (2848, 0.0), (2849, 0.0), (2850, 0.0), (2851, 0.0), (2852, 0.0), (2853, 0.0), (2854, 0.0), (2855, 0.0), (2856, 0.0), (2857, 0.04483461077354938), (2858, 0.0), (2859, 0.0), (2860, 0.0), (2861, 0.004977621464389993), (2862, 0.0), (2863, 0.023552345817091563), (2864, 0.003585217335965788), (2865, 0.0), (2866, 0.0), (2867, 0.0), (2868, 0.0), (2869, 0.0), (2870, 0.0), (2871, 0.022661171746615923), (2872, 0.0), (2873, 0.005893084133725098), (2874, 0.0), (2875, 0.013164832477066723), (2876, 0.0), (2877, 0.007862796913391165), (2878, 0.0), (2879, 0.0), (2880, 0.0), (2881, 0.0), (2882, 0.0), (2883, 0.0), (2884, 0.0), (2885, 0.0), (2886, 0.0), (2887, 0.0), (2888, 0.0), (2889, 0.0), (2890, 0.01337331217322446), (2891, 0.02317541105318229), (2892, 0.0), (2893, 0.0), (2894, 0.012779519683154127), (2895, 0.0), (2896, 0.0), (2897, 0.0), (2898, 0.0), (2899, 0.0), (2900, 0.0), (2901, 0.0), (2902, 0.0), (2903, 0.0), (2904, 0.0), (2905, 0.0), (2906, 0.0), (2907, 0.02852985272436582), (2908, 0.0), (2909, 0.0), (2910, 0.0), (2911, 0.0029699992485701845), (2912, 0.0), (2913, 0.0), (2914, 0.028384192149879677), (2915, 0.0), (2916, 0.0), (2917, 0.0), (2918, 0.0), (2919, 0.0), (2920, 0.0), (2921, 0.0), (2922, 0.002706565127816573), (2923, 0.0), (2924, 0.019523167929668538), (2925, 0.0), (2926, 0.0), (2927, 0.0), (2928, 0.011838115607852012), (2929, 0.0), (2930, 0.0), (2931, 0.002481559639464395), (2932, 0.0), (2933, 0.00928184833074472), (2934, 0.0), (2935, 0.0), (2936, 0.014528405190654304), (2937, 0.0), (2938, 0.0), (2939, 0.0), (2940, 0.0), (2941, 0.0), (2942, 0.0), (2943, 0.017538301269544067), (2944, 0.03237115703973043), (2945, 0.012316362067424863), (2946, 0.026532503489824083), (2947, 0.0), (2948, 0.019374263638311608), (2949, 0.0), (2950, 0.0), (2951, 0.0), (2952, 0.0), (2953, 0.007975137376441024), (2954, 0.0), (2955, 0.027833589742993024), (2956, 0.0), (2957, 0.005628613058988631), (2958, 0.0), (2959, 0.0), (2960, 0.0), (2961, 0.0), (2962, 0.0), (2963, 0.02555149444246052), (2964, 0.0), (2965, 0.00594925906992893), (2966, 0.0030227181466738555), (2967, 0.0), (2968, 0.0), (2969, 0.0), (2970, 0.0), (2971, 0.0), (2972, 0.007601736877144491), (2973, 0.0), (2974, 0.0), (2975, 0.012089431410877255), (2976, 0.0), (2977, 0.0), (2978, 0.0), (2979, 0.0), (2980, 0.0), (2981, 0.001840531405044195), (2982, 0.0), (2983, 0.00424349503272339), (2984, 0.00731918119955133), (2985, 0.0), (2986, 0.0), (2987, 0.0), (2988, 0.004305429635781475), (2989, 0.0), (2990, 0.0), (2991, 0.0), (2992, 0.0), (2993, 0.0), (2994, 0.0), (2995, 0.0055683781314340665), (2996, 0.006702303775131487), (2997, 0.0), (2998, 0.027770480955392588), (2999, 0.0), (3000, 0.00688392002604973), (3001, 0.0), (3002, 0.0), (3003, 0.016125512158369822), (3004, 0.0), (3005, 0.02194758580342411), (3006, 0.003861674251647066), (3007, 0.0), (3008, 0.0), (3009, 0.0), (3010, 0.0), (3011, 0.0), (3012, 0.003084497860941989), (3013, 0.0), (3014, 0.0), (3015, 0.0), (3016, 0.006784732374838023), (3017, 0.0), (3018, 0.0), (3019, 0.009052058539894029), (3020, 0.0), (3021, 0.0), (3022, 0.011933958337796254), (3023, 0.0), (3024, 0.008490451311098242), (3025, 0.013992296846562587), (3026, 0.03132262537368433), (3027, 0.027320466591390702), (3028, 0.0), (3029, 0.005531472055598835), (3030, 0.013124125641825335), (3031, 0.0), (3032, 0.0), (3033, 0.0), (3034, 0.023093058631907762), (3035, 0.0), (3036, 0.0), (3037, 0.0), (3038, 0.0), (3039, 0.0), (3040, 0.00924730675845161), (3041, 0.0), (3042, 0.008165615730906878), (3043, 0.0), (3044, 0.005715923311021146), (3045, 0.0), (3046, 0.0), (3047, 0.010497598464783119), (3048, 0.010437352936736033), (3049, 0.0), (3050, 0.00608452416745403), (3051, 0.0), (3052, 0.011609177572171208), (3053, 0.0), (3054, 0.0), (3055, 0.0), (3056, 0.026506922661103674), (3057, 0.005643023131607258), (3058, 0.0), (3059, 0.0), (3060, 0.0), (3061, 0.008758632889027586), (3062, 0.013356997720468779), (3063, 0.020211750483814808), (3064, 0.0), (3065, 0.0), (3066, 0.0478597473190266), (3067, 0.0), (3068, 0.02878315960929751), (3069, 0.04059984080068052), (3070, 0.0), (3071, 0.027519398461626723), (3072, 0.0), (3073, 0.0), (3074, 0.021091452045192614), (3075, 0.0), (3076, 0.10763980156127986), (3077, 0.0), (3078, 0.008609076302723066), (3079, 0.0), (3080, 0.00378361222666776), (3081, 0.011671898519082902), (3082, 0.0), (3083, 0.0), (3084, 0.0), (3085, 0.02036019797436467), (3086, 0.008945747166060778), (3087, 0.0), (3088, 0.019888017445411344), (3089, 0.0), (3090, 0.0), (3091, 0.03500619448087695), (3092, 0.0), (3093, 0.0), (3094, 0.011141506926485446), (3095, 0.0), (3096, 0.0), (3097, 0.0), (3098, 0.0), (3099, 0.0), (3100, 0.005264841365682996), (3101, 0.0), (3102, 0.0), (3103, 0.060220595184710464), (3104, 0.0), (3105, 0.0), (3106, 0.0), (3107, 0.0), (3108, 0.0), (3109, 0.0), (3110, 0.018224993904374945), (3111, 0.006157991008573921), (3112, 0.0), (3113, 0.0), (3114, 0.009418606580124153), (3115, 0.04857444626870798), (3116, 0.0), (3117, 0.0), (3118, 0.0952227515187248), (3119, 0.012453107991380549), (3120, 0.022707090825572658), (3121, 0.0), (3122, 0.0), (3123, 0.0), (3124, 0.0), (3125, 0.0), (3126, 0.012081668174226672), (3127, 0.0), (3128, 0.0), (3129, 0.0), (3130, 0.0), (3131, 0.004880712714471268), (3132, 0.0), (3133, 0.0), (3134, 0.0), (3135, 0.017701675543693937), (3136, 0.0), (3137, 0.0025954376533902602), (3138, 0.005352400626829092), (3139, 0.0), (3140, 0.0), (3141, 0.010343294870889886), (3142, 0.01794553683517691), (3143, 0.021430179007025367), (3144, 0.011140306054322426), (3145, 0.0), (3146, 0.0), (3147, 0.0), (3148, 0.0), (3149, 0.0), (3150, 0.0), (3151, 0.0), (3152, 0.0), (3153, 0.004230093293408449), (3154, 0.0), (3155, 0.0), (3156, 0.0), (3157, 0.0), (3158, 0.025589925980847295), (3159, 0.0), (3160, 0.013557692134643258), (3161, 0.0), (3162, 0.0), (3163, 0.0), (3164, 0.005107118577424777), (3165, 0.006391225273228401), (3166, 0.004952842752355631), (3167, 0.006273353587011097), (3168, 0.0), (3169, 0.0), (3170, 0.0066537552390914904), (3171, 0.0017833804238267638), (3172, 0.0), (3173, 0.005669454511847114), (3174, 0.0), (3175, 0.01424235513652417), (3176, 0.02173934026802289), (3177, 0.02435517399761372), (3178, 0.007940175256215739), (3179, 0.0), (3180, 0.00759063720957983), (3181, 0.0), (3182, 0.0), (3183, 0.0), (3184, 0.0), (3185, 0.0), (3186, 0.0), (3187, 0.0), (3188, 0.0), (3189, 0.0), (3190, 0.0), (3191, 0.0), (3192, 0.0), (3193, 0.0), (3194, 0.0), (3195, 0.0), (3196, 0.0), (3197, 0.0), (3198, 0.0), (3199, 0.0), (3200, 0.0), (3201, 0.0), (3202, 0.01600912853910435), (3203, 0.010814016897955366), (3204, 0.006574366369108034), (3205, 0.0), (3206, 0.0), (3207, 0.0), (3208, 0.009969308491230587), (3209, 0.0), (3210, 0.0), (3211, 0.0), (3212, 0.00323944499778513), (3213, 0.006645624399908149), (3214, 0.0), (3215, 0.0), (3216, 0.0), (3217, 0.006376928860257513), (3218, 0.0), (3219, 0.014293378230883199), (3220, 0.016959885341260483), (3221, 0.0), (3222, 0.0), (3223, 0.00457977742866918), (3224, 0.0), (3225, 0.0), (3226, 0.0), (3227, 0.024865368979544982), (3228, 0.0), (3229, 0.0), (3230, 0.0), (3231, 0.0), (3232, 0.007491525865899479), (3233, 0.005801616360178517), (3234, 0.0), (3235, 0.0), (3236, 0.0), (3237, 0.0), (3238, 0.010377016437182071), (3239, 0.010557697472162626), (3240, 0.0), (3241, 0.0), (3242, 0.0), (3243, 0.011275991414692777), (3244, 0.005421462289915381), (3245, 0.0), (3246, 0.0), (3247, 0.0), (3248, 0.0), (3249, 0.0), (3250, 0.0), (3251, 0.0), (3252, 0.010228784145240043), (3253, 0.0), (3254, 0.0), (3255, 0.0022056152126281587), (3256, 0.0), (3257, 0.0), (3258, 0.0), (3259, 0.0), (3260, 0.0027660786055703694), (3261, 0.0), (3262, 0.0), (3263, 0.0), (3264, 0.0), (3265, 0.0), (3266, 0.0), (3267, 0.05453470237410196), (3268, 0.0028285622101481165), (3269, 0.0), (3270, 0.020882680209471125), (3271, 0.0), (3272, 0.002522564247046217), (3273, 0.0), (3274, 0.0), (3275, 0.00826940869842109), (3276, 0.011438216385215676), (3277, 0.0), (3278, 0.011333240272951335), (3279, 0.0), (3280, 0.00944780904494031), (3281, 0.0), (3282, 0.02859078354960595), (3283, 0.011182010755239223), (3284, 0.0), (3285, 0.004165631805568375), (3286, 0.0), (3287, 0.010285495606667474), (3288, 0.0), (3289, 0.0), (3290, 0.0), (3291, 0.012306421129509418), (3292, 0.0), (3293, 0.0), (3294, 0.0), (3295, 0.0), (3296, 0.0), (3297, 0.036941549043601744), (3298, 0.0), (3299, 0.019235208107874095), (3300, 0.0), (3301, 0.0365334713302607), (3302, 0.0), (3303, 0.0), (3304, 0.0), (3305, 0.0), (3306, 0.00880434909307739), (3307, 0.005960234730719359), (3308, 0.007727106639567123), (3309, 0.016769166515172202), (3310, 0.010881464659952862), (3311, 0.0), (3312, 0.027256769265435892), (3313, 0.014363505405793547), (3314, 0.0), (3315, 0.0), (3316, 0.0), (3317, 0.004090843533610707), (3318, 0.013615499233090689), (3319, 0.0), (3320, 0.0), (3321, 0.006534935631426872), (3322, 0.0), (3323, 0.015796269144883503), (3324, 0.0), (3325, 0.0), (3326, 0.011990682085550283), (3327, 0.0), (3328, 0.0), (3329, 0.0), (3330, 0.0), (3331, 0.0), (3332, 0.005493345329398335), (3333, 0.0), (3334, 0.0), (3335, 0.0), (3336, 0.0), (3337, 0.013229480313981924), (3338, 0.0), (3339, 0.0), (3340, 0.0), (3341, 0.0), (3342, 0.0), (3343, 0.0), (3344, 0.0), (3345, 0.0), (3346, 0.004163396518418111), (3347, 0.01214876165003617), (3348, 0.028604746744576137), (3349, 0.0), (3350, 0.0), (3351, 0.0), (3352, 0.0), (3353, 0.0), (3354, 0.0), (3355, 0.0), (3356, 0.0), (3357, 0.0), (3358, 0.01806744329754609), (3359, 0.01626667260831638), (3360, 0.0), (3361, 0.0), (3362, 0.0044715367123408884), (3363, 0.0), (3364, 0.0020820052536508877), (3365, 0.005070775354282441), (3366, 0.021475896321683605), (3367, 0.006259138417031815), (3368, 0.0), (3369, 0.006130195147668647), (3370, 0.0), (3371, 0.0), (3372, 0.0), (3373, 0.0), (3374, 0.011042205074047046), (3375, 0.0), (3376, 0.0), (3377, 0.006499807031434475), (3378, 0.0), (3379, 0.0), (3380, 0.0), (3381, 0.007068996360302499), (3382, 0.003551647506437266), (3383, 0.0), (3384, 0.0), (3385, 0.0), (3386, 0.0), (3387, 0.006679823113679939), (3388, 0.04328028997737088), (3389, 0.0), (3390, 0.015337775729582104), (3391, 0.0), (3392, 0.004254564756798868), (3393, 0.0), (3394, 0.04691724273427195), (3395, 0.0), (3396, 0.004348696761886653), (3397, 0.013191531008035134), (3398, 0.0), (3399, 0.03192659115833883), (3400, 0.0), (3401, 0.0), (3402, 0.009523904658666902), (3403, 0.0), (3404, 0.015983172325407195), (3405, 0.0), (3406, 0.0025326157948348587), (3407, 0.0), (3408, 0.0), (3409, 0.0), (3410, 0.0075731749417702315), (3411, 0.0), (3412, 0.013888263956722036), (3413, 0.0), (3414, 0.0), (3415, 0.0), (3416, 0.0), (3417, 0.0), (3418, 0.0), (3419, 0.0), (3420, 0.01605371839119335), (3421, 0.0052290901524357745), (3422, 0.005323100545167091), (3423, 0.0), (3424, 0.0), (3425, 0.0), (3426, 0.0), (3427, 0.0), (3428, 0.0), (3429, 0.0), (3430, 0.005250528495142436), (3431, 0.0), (3432, 0.0), (3433, 0.00831687124853109), (3434, 0.0), (3435, 0.0), (3436, 0.0), (3437, 0.013758670947466576), (3438, 0.004393471301220975), (3439, 0.0), (3440, 0.0), (3441, 0.0), (3442, 0.0), (3443, 0.0), (3444, 0.0), (3445, 0.0), (3446, 0.00543065447528999), (3447, 0.0), (3448, 0.0), (3449, 0.0), (3450, 0.0), (3451, 0.0), (3452, 0.007957493324464222), (3453, 0.0), (3454, 0.004814603441785771), (3455, 0.005237759038077736), (3456, 0.0), (3457, 0.006217145003597635), (3458, 0.0), (3459, 0.006060937323540666), (3460, 0.0), (3461, 0.0), (3462, 0.013718294927376013), (3463, 0.005104420114790629), (3464, 0.0), (3465, 0.004643690454510067), (3466, 0.0), (3467, 0.0), (3468, 0.00653453198459624), (3469, 0.007699253160845172), (3470, 0.0), (3471, 0.0), (3472, 0.0), (3473, 0.0), (3474, 0.004594320261322434), (3475, 0.0), (3476, 0.0032467855431949637), (3477, 0.0), (3478, 0.007162221964964581), (3479, 0.0), (3480, 0.0), (3481, 0.0), (3482, 0.0), (3483, 0.0), (3484, 0.0), (3485, 0.0), (3486, 0.0), (3487, 0.0), (3488, 0.0), (3489, 0.0), (3490, 0.0), (3491, 0.0), (3492, 0.008754455975731315), (3493, 0.0), (3494, 0.0), (3495, 0.0), (3496, 0.0), (3497, 0.005770301589406275), (3498, 0.010203951080607789), (3499, 0.018059865337752987), (3500, 0.0), (3501, 0.006851558881632239), (3502, 0.014765030075301782), (3503, 0.0), (3504, 0.03597443438977351), (3505, 0.02832837746180512), (3506, 0.0), (3507, 0.0), (3508, 0.0), (3509, 0.01733914292561611), (3510, 0.011928974876642448), (3511, 0.0), (3512, 0.0), (3513, 0.0), (3514, 0.0), (3515, 0.0), (3516, 0.0), (3517, 0.0), (3518, 0.0), (3519, 0.0), (3520, 0.0), (3521, 0.021094356228708696), (3522, 0.0), (3523, 0.0), (3524, 0.007257968085938706), (3525, 0.006540132529685044), (3526, 0.005872520812936214), (3527, 0.0), (3528, 0.0), (3529, 0.014043828851878812), (3530, 0.005685099566993676), (3531, 0.0), (3532, 0.0066016052462294665), (3533, 0.10130248189765484), (3534, 0.0), (3535, 0.0), (3536, 0.0), (3537, 0.0), (3538, 0.015593824691896878), (3539, 0.0), (3540, 0.0034451495342535643), (3541, 0.0), (3542, 0.0043958505428409265), (3543, 0.0), (3544, 0.0), (3545, 0.0), (3546, 0.0), (3547, 0.007668872455880683), (3548, 0.0), (3549, 0.0), (3550, 0.0), (3551, 0.0), (3552, 0.008789198241257706), (3553, 0.0), (3554, 0.0), (3555, 0.0), (3556, 0.007404031263402231), (3557, 0.003616515596375869), (3558, 0.007981709277811442), (3559, 0.0), (3560, 0.01772884483662181), (3561, 0.0), (3562, 0.0), (3563, 0.005736739619087637), (3564, 0.0), (3565, 0.0), (3566, 0.01800876813279404), (3567, 0.0), (3568, 0.0), (3569, 0.0), (3570, 0.00728143965655109), (3571, 0.013932114732608131), (3572, 0.007087627662106192), (3573, 0.008279430117287457), (3574, 0.012675796187581582), (3575, 0.0), (3576, 0.01714898254083957), (3577, 0.0), (3578, 0.013473218402160536), (3579, 0.0), (3580, 0.0), (3581, 0.0), (3582, 0.0), (3583, 0.0), (3584, 0.011869685586015845), (3585, 0.0), (3586, 0.0), (3587, 0.0), (3588, 0.0), (3589, 0.0), (3590, 0.008129685257829668), (3591, 0.022246993502573455), (3592, 0.0), (3593, 0.0), (3594, 0.0), (3595, 0.0), (3596, 0.022851454481433917), (3597, 0.0), (3598, 0.031449819021363075), (3599, 0.0), (3600, 0.005411922010125253), (3601, 0.0), (3602, 0.0), (3603, 0.0), (3604, 0.009587830509403542), (3605, 0.0), (3606, 0.013155436119936123), (3607, 0.0318187344398109), (3608, 0.0), (3609, 0.0), (3610, 0.0), (3611, 0.0), (3612, 0.007406683359540086), (3613, 0.032751094824775825), (3614, 0.0), (3615, 0.013751121200309687), (3616, 0.0), (3617, 0.0), (3618, 0.0), (3619, 0.0022392625689127447), (3620, 0.02622551101770489), (3621, 0.0), (3622, 0.018980005861409438), (3623, 0.0), (3624, 0.0), (3625, 0.0), (3626, 0.0), (3627, 0.012284167706312769), (3628, 0.06861253545163931), (3629, 0.01965952652762427), (3630, 0.0), (3631, 0.0), (3632, 0.0), (3633, 0.0814412634666697), (3634, 0.0), (3635, 0.01681835405748327), (3636, 0.0), (3637, 0.0), (3638, 0.0), (3639, 0.003625589501314143), (3640, 0.005378336425376502), (3641, 0.017082445816003097), (3642, 0.0), (3643, 0.0), (3644, 0.007988606538458587), (3645, 0.015520831118747934), (3646, 0.0), (3647, 0.029700437664693158), (3648, 0.021885498738519995), (3649, 0.0), (3650, 0.003688193147253932), (3651, 0.0), (3652, 0.006997833518516331), (3653, 0.0), (3654, 0.009712985410183918), (3655, 0.012961363933707531), (3656, 0.0064478076131371555), (3657, 0.0), (3658, 0.01157478701000809), (3659, 0.025312030203023993), (3660, 0.02337062425859058), (3661, 0.0), (3662, 0.020295452065689914), (3663, 0.0), (3664, 0.0), (3665, 0.0), (3666, 0.0), (3667, 0.0), (3668, 0.0), (3669, 0.0), (3670, 0.0), (3671, 0.0), (3672, 0.007868640210639198), (3673, 0.007889022478467149), (3674, 0.0), (3675, 0.006735691976550681), (3676, 0.0), (3677, 0.005233611260727761), (3678, 0.0), (3679, 0.0063826500245668565), (3680, 0.0), (3681, 0.0), (3682, 0.0), (3683, 0.0), (3684, 0.0), (3685, 0.0), (3686, 0.0), (3687, 0.0), (3688, 0.0), (3689, 0.0), (3690, 0.007272972818992461), (3691, 0.0), (3692, 0.0), (3693, 0.0), (3694, 0.0), (3695, 0.009935577576123327), (3696, 0.0047092594093090575), (3697, 0.007690814859428713), (3698, 0.0), (3699, 0.008920035635022229), (3700, 0.0178067809246961), (3701, 0.0), (3702, 0.005986444915142141), (3703, 0.0), (3704, 0.0), (3705, 0.0), (3706, 0.0), (3707, 0.0038980595274585345), (3708, 0.01087007161807628), (3709, 0.0), (3710, 0.004024815467145378), (3711, 0.0), (3712, 0.0), (3713, 0.0), (3714, 0.0), (3715, 0.016861489764272732), (3716, 0.032357844250522315), (3717, 0.006785247209388724), (3718, 0.0), (3719, 0.0), (3720, 0.021568390784225597), (3721, 0.00911211491979131), (3722, 0.0), (3723, 0.01383905126489091), (3724, 0.0), (3725, 0.0), (3726, 0.023849695115682742), (3727, 0.005510709191823654), (3728, 0.005604273102531961), (3729, 0.0), (3730, 0.004814741566388471), (3731, 0.0), (3732, 0.0), (3733, 0.0), (3734, 0.0), (3735, 0.0033910056560387454), (3736, 0.0), (3737, 0.0), (3738, 0.0), (3739, 0.004026334692772596), (3740, 0.0), (3741, 0.0), (3742, 0.0), (3743, 0.0), (3744, 0.0), (3745, 0.022256389091386088), (3746, 0.0), (3747, 0.0), (3748, 0.0), (3749, 0.0), (3750, 0.0), (3751, 0.0042832414523950105), (3752, 0.009594947693099239), (3753, 0.0), (3754, 0.0), (3755, 0.0), (3756, 0.006735104489438264), (3757, 0.0), (3758, 0.0), (3759, 0.0), (3760, 0.006019227546214393), (3761, 0.0), (3762, 0.007270706660505909), (3763, 0.0), (3764, 0.009086463014583082), (3765, 0.004064131415050752), (3766, 0.0), (3767, 0.0), (3768, 0.0), (3769, 0.0), (3770, 0.0), (3771, 0.0), (3772, 0.0), (3773, 0.0), (3774, 0.0), (3775, 0.0), (3776, 0.0), (3777, 0.0), (3778, 0.0), (3779, 0.006910963133148088), (3780, 0.0), (3781, 0.0), (3782, 0.012785781298422495), (3783, 0.009718106143151509), (3784, 0.0), (3785, 0.0), (3786, 0.0), (3787, 0.004438372777542669), (3788, 0.0), (3789, 0.021469972779968458), (3790, 0.0), (3791, 0.0), (3792, 0.0), (3793, 0.0), (3794, 0.0), (3795, 0.004136242790213739), (3796, 0.0), (3797, 0.0), (3798, 0.0), (3799, 0.0), (3800, 0.0), (3801, 0.006496589803483196), (3802, 0.0), (3803, 0.0), (3804, 0.0), (3805, 0.0), (3806, 0.0), (3807, 0.0), (3808, 0.007358651467457267), (3809, 0.006147045185907463), (3810, 0.0), (3811, 0.007250969101226661), (3812, 0.0), (3813, 0.0), (3814, 0.0032149473907238384), (3815, 0.0078009877450628705), (3816, 0.0), (3817, 0.0023575078962899346), (3818, 0.0), (3819, 0.015375968271394442), (3820, 0.0), (3821, 0.006190107527873686), (3822, 0.0), (3823, 0.0), (3824, 0.013953480717317406), (3825, 0.0), (3826, 0.0), (3827, 0.0), (3828, 0.0), (3829, 0.0), (3830, 0.0), (3831, 0.005700986082912674), (3832, 0.0), (3833, 0.0), (3834, 0.004871919147505589), (3835, 0.005105780628896109), (3836, 0.0059358726971128475), (3837, 0.0), (3838, 0.0057199184308556585), (3839, 0.023005399696851194), (3840, 0.006996559890664683), (3841, 0.0), (3842, 0.0), (3843, 0.0), (3844, 0.005963418912896226), (3845, 0.0), (3846, 0.0), (3847, 0.0), (3848, 0.0), (3849, 0.0), (3850, 0.0), (3851, 0.005628669379331535), (3852, 0.0), (3853, 0.0), (3854, 0.0), (3855, 0.004258618898589179), (3856, 0.010302430426794048), (3857, 0.0), (3858, 0.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Description of the Code\n",
        "\n",
        "We sort the similarity scores and find the top-k most similar movies to Star Wars\n",
        "\n",
        "1. **Sorting the Similarity Scores**:\n",
        "   - **`similarity_scores`**: The list of movie-similarity score pairs is sorted in descending order based on the similarity score. This is done using Python's `sorted()` function, where the `key` argument is a lambda function that extracts the similarity score (the second element in each tuple) to sort by.\n",
        "\n",
        "2. **Displaying Sorted Similarity Scores**:\n",
        "   - The sorted list is printed, showing the movie IDs along with their cosine similarity scores, with the most similar movies appearing first.\n"
      ],
      "metadata": {
        "id": "ObAJC_f1JmYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we are interested in the most similar movies, we sort\n",
        "# Sort by similarity score in descending order\n",
        "similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
        "print('Movie-similarity score pairs (sorted)')\n",
        "print(similarity_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQts_Ej0BE0c",
        "outputId": "f7f8e87a-bb97-4450-a1c4-5d6bdf6dca40"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Movie-similarity score pairs (sorted)\n",
            "[(257, 0.9999999999999999), (1184, 0.4726571038951565), (1171, 0.4335392852988003), (865, 0.12776183015002765), (3076, 0.10763980156127986), (3533, 0.10130248189765484), (3118, 0.0952227515187248), (2012, 0.08853496379109525), (1342, 0.08412621888340621), (574, 0.08321747918144712), (3633, 0.0814412634666697), (941, 0.08127429536911791), (1248, 0.07953463431301931), (1766, 0.07012974824437315), (462, 0.06934650192307547), (3628, 0.06861253545163931), (2553, 0.06795390810632497), (255, 0.06712046678403279), (2551, 0.06541532509609614), (228, 0.06032442937679674), (2347, 0.060294998631532634), (3103, 0.060220595184710464), (899, 0.05937161781971309), (3267, 0.05453470237410196), (2552, 0.049221093951288604), (3115, 0.04857444626870798), (1339, 0.04838283309302201), (3066, 0.0478597473190266), (2239, 0.047780390419612746), (2100, 0.047733350277797265), (1601, 0.04746997295787472), (3394, 0.04691724273427195), (582, 0.04640025589284035), (506, 0.046245407387482784), (2312, 0.04590321001998637), (2631, 0.04495911726888441), (2857, 0.04483461077354938), (1528, 0.04345899938090852), (3388, 0.04328028997737088), (1175, 0.043192960065587885), (900, 0.04195910563370074), (2549, 0.041629718772970746), (2059, 0.04128639855564124), (3069, 0.04059984080068052), (108, 0.04055364647476116), (2615, 0.04012955945871065), (1197, 0.03896545835598053), (1172, 0.03877990992127391), (2838, 0.03870551474056575), (639, 0.03838266340042399), (588, 0.037832752003878964), (325, 0.03768084334267056), (3297, 0.036941549043601744), (171, 0.03662723785033928), (2771, 0.03653843573450408), (3301, 0.0365334713302607), (1435, 0.0364483886542064), (550, 0.03609685450163774), (3504, 0.03597443438977351), (2488, 0.035781422779649096), (852, 0.03556066936660281), (1044, 0.035345962606676995), (2458, 0.035176030278638214), (3091, 0.03500619448087695), (382, 0.03498125912275193), (182, 0.03427389462234283), (89, 0.034103807051222304), (1017, 0.03375581773829743), (2548, 0.03362495929795323), (144, 0.03358299439648683), (2317, 0.03326900245016859), (975, 0.03319871942601911), (487, 0.03300883621493249), (259, 0.03282804338151579), (3613, 0.032751094824775825), (1686, 0.03272567462820667), (1555, 0.0326610746253405), (242, 0.032491753951403746), (2944, 0.03237115703973043), (3716, 0.032357844250522315), (2209, 0.03230514023348792), (898, 0.032140923948720965), (196, 0.03196190259031823), (3399, 0.03192659115833883), (3607, 0.0318187344398109), (2807, 0.031493917440462024), (3598, 0.031449819021363075), (677, 0.03140133039531247), (3026, 0.03132262537368433), (310, 0.03116223171264484), (1301, 0.030918154741722423), (2110, 0.030685067080327262), (1016, 0.030646626774665574), (2263, 0.030599836502333375), (1466, 0.03035418182213344), (319, 0.029962167575930183), (2813, 0.029847393504972366), (3647, 0.029700437664693158), (2319, 0.02966705260460522), (2008, 0.029566331833328255), (1535, 0.0294625443880471), (1662, 0.02935122613537266), (2486, 0.02928471513776311), (3068, 0.02878315960929751), (2001, 0.028774112041316146), (1065, 0.028749909115346473), (3348, 0.028604746744576137), (3282, 0.02859078354960595), (2907, 0.02852985272436582), (2914, 0.028384192149879677), (3505, 0.02832837746180512), (1398, 0.02825396405680565), (2200, 0.028130310989619742), (2598, 0.027972754613240527), (2955, 0.027833589742993024), (2998, 0.027770480955392588), (3071, 0.027519398461626723), (1476, 0.02744080645953486), (2373, 0.02734528914751876), (3027, 0.027320466591390702), (1214, 0.027264506109820476), (3312, 0.027256769265435892), (664, 0.026942642119014266), (2098, 0.026896487770479236), (1860, 0.02685610701880966), (568, 0.02679219714067607), (2946, 0.026532503489824083), (3056, 0.026506922661103674), (2223, 0.026450784946702215), (2587, 0.026426163592699507), (2006, 0.026307377918065627), (680, 0.02626088355505017), (2068, 0.0262392459601609), (3620, 0.02622551101770489), (75, 0.025854895666663352), (3158, 0.025589925980847295), (2963, 0.02555149444246052), (642, 0.025502261470470695), (2111, 0.025349714051174543), (3659, 0.025312030203023993), (1097, 0.02527070720523414), (1192, 0.02518306313351727), (1884, 0.025041911094168916), (2309, 0.02501228382788036), (2213, 0.024952250417530887), (1955, 0.024937069320020353), (3227, 0.024865368979544982), (2773, 0.024641707611562785), (1354, 0.024571353310207406), (2836, 0.024451731505438685), (1008, 0.024363344075086068), (3177, 0.02435517399761372), (1370, 0.024332478496510317), (2460, 0.024330296524584155), (1624, 0.024252038727138714), (1872, 0.024183208627803827), (29, 0.024059512435648148), (633, 0.024046758419329885), (2432, 0.023949975579054886), (3726, 0.023849695115682742), (2736, 0.02383981735460432), (2069, 0.023788010689282917), (1338, 0.02374264523879642), (483, 0.02369030876171032), (2863, 0.023552345817091563), (1412, 0.023503270496583295), (3660, 0.02337062425859058), (1610, 0.02333880970618626), (2072, 0.023299858207074906), (1672, 0.023185792260629334), (2891, 0.02317541105318229), (360, 0.02310142000135587), (2505, 0.02310059204562111), (3034, 0.023093058631907762), (2623, 0.02304107629812137), (1295, 0.02301047550797293), (3839, 0.023005399696851194), (896, 0.023002745090155163), (1345, 0.02287662316353779), (3596, 0.022851454481433917), (1384, 0.022752744098900834), (3120, 0.022707090825572658), (2871, 0.022661171746615923), (923, 0.022627341510225222), (1483, 0.022417475312741512), (2465, 0.022335967333187528), (1634, 0.022295583970512244), (2583, 0.022266878422479146), (478, 0.022265615613812427), (3745, 0.022256389091386088), (3591, 0.022246993502573455), (461, 0.022200838092431178), (356, 0.022162648716183304), (1270, 0.02213877944086232), (2826, 0.02208657418039337), (2092, 0.02205422576979468), (122, 0.022020894824123914), (1714, 0.02199209509688069), (3005, 0.02194758580342411), (3648, 0.021885498738519995), (2188, 0.021843422134395003), (683, 0.0218408972404161), (3176, 0.02173934026802289), (620, 0.02169372618294079), (1527, 0.021634700677442727), (3720, 0.021568390784225597), (3366, 0.021475896321683605), (3789, 0.021469972779968458), (2056, 0.021467110776141992), (1322, 0.021464492201802115), (708, 0.02143798297019318), (3143, 0.021430179007025367), (1488, 0.021165882475484815), (430, 0.021155361553963015), (1851, 0.021149662931399665), (40, 0.021127327939290914), (3521, 0.021094356228708696), (3074, 0.021091452045192614), (3270, 0.020882680209471125), (2612, 0.020865958644728795), (2215, 0.02080643162501402), (1677, 0.020745677293203903), (1326, 0.020592768818460797), (14, 0.020513331429116138), (3085, 0.02036019797436467), (3662, 0.020295452065689914), (3063, 0.020211750483814808), (603, 0.020179946668680716), (1810, 0.020015549120875886), (15, 0.019995212297021628), (3088, 0.019888017445411344), (1179, 0.01978654935671029), (1915, 0.019749758272553163), (2667, 0.019724934245307343), (3629, 0.01965952652762427), (386, 0.019602114271672057), (409, 0.019553238107607302), (2924, 0.019523167929668538), (891, 0.019462854728729908), (1920, 0.019445352102312484), (2543, 0.019405872943719264), (2948, 0.019374263638311608), (17, 0.01934702244621565), (3299, 0.019235208107874095), (105, 0.019170767432015005), (2416, 0.019049586411597156), (3622, 0.018980005861409438), (2777, 0.01896888787428283), (2129, 0.018802090446634927), (1064, 0.01879795941623079), (2167, 0.018682846435487715), (510, 0.018599835753391893), (270, 0.018564365011848043), (1868, 0.01853453985434288), (2067, 0.018451781051451878), (3110, 0.018224993904374945), (414, 0.018223223678890874), (2018, 0.018181083660686048), (2730, 0.01816848045072999), (1918, 0.01811602756493729), (3358, 0.01806744329754609), (3499, 0.018059865337752987), (1373, 0.018055950412287542), (702, 0.018019088133791657), (3566, 0.01800876813279404), (467, 0.017998241167092078), (2644, 0.017948057275266684), (3142, 0.01794553683517691), (202, 0.01793110399779748), (1693, 0.017913462023270956), (815, 0.01790813220111722), (2816, 0.01787143516514499), (3700, 0.0178067809246961), (206, 0.01776114095554666), (1532, 0.01775968236883901), (2527, 0.017743768315407183), (3560, 0.01772884483662181), (2326, 0.017715399165542944), (3135, 0.017701675543693937), (1859, 0.01757104637249673), (1347, 0.017551237178234626), (2943, 0.017538301269544067), (1108, 0.017505719817744674), (1966, 0.01749606525641491), (2017, 0.017456768183957017), (1363, 0.01743539953061415), (3509, 0.01733914292561611), (1731, 0.017320854074195695), (1331, 0.017289595358154258), (1546, 0.017203078794943816), (1149, 0.017200900768158715), (1361, 0.017163704529228246), (2743, 0.017160465497729798), (3576, 0.01714898254083957), (2627, 0.017138589122315126), (312, 0.017106006621484388), (3641, 0.017082445816003097), (952, 0.017050332160865992), (721, 0.016966444314181955), (3220, 0.016959885341260483), (1819, 0.016956188408029708), (87, 0.016875116290740646), (3715, 0.016861489764272732), (2264, 0.01684411437675714), (2731, 0.016839949475275607), (3635, 0.01681835405748327), (3309, 0.016769166515172202), (764, 0.01674726922960685), (518, 0.016696504038780945), (2003, 0.01667161035890709), (159, 0.01666877240911804), (632, 0.016638303825169846), (567, 0.016618851238554395), (2584, 0.01659687218755994), (2296, 0.016579032404088073), (564, 0.01651554438474592), (2005, 0.016510365671350266), (886, 0.016413038373275506), (1336, 0.01636382908427584), (851, 0.01627183752837716), (3359, 0.01626667260831638), (207, 0.01624232852524783), (214, 0.01623372684088141), (548, 0.016156195578160795), (3003, 0.016125512158369822), (3420, 0.01605371839119335), (980, 0.01602784914693705), (396, 0.016025602167931367), (3202, 0.01600912853910435), (2457, 0.015985095711392526), (3404, 0.015983172325407195), (151, 0.015879197814512903), (559, 0.01585532013528309), (2464, 0.015827346584241616), (3323, 0.015796269144883503), (138, 0.015731887874006072), (1268, 0.01567844334672536), (2043, 0.015653306876623602), (3538, 0.015593824691896878), (1410, 0.015582108584265423), (780, 0.015566637635910898), (3645, 0.015520831118747934), (2497, 0.015513307766738356), (1002, 0.01545916095453806), (846, 0.015458740715339914), (1635, 0.015456016431888878), (644, 0.01540728926394705), (1669, 0.015388261373566622), (3819, 0.015375968271394442), (3390, 0.015337775729582104), (700, 0.015317750049345318), (529, 0.015260993564531863), (1977, 0.015231591378924495), (1564, 0.015168325778729619), (645, 0.01515772191519906), (2585, 0.01503331286970673), (1972, 0.014991949926289692), (2320, 0.014987675674795916), (1557, 0.014939880862665638), (915, 0.014894977180796432), (125, 0.014885005189665543), (133, 0.014832155317054934), (324, 0.014780936447917864), (1341, 0.014767854002798862), (3502, 0.014765030075301782), (926, 0.014731501198121864), (2467, 0.014586190172716224), (2496, 0.014537738670259648), (2936, 0.014528405190654304), (911, 0.014521091025824159), (2723, 0.014474680955350941), (2726, 0.014435254426761893), (1606, 0.014427340214121932), (1917, 0.014413294985196206), (2191, 0.014407135131107588), (1433, 0.014395465622951957), (3313, 0.014363505405793547), (3219, 0.014293378230883199), (3175, 0.01424235513652417), (1109, 0.014210582335090274), (513, 0.014176200257978862), (2529, 0.01413890711445427), (1998, 0.014103130816463529), (3529, 0.014043828851878812), (227, 0.014019264122158228), (1480, 0.014011219733436962), (3025, 0.013992296846562587), (3824, 0.013953480717317406), (1798, 0.013935151000577317), (3571, 0.013932114732608131), (1401, 0.013908130976205949), (91, 0.013904823190005846), (3412, 0.013888263956722036), (3723, 0.01383905126489091), (2539, 0.0138324566663505), (2811, 0.013817790904797424), (1739, 0.013802584057645206), (3437, 0.013758670947466576), (3615, 0.013751121200309687), (2420, 0.013738669759004736), (1751, 0.013722952583133465), (3462, 0.013718294927376013), (631, 0.013667610022913222), (1753, 0.013656844652272284), (685, 0.013651961705678388), (1276, 0.013624533905705363), (3318, 0.013615499233090689), (3160, 0.013557692134643258), (1375, 0.013556981051823798), (423, 0.013549351486775099), (2441, 0.013546521476861178), (161, 0.013485677656472706), (3578, 0.013473218402160536), (2602, 0.013467272878474379), (1173, 0.013451831654137329), (2070, 0.013403695504922522), (2890, 0.01337331217322446), (3062, 0.013356997720468779), (2297, 0.013342136762637057), (26, 0.013276764834495514), (69, 0.013263045534816022), (1827, 0.013246332375853917), (3337, 0.013229480313981924), (94, 0.013220742745680787), (2463, 0.01320203992706862), (1636, 0.013201953292455729), (2163, 0.013196504229718525), (3397, 0.013191531008035134), (2875, 0.013164832477066723), (3606, 0.013155436119936123), (905, 0.013141434440953871), (2437, 0.013124235284024014), (3030, 0.013124125641825335), (1119, 0.013055878813478007), (1855, 0.013020866381849086), (2716, 0.012971452779988787), (2630, 0.012971341627121803), (1883, 0.012962055371077022), (3655, 0.012961363933707531), (364, 0.012885120724534646), (417, 0.012858109649876541), (1405, 0.012802593348574995), (3782, 0.012785781298422495), (2894, 0.012779519683154127), (1095, 0.012776958492778137), (1486, 0.012735356268559445), (580, 0.012718354101395381), (3574, 0.012675796187581582), (1515, 0.012641127999026914), (595, 0.012546793507481705), (2314, 0.012525677864579924), (2021, 0.012497054916090853), (1886, 0.012482571579819168), (1426, 0.01247785426565598), (1116, 0.012463871902761664), (3119, 0.012453107991380549), (731, 0.012438943440290715), (2425, 0.012437747914194051), (2589, 0.012408008720611532), (2238, 0.012332093182878891), (2945, 0.012316362067424863), (3291, 0.012306421129509418), (3627, 0.012284167706312769), (1194, 0.01217017583986895), (1388, 0.01216491963123185), (3347, 0.01214876165003617), (2975, 0.012089431410877255), (3126, 0.012081668174226672), (2175, 0.012051925880761236), (2556, 0.012032558613813865), (1160, 0.01203186872569012), (1254, 0.012007457956468542), (1125, 0.01199087410510521), (3326, 0.011990682085550283), (712, 0.011986317272031517), (332, 0.011966208381215922), (3022, 0.011933958337796254), (2715, 0.011929320549619466), (3510, 0.011928974876642448), (152, 0.011927370265836196), (1238, 0.011891641017823093), (2097, 0.011890290985424472), (3584, 0.011869685586015845), (2835, 0.01186329893410005), (443, 0.011860495113883505), (2150, 0.011840128696457715), (2928, 0.011838115607852012), (792, 0.011829541723834379), (604, 0.011827251773288316), (535, 0.011772521251956724), (1072, 0.011722288298196276), (2526, 0.011716938057874037), (383, 0.011711817666193487), (1543, 0.011702486908363398), (912, 0.011697598654815382), (46, 0.011680379906654527), (1640, 0.0116742054298402), (3081, 0.011671898519082902), (1567, 0.01164448488468943), (1003, 0.011640685475809398), (3052, 0.011609177572171208), (2791, 0.011589722728762875), (2502, 0.011577729933573897), (3658, 0.01157478701000809), (2148, 0.011563468701874444), (164, 0.01155768814090946), (1328, 0.011505793459029065), (2443, 0.011503004283445984), (158, 0.01147038076464546), (3276, 0.011438216385215676), (3278, 0.011333240272951335), (1709, 0.011321690492866836), (2372, 0.011318729524152011), (3243, 0.011275991414692777), (888, 0.011272434782115447), (1399, 0.011225351127834345), (2595, 0.011194713105533136), (3283, 0.011182010755239223), (2190, 0.011177148398687404), (3094, 0.011141506926485446), (3144, 0.011140306054322426), (855, 0.011117824622845272), (2637, 0.011106411650426744), (2803, 0.011044415114858359), (3374, 0.011042205074047046), (235, 0.011034518268868383), (2512, 0.011025984339411137), (1332, 0.011023334583205755), (922, 0.010998244987796788), (1491, 0.010948313965903657), (260, 0.010936560555822416), (1163, 0.010926011457603262), (3310, 0.010881464659952862), (3708, 0.01087007161807628), (1916, 0.01086112235500147), (1024, 0.010836712633270202), (1847, 0.010816052745889742), (3203, 0.010814016897955366), (767, 0.010794013034286195), (866, 0.010787886049599623), (2139, 0.010775165035850524), (1159, 0.010775149020004742), (1185, 0.010767889127932003), (1439, 0.010763428001266638), (1351, 0.010751795735810102), (390, 0.010716624624233801), (1517, 0.010686917727590058), (2289, 0.010636612683414903), (2028, 0.010614856534959152), (1629, 0.010599996212291803), (2513, 0.01059828880204496), (1377, 0.010590442083959355), (3239, 0.010557697472162626), (563, 0.010514906878750492), (544, 0.010508713428834896), (226, 0.010501637946258056), (3047, 0.010497598464783119), (786, 0.010493178586945817), (2002, 0.01047706711042863), (3048, 0.010437352936736033), (2179, 0.010429994907306181), (284, 0.010419558066834662), (2393, 0.010389693929364079), (3238, 0.010377016437182071), (3141, 0.010343294870889886), (3856, 0.010302430426794048), (3287, 0.010285495606667474), (2507, 0.010281993413538125), (246, 0.010269528024909231), (1507, 0.010236861006605463), (3252, 0.010228784145240043), (3498, 0.010203951080607789), (378, 0.01012036487469311), (959, 0.01006684167084286), (1950, 0.010050995209681), (481, 0.010049828809772995), (2712, 0.010045180464081411), (3208, 0.009969308491230587), (1104, 0.009954654768557046), (3695, 0.009935577576123327), (2701, 0.009881684882413505), (2031, 0.009878481070559492), (2729, 0.009872828302890392), (2126, 0.009867555240786724), (624, 0.009860405701775442), (2800, 0.009847005637804282), (766, 0.009827807958482804), (2146, 0.009810158586214025), (860, 0.009779088806748859), (2817, 0.009747482342166765), (3783, 0.009718106143151509), (1957, 0.009713219460987526), (3654, 0.009712985410183918), (1603, 0.009704595204950654), (3752, 0.009594947693099239), (3604, 0.009587830509403542), (1261, 0.009546791944830876), (2547, 0.009542625700791637), (3402, 0.009523904658666902), (884, 0.009517101225964069), (2654, 0.00949368013426538), (2147, 0.009465436134026919), (3280, 0.00944780904494031), (412, 0.009439881587753815), (784, 0.009438746589106591), (1925, 0.009433236054348076), (1062, 0.009418960977863513), (3114, 0.009418606580124153), (1621, 0.009391791150199641), (1650, 0.00938241974370928), (162, 0.009339377311456615), (2290, 0.009332039543581057), (2345, 0.009331871198563524), (480, 0.00932799029614577), (2211, 0.009300958973717206), (2933, 0.00928184833074472), (1788, 0.009274808231809874), (2212, 0.009266722884730242), (1983, 0.00926214151843019), (1541, 0.009258572711604206), (3040, 0.00924730675845161), (119, 0.009239100246494101), (1223, 0.009212883757355277), (1959, 0.009194685046056644), (2346, 0.009158538991766257), (3721, 0.00911211491979131), (2255, 0.009096849527862707), (3764, 0.009086463014583082), (796, 0.009077239915265498), (3019, 0.009052058539894029), (2318, 0.009046102762100793), (1814, 0.009037223940353702), (1582, 0.009036707303832077), (2308, 0.009031839527171834), (2788, 0.009023285100567519), (2224, 0.008975592151988178), (2267, 0.008966552407927571), (3086, 0.008945747166060778), (1308, 0.008940828444755685), (901, 0.008935010232570083), (499, 0.00892861379676273), (3699, 0.008920035635022229), (1804, 0.008908141156181788), (215, 0.008906812520451144), (2376, 0.008885753527489116), (2399, 0.008878040473984225), (945, 0.008873809044217142), (770, 0.008864332113258785), (2760, 0.008853443676328402), (2257, 0.008836429290698113), (939, 0.008824091948333052), (735, 0.00881253061319214), (1455, 0.008809015615345086), (3306, 0.00880434909307739), (3552, 0.008789198241257706), (1026, 0.008789134649493841), (2699, 0.008786155046840298), (1033, 0.008785450166381912), (3061, 0.008758632889027586), (3492, 0.008754455975731315), (2470, 0.00873440886228914), (19, 0.008713596376681952), (913, 0.008681973704940376), (247, 0.008666784067993955), (1523, 0.0086606588733715), (194, 0.008658591850714891), (2591, 0.008651713803651052), (2199, 0.008621586226580305), (2626, 0.008617868039253067), (3078, 0.008609076302723066), (2349, 0.008584726831788918), (1684, 0.008566909608389829), (1664, 0.00855190726126686), (1391, 0.00854732000860831), (2218, 0.008502823897662982), (3024, 0.008490451311098242), (1727, 0.00845511525114065), (1358, 0.008420147360727902), (676, 0.008414273558490667), (1200, 0.008394760459145173), (275, 0.008390438023964868), (647, 0.008382651577880772), (1679, 0.008365133488769123), (3433, 0.00831687124853109), (751, 0.00830526617795416), (249, 0.008288544046735607), (339, 0.00828724179874585), (398, 0.008281619690312998), (3573, 0.008279430117287457), (3275, 0.00826940869842109), (2160, 0.00824346117964331), (120, 0.008237300686574177), (482, 0.008225656345308517), (2475, 0.008223341952591242), (2509, 0.008219463005668047), (3042, 0.008165615730906878), (737, 0.008160112803224383), (957, 0.008151027636548056), (2827, 0.008145184638962149), (2510, 0.008138316632241713), (3590, 0.008129685257829668), (2337, 0.00810361544391826), (2795, 0.008083370000555841), (2439, 0.008080581338748997), (1608, 0.008066677509680265), (225, 0.008054338367536698), (343, 0.008032530894868078), (1365, 0.008017242181347478), (3644, 0.007988606538458587), (2353, 0.007984432481537703), (3558, 0.007981709277811442), (2172, 0.007980144475795124), (2953, 0.007975137376441024), (2242, 0.007967804052808591), (434, 0.007966876496142208), (1871, 0.00795944364073004), (3452, 0.007957493324464222), (3178, 0.007940175256215739), (1713, 0.007933611887169354), (1563, 0.00792753151857476), (503, 0.007921053590417159), (2839, 0.007911452076306008), (2299, 0.007904612056306303), (3673, 0.007889022478467149), (273, 0.007870788222112632), (3672, 0.007868640210639198), (2877, 0.007862796913391165), (1414, 0.007858869851040139), (2628, 0.007847433399653898), (1039, 0.007843933897592113), (1687, 0.007813452855198263), (2647, 0.007813236885385476), (3815, 0.0078009877450628705), (1926, 0.007799620741033124), (1090, 0.0077700096937030885), (1167, 0.00776110877863237), (1031, 0.007756066108469966), (179, 0.00773514288833975), (71, 0.007734305080969812), (790, 0.007733991075313942), (3308, 0.007727106639567123), (2189, 0.0077129906990642755), (3469, 0.007699253160845172), (3697, 0.007690814859428713), (231, 0.00767475757552825), (3547, 0.007668872455880683), (699, 0.007654335531366955), (450, 0.007643444670381008), (38, 0.007639667146395728), (2972, 0.007601736877144491), (1428, 0.00759230389858989), (3180, 0.00759063720957983), (295, 0.00757553401880439), (3410, 0.0075731749417702315), (1849, 0.007550813553129756), (1954, 0.007541035188645141), (1006, 0.007529162305000255), (810, 0.007527887684558096), (248, 0.0075249593111964275), (147, 0.007513611100309499), (376, 0.007509621993603237), (1765, 0.0075078261788102205), (3232, 0.007491525865899479), (2617, 0.007479844663314732), (322, 0.007430934708667289), (1612, 0.007419852241614347), (1250, 0.007409430213853835), (3612, 0.007406683359540086), (3556, 0.007404031263402231), (495, 0.007398737672521938), (2560, 0.0073868240764874684), (749, 0.007375209789550198), (3808, 0.007358651467457267), (2351, 0.007346172932841923), (2183, 0.007328772997411325), (1294, 0.007320347350278475), (2984, 0.00731918119955133), (857, 0.007312213232788182), (2768, 0.007304728137775272), (850, 0.007284801014462942), (154, 0.0072841940849866366), (1878, 0.007282897018943128), (3570, 0.00728143965655109), (2305, 0.0072734502721952315), (3690, 0.007272972818992461), (216, 0.007271509476898464), (3762, 0.007270706660505909), (1450, 0.007270614045130107), (2101, 0.007261624980587736), (3524, 0.007257968085938706), (3811, 0.007250969101226661), (641, 0.007240373670983657), (254, 0.007239791014722917), (2790, 0.007238811111307489), (833, 0.007232054504489379), (1362, 0.007227232476711827), (1828, 0.0072024521259535365), (783, 0.007186927785491542), (1069, 0.0071783639397943215), (903, 0.007176610012500201), (3478, 0.007162221964964581), (1657, 0.007153536515475913), (1558, 0.007129510906532589), (2292, 0.007090082672804298), (3572, 0.007087627662106192), (67, 0.00707590069107236), (361, 0.007073259782373109), (3381, 0.007068996360302499), (760, 0.007055739711617612), (2176, 0.007053619662018794), (359, 0.007047618560897853), (2210, 0.007033270731750586), (533, 0.007028072293763663), (2214, 0.007013249237856822), (1774, 0.007004227825557203), (2794, 0.007002948447293258), (736, 0.0069982180432355484), (3652, 0.006997833518516331), (3840, 0.006996559890664683), (2641, 0.006959652666693826), (1941, 0.006943200572936879), (2520, 0.006937684521332948), (2365, 0.006935781601976215), (570, 0.006925534301907231), (1642, 0.006924572786796971), (519, 0.00692097060702739), (279, 0.0069159457238887195), (3779, 0.006910963133148088), (878, 0.006900818464299356), (245, 0.006897341009663337), (1303, 0.006894584002155678), (3000, 0.00688392002604973), (2789, 0.006876456027460586), (1265, 0.006873389708426587), (3501, 0.006851558881632239), (2415, 0.006825757091113645), (1239, 0.006823627894497174), (2487, 0.006809591934478753), (1560, 0.006787852747005994), (3717, 0.006785247209388724), (3016, 0.006784732374838023), (1627, 0.006780374395656515), (2099, 0.006777106260342535), (2311, 0.006774424580200782), (49, 0.006763629390154573), (2380, 0.006756290925229068), (3675, 0.006735691976550681), (3756, 0.006735104489438264), (213, 0.006724209364223501), (1220, 0.006723907731329832), (1700, 0.006714247841640055), (1420, 0.006710298153830251), (2996, 0.006702303775131487), (3387, 0.006679823113679939), (2566, 0.006659200631061852), (1393, 0.006658185860082496), (1873, 0.0066572865626993594), (3170, 0.0066537552390914904), (2688, 0.006652291375703643), (3213, 0.006645624399908149), (2523, 0.006637001666154812), (1253, 0.006633878874136815), (2564, 0.006633128571661469), (2687, 0.0066248476505824695), (3532, 0.0066016052462294665), (1461, 0.006598221861011813), (561, 0.006587680066157494), (3204, 0.006574366369108034), (591, 0.006573771680918668), (2090, 0.006551790880646048), (902, 0.006544970470658108), (3525, 0.006540132529685044), (3321, 0.006534935631426872), (3468, 0.00653453198459624), (781, 0.0065252993890491315), (2411, 0.006517515163655668), (1566, 0.006516496217208473), (2137, 0.00651611016984089), (289, 0.006514522798309562), (729, 0.0065143935458500495), (3377, 0.006499807031434475), (3801, 0.006496589803483196), (436, 0.006488443587331896), (1310, 0.006486051068628447), (1943, 0.006472455478188765), (1531, 0.006471359769190146), (2015, 0.00646649393681551), (1549, 0.006466210908556227), (1397, 0.006458920451338799), (3656, 0.0064478076131371555), (2359, 0.006442780392502726), (220, 0.006433065515251853), (1333, 0.006428964967565002), (2594, 0.006428073168545911), (83, 0.006423199007022055), (1453, 0.00642086028479576), (1667, 0.00640666213952978), (717, 0.006405500071730205), (3165, 0.006391225273228401), (3679, 0.0063826500245668565), (2193, 0.006379231453870931), (2298, 0.00637820972940698), (3217, 0.006376928860257513), (2358, 0.006376577970236017), (862, 0.006371150930233828), (1992, 0.006357302361514787), (36, 0.006348626965806443), (281, 0.00634836617167658), (1906, 0.006340998563912193), (2019, 0.006324108015824677), (1935, 0.006320554377721991), (3167, 0.006273353587011097), (2000, 0.00626069493089036), (3367, 0.006259138417031815), (887, 0.006259075620779108), (2698, 0.006256459659069577), (1089, 0.006237305490121149), (2038, 0.006221157426077961), (3457, 0.006217145003597635), (2151, 0.006216510807572469), (293, 0.006215489384698668), (1043, 0.006212521027408386), (428, 0.006205031680479512), (769, 0.006197467132464888), (3821, 0.006190107527873686), (1164, 0.006186157245574783), (2341, 0.006184969960728809), (2575, 0.006173285954991821), (654, 0.006158183227032408), (3111, 0.006157991008573921), (2106, 0.006152812051303181), (1169, 0.00615013139635874), (2321, 0.006147594443754179), (3809, 0.006147045185907463), (1037, 0.006133848969648392), (3369, 0.006130195147668647), (732, 0.006129436559822793), (2010, 0.006121644980063669), (2041, 0.006101957471574332), (1349, 0.006086452056644323), (3050, 0.00608452416745403), (787, 0.006073623402671105), (2194, 0.006061111392751756), (3459, 0.006060937323540666), (872, 0.006056442441269355), (1182, 0.006052172952420899), (2846, 0.006026601600728128), (2369, 0.006024897514420538), (3760, 0.006019227546214393), (2604, 0.005995791854428744), (1825, 0.005988807521765569), (3702, 0.005986444915142141), (1259, 0.005973346920340082), (3844, 0.005963418912896226), (3307, 0.005960234730719359), (1309, 0.005954456375067472), (2842, 0.0059519487959520875), (2965, 0.00594925906992893), (2445, 0.005940623934216363), (3836, 0.0059358726971128475), (1487, 0.005934569629303429), (2383, 0.0059290437200938614), (2494, 0.005924782300667394), (2873, 0.005893084133725098), (517, 0.005891940417154006), (3526, 0.005872520812936214), (2456, 0.005856570998576544), (795, 0.005823232270583433), (3233, 0.005801616360178517), (1186, 0.005798417478353447), (653, 0.005793816367065599), (1993, 0.005772333392065918), (3497, 0.005770301589406275), (2124, 0.005757767059919408), (765, 0.005749580309847509), (2389, 0.005748126722757461), (3563, 0.005736739619087637), (128, 0.0057361704222008226), (64, 0.005733518740979196), (3838, 0.0057199184308556585), (3044, 0.005715923311021146), (720, 0.005706321911839517), (3831, 0.005700986082912674), (1474, 0.00569443232767384), (1961, 0.005688348559455236), (3530, 0.005685099566993676), (3173, 0.005669454511847114), (475, 0.005668120984058578), (370, 0.005663758608161805), (2024, 0.00565042895653039), (3057, 0.005643023131607258), (471, 0.005642404975067953), (1012, 0.0056381770690748755), (524, 0.005634828050499352), (3851, 0.005628669379331535), (2957, 0.005628613058988631), (385, 0.005624205823505264), (433, 0.005622168500699815), (224, 0.005611907019575541), (5, 0.005611259521416583), (587, 0.0056056951978934524), (3728, 0.005604273102531961), (351, 0.005602568742588214), (444, 0.005600489740039469), (771, 0.005594940103971286), (191, 0.005577065037387603), (2995, 0.0055683781314340665), (3029, 0.005531472055598835), (1769, 0.0055219537948491566), (3727, 0.005510709191823654), (547, 0.005496671192422925), (2246, 0.005496029320543659), (3332, 0.005493345329398335), (2717, 0.005493106392921144), (1152, 0.0054634071094949955), (6, 0.005438556469947753), (1489, 0.005438473478853049), (3446, 0.00543065447528999), (3244, 0.005421462289915381), (3600, 0.005411922010125253), (232, 0.005406973400267277), (188, 0.005400606466759352), (589, 0.005396593325691649), (3640, 0.005378336425376502), (1577, 0.005377287229757622), (488, 0.005363255292723171), (347, 0.005352689217472357), (581, 0.005352488035635765), (3138, 0.005352400626829092), (1490, 0.005341324392234845), (1221, 0.005326366887846234), (1526, 0.005326155536610958), (2102, 0.005325128965845557), (3422, 0.005323100545167091), (1255, 0.0053184476313096135), (1321, 0.005306600608674815), (2636, 0.005289233438701245), (688, 0.005285959747266833), (426, 0.005278560053613567), (416, 0.005275952850572301), (2116, 0.005273158844801471), (3100, 0.005264841365682996), (3430, 0.005250528495142436), (86, 0.005249344494505807), (744, 0.005247780902364746), (167, 0.0052434726880116085), (2781, 0.00523780749547895), (3455, 0.005237759038077736), (2007, 0.0052357297034881616), (1485, 0.005234799167327875), (3677, 0.005233611260727761), (3421, 0.0052290901524357745), (1823, 0.005226298229602726), (1976, 0.0051914587354045345), (2532, 0.005188868336316064), (1273, 0.005172465161981587), (1732, 0.005144503020204793), (2045, 0.005130604861693407), (2613, 0.005128130894940209), (1745, 0.005120124738192812), (2482, 0.005119162676645514), (35, 0.0051105447999713486), (3164, 0.005107118577424777), (3835, 0.005105780628896109), (3463, 0.005104420114790629), (2055, 0.005089310740732768), (1209, 0.005079506402160132), (2683, 0.005073941871673406), (3365, 0.005070775354282441), (1468, 0.005058220123218859), (1652, 0.0050327597863022), (2221, 0.005031538510151806), (2810, 0.005031197618244999), (384, 0.00500276841826758), (2861, 0.004977621464389993), (2778, 0.0049688985138716035), (3166, 0.004952842752355631), (2727, 0.004944362789393175), (1256, 0.004940208457584938), (1550, 0.004934702594661469), (1580, 0.004923443546834534), (1914, 0.0049208134105300175), (2334, 0.004911323079697703), (2694, 0.004905174488579673), (1269, 0.00489709108532292), (3131, 0.004880712714471268), (3834, 0.004871919147505589), (507, 0.004854600728130943), (916, 0.004848221303775953), (2379, 0.00484145007611151), (990, 0.004837100988067164), (3730, 0.004814741566388471), (3454, 0.004814603441785771), (1123, 0.004802390627553834), (1424, 0.004801537422380331), (895, 0.0047978785882822166), (1506, 0.004772477156162541), (1539, 0.0047487443208204085), (57, 0.004724119319047174), (1028, 0.004716051298193099), (944, 0.004714823287349396), (2833, 0.004709632123014222), (3696, 0.0047092594093090575), (933, 0.00469478885461223), (1744, 0.004687175464132055), (1440, 0.004686458949372772), (1496, 0.004684821664608216), (1703, 0.004682372716604562), (504, 0.004679852324637821), (2397, 0.004673571541286747), (2528, 0.004656713323850006), (2618, 0.004649869676002422), (2156, 0.004643818556080035), (3465, 0.004643690454510067), (1054, 0.0046354613506258335), (868, 0.004610030045162432), (2271, 0.004601699646872485), (3474, 0.004594320261322434), (92, 0.004589610937995691), (3223, 0.00457977742866918), (1812, 0.004577985608862231), (440, 0.004565250447504982), (2597, 0.004562554470402003), (1472, 0.00455876461826439), (2557, 0.004550814174134015), (1820, 0.0045140713062855), (1710, 0.004509483113243224), (3362, 0.0044715367123408884), (742, 0.004464264325952677), (3787, 0.004438372777542669), (2744, 0.004430214270395812), (2538, 0.004398300917890288), (3542, 0.0043958505428409265), (3438, 0.004393471301220975), (2603, 0.004391474043134215), (2375, 0.004387108211071946), (1497, 0.004381220946069948), (1277, 0.004354864420691472), (3396, 0.004348696761886653), (1423, 0.004346566166386799), (48, 0.004338957731692339), (1130, 0.00432839679996409), (2643, 0.004313776943376451), (456, 0.0043119064376113845), (2670, 0.004309225897572107), (2988, 0.004305429635781475), (696, 0.004291454828844404), (3751, 0.0042832414523950105), (99, 0.00428310183180643), (1429, 0.004267610981135474), (2083, 0.004261906390458905), (2112, 0.004260404499583125), (3855, 0.004258618898589179), (3392, 0.004254564756798868), (2983, 0.00424349503272339), (3153, 0.004230093293408449), (2821, 0.004187001166308433), (1697, 0.004185777226561897), (1315, 0.004167772369015169), (3285, 0.004165631805568375), (3346, 0.004163396518418111), (2265, 0.004152587063998201), (1685, 0.0041394897871573424), (3795, 0.004136242790213739), (1574, 0.004094717056406003), (3317, 0.004090843533610707), (551, 0.004086422988566992), (985, 0.004085840367249405), (1061, 0.0040699166538774355), (1901, 0.004068534584665548), (333, 0.004065450807284318), (3765, 0.004064131415050752), (874, 0.004056521407230442), (1512, 0.004039350470341846), (3739, 0.004026334692772596), (1385, 0.0040260107853035436), (3710, 0.004024815467145378), (1027, 0.003982048716773452), (2217, 0.0039618058100654345), (2565, 0.003961232232349236), (832, 0.003947180104169665), (145, 0.003945866001189277), (1836, 0.003937543142370319), (2071, 0.003912718463647222), (2270, 0.003899578497613767), (3707, 0.0038980595274585345), (3006, 0.003861674251647066), (665, 0.003816963351666015), (824, 0.0037981241068281886), (3080, 0.00378361222666776), (863, 0.0037721773155154417), (156, 0.0037339160939698817), (438, 0.003706341171217156), (725, 0.0037008036879541697), (3650, 0.003688193147253932), (1298, 0.003636110184406601), (3639, 0.003625589501314143), (3557, 0.003616515596375869), (110, 0.003604870526258632), (2864, 0.003585217335965788), (163, 0.0035710137066014506), (402, 0.003566613927869583), (2610, 0.0035548599793437615), (1502, 0.0035543287833602363), (3382, 0.003551647506437266), (205, 0.0035476587292154822), (177, 0.003534108635771168), (2371, 0.00353291355152895), (1953, 0.0035323955778219437), (201, 0.003468976874765784), (3540, 0.0034451495342535643), (2178, 0.003392651862650304), (3735, 0.0033910056560387454), (1857, 0.003268230668441239), (2062, 0.003259722213640732), (3476, 0.0032467855431949637), (3212, 0.00323944499778513), (935, 0.003223661358816785), (3814, 0.0032149473907238384), (1537, 0.003197434569290144), (2713, 0.003142186690299459), (60, 0.0031183166973559394), (1176, 0.0031069731874763516), (1346, 0.003091636807131516), (3012, 0.003084497860941989), (1921, 0.003082144401699755), (936, 0.0030497173559712763), (2828, 0.003036217505697796), (2966, 0.0030227181466738555), (938, 0.0030221507158634626), (2911, 0.0029699992485701845), (1189, 0.0029638351795246193), (2030, 0.0029122050171427), (1864, 0.002881528802092692), (2046, 0.0028458399819489373), (3268, 0.0028285622101481165), (1880, 0.002811345917837276), (3260, 0.0027660786055703694), (180, 0.002754742238789424), (2922, 0.002706565127816573), (1368, 0.002683089623961543), (2834, 0.002665623091686762), (197, 0.0026461938183043815), (516, 0.0026301584722075275), (3137, 0.0025954376533902602), (3406, 0.0025326157948348587), (954, 0.0025279630866817566), (3272, 0.002522564247046217), (2931, 0.002481559639464395), (881, 0.0024059185491105773), (3817, 0.0023575078962899346), (3619, 0.0022392625689127447), (1777, 0.0022319547925259463), (882, 0.002217048218210588), (3255, 0.0022056152126281587), (3364, 0.0020820052536508877), (1630, 0.001939181845863038), (2981, 0.001840531405044195), (3171, 0.0017833804238267638), (2638, 0.001755195872660516), (1057, 0.0016860560171941814), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (7, 0.0), (8, 0.0), (9, 0.0), (10, 0.0), (11, 0.0), (12, 0.0), (13, 0.0), (16, 0.0), (18, 0.0), (20, 0.0), (21, 0.0), (22, 0.0), (23, 0.0), (24, 0.0), (25, 0.0), (27, 0.0), (28, 0.0), (30, 0.0), (31, 0.0), (32, 0.0), (33, 0.0), (34, 0.0), (37, 0.0), (39, 0.0), (41, 0.0), (42, 0.0), (43, 0.0), (44, 0.0), (45, 0.0), (47, 0.0), (50, 0.0), (51, 0.0), (52, 0.0), (53, 0.0), (54, 0.0), (55, 0.0), (56, 0.0), (58, 0.0), (59, 0.0), (61, 0.0), (62, 0.0), (63, 0.0), (65, 0.0), (66, 0.0), (68, 0.0), (70, 0.0), (72, 0.0), (73, 0.0), (74, 0.0), (76, 0.0), (77, 0.0), (78, 0.0), (79, 0.0), (80, 0.0), (81, 0.0), (82, 0.0), (84, 0.0), (85, 0.0), (88, 0.0), (90, 0.0), (93, 0.0), (95, 0.0), (96, 0.0), (97, 0.0), (98, 0.0), (100, 0.0), (101, 0.0), (102, 0.0), (103, 0.0), (104, 0.0), (106, 0.0), (107, 0.0), (109, 0.0), (111, 0.0), (112, 0.0), (113, 0.0), (114, 0.0), (115, 0.0), (116, 0.0), (117, 0.0), (118, 0.0), (121, 0.0), (123, 0.0), (124, 0.0), (126, 0.0), (127, 0.0), (129, 0.0), (130, 0.0), (131, 0.0), (132, 0.0), (134, 0.0), (135, 0.0), (136, 0.0), (137, 0.0), (139, 0.0), (140, 0.0), (141, 0.0), (142, 0.0), (143, 0.0), (146, 0.0), (148, 0.0), (149, 0.0), (150, 0.0), (153, 0.0), (155, 0.0), (157, 0.0), (160, 0.0), (165, 0.0), (166, 0.0), (168, 0.0), (169, 0.0), (170, 0.0), (172, 0.0), (173, 0.0), (174, 0.0), (175, 0.0), (176, 0.0), (178, 0.0), (181, 0.0), (183, 0.0), (184, 0.0), (185, 0.0), (186, 0.0), (187, 0.0), (189, 0.0), (190, 0.0), (192, 0.0), (193, 0.0), (195, 0.0), (198, 0.0), (199, 0.0), (200, 0.0), (203, 0.0), (204, 0.0), (208, 0.0), (209, 0.0), (210, 0.0), (211, 0.0), (212, 0.0), (217, 0.0), (218, 0.0), (219, 0.0), (221, 0.0), (222, 0.0), (223, 0.0), (229, 0.0), (230, 0.0), (233, 0.0), (234, 0.0), (236, 0.0), (237, 0.0), (238, 0.0), (239, 0.0), (240, 0.0), (241, 0.0), (243, 0.0), (244, 0.0), (250, 0.0), (251, 0.0), (252, 0.0), (253, 0.0), (256, 0.0), (258, 0.0), (261, 0.0), (262, 0.0), (263, 0.0), (264, 0.0), (265, 0.0), (266, 0.0), (267, 0.0), (268, 0.0), (269, 0.0), (271, 0.0), (272, 0.0), (274, 0.0), (276, 0.0), (277, 0.0), (278, 0.0), (280, 0.0), (282, 0.0), (283, 0.0), (285, 0.0), (286, 0.0), (287, 0.0), (288, 0.0), (290, 0.0), (291, 0.0), (292, 0.0), (294, 0.0), (296, 0.0), (297, 0.0), (298, 0.0), (299, 0.0), (300, 0.0), (301, 0.0), (302, 0.0), (303, 0.0), (304, 0.0), (305, 0.0), (306, 0.0), (307, 0.0), (308, 0.0), (309, 0.0), (311, 0.0), (313, 0.0), (314, 0.0), (315, 0.0), (316, 0.0), (317, 0.0), (318, 0.0), (320, 0.0), (321, 0.0), (323, 0.0), (326, 0.0), (327, 0.0), (328, 0.0), (329, 0.0), (330, 0.0), (331, 0.0), (334, 0.0), (335, 0.0), (336, 0.0), (337, 0.0), (338, 0.0), (340, 0.0), (341, 0.0), (342, 0.0), (344, 0.0), (345, 0.0), (346, 0.0), (348, 0.0), (349, 0.0), (350, 0.0), (352, 0.0), (353, 0.0), (354, 0.0), (355, 0.0), (357, 0.0), (358, 0.0), (362, 0.0), (363, 0.0), (365, 0.0), (366, 0.0), (367, 0.0), (368, 0.0), (369, 0.0), (371, 0.0), (372, 0.0), (373, 0.0), (374, 0.0), (375, 0.0), (377, 0.0), (379, 0.0), (380, 0.0), (381, 0.0), (387, 0.0), (388, 0.0), (389, 0.0), (391, 0.0), (392, 0.0), (393, 0.0), (394, 0.0), (395, 0.0), (397, 0.0), (399, 0.0), (400, 0.0), (401, 0.0), (403, 0.0), (404, 0.0), (405, 0.0), (406, 0.0), (407, 0.0), (408, 0.0), (410, 0.0), (411, 0.0), (413, 0.0), (415, 0.0), (418, 0.0), (419, 0.0), (420, 0.0), (421, 0.0), (422, 0.0), (424, 0.0), (425, 0.0), (427, 0.0), (429, 0.0), (431, 0.0), (432, 0.0), (435, 0.0), (437, 0.0), (439, 0.0), (441, 0.0), (442, 0.0), (445, 0.0), (446, 0.0), (447, 0.0), (448, 0.0), (449, 0.0), (451, 0.0), (452, 0.0), (453, 0.0), (454, 0.0), (455, 0.0), (457, 0.0), (458, 0.0), (459, 0.0), (460, 0.0), (463, 0.0), (464, 0.0), (465, 0.0), (466, 0.0), (468, 0.0), (469, 0.0), (470, 0.0), (472, 0.0), (473, 0.0), (474, 0.0), (476, 0.0), (477, 0.0), (479, 0.0), (484, 0.0), (485, 0.0), (486, 0.0), (489, 0.0), (490, 0.0), (491, 0.0), (492, 0.0), (493, 0.0), (494, 0.0), (496, 0.0), (497, 0.0), (498, 0.0), (500, 0.0), (501, 0.0), (502, 0.0), (505, 0.0), (508, 0.0), (509, 0.0), (511, 0.0), (512, 0.0), (514, 0.0), (515, 0.0), (520, 0.0), (521, 0.0), (522, 0.0), (523, 0.0), (525, 0.0), (526, 0.0), (527, 0.0), (528, 0.0), (530, 0.0), (531, 0.0), (532, 0.0), (534, 0.0), (536, 0.0), (537, 0.0), (538, 0.0), (539, 0.0), (540, 0.0), (541, 0.0), (542, 0.0), (543, 0.0), (545, 0.0), (546, 0.0), (549, 0.0), (552, 0.0), (553, 0.0), (554, 0.0), (555, 0.0), (556, 0.0), (557, 0.0), (558, 0.0), (560, 0.0), (562, 0.0), (565, 0.0), (566, 0.0), (569, 0.0), (571, 0.0), (572, 0.0), (573, 0.0), (575, 0.0), (576, 0.0), (577, 0.0), (578, 0.0), (579, 0.0), (583, 0.0), (584, 0.0), (585, 0.0), (586, 0.0), (590, 0.0), (592, 0.0), (593, 0.0), (594, 0.0), (596, 0.0), (597, 0.0), (598, 0.0), (599, 0.0), (600, 0.0), (601, 0.0), (602, 0.0), (605, 0.0), (606, 0.0), (607, 0.0), (608, 0.0), (609, 0.0), (610, 0.0), (611, 0.0), (612, 0.0), (613, 0.0), (614, 0.0), (615, 0.0), (616, 0.0), (617, 0.0), (618, 0.0), (619, 0.0), (621, 0.0), (622, 0.0), (623, 0.0), (625, 0.0), (626, 0.0), (627, 0.0), (628, 0.0), (629, 0.0), (630, 0.0), (634, 0.0), (635, 0.0), (636, 0.0), (637, 0.0), (638, 0.0), (640, 0.0), (643, 0.0), (646, 0.0), (648, 0.0), (649, 0.0), (650, 0.0), (651, 0.0), (652, 0.0), (655, 0.0), (656, 0.0), (657, 0.0), (658, 0.0), (659, 0.0), (660, 0.0), (661, 0.0), (662, 0.0), (663, 0.0), (666, 0.0), (667, 0.0), (668, 0.0), (669, 0.0), (670, 0.0), (671, 0.0), (672, 0.0), (673, 0.0), (674, 0.0), (675, 0.0), (678, 0.0), (679, 0.0), (681, 0.0), (682, 0.0), (684, 0.0), (686, 0.0), (687, 0.0), (689, 0.0), (690, 0.0), (691, 0.0), (692, 0.0), (693, 0.0), (694, 0.0), (695, 0.0), (697, 0.0), (698, 0.0), (701, 0.0), (703, 0.0), (704, 0.0), (705, 0.0), (706, 0.0), (707, 0.0), (709, 0.0), (710, 0.0), (711, 0.0), (713, 0.0), (714, 0.0), (715, 0.0), (716, 0.0), (718, 0.0), (719, 0.0), (722, 0.0), (723, 0.0), (724, 0.0), (726, 0.0), (727, 0.0), (728, 0.0), (730, 0.0), (733, 0.0), (734, 0.0), (738, 0.0), (739, 0.0), (740, 0.0), (741, 0.0), (743, 0.0), (745, 0.0), (746, 0.0), (747, 0.0), (748, 0.0), (750, 0.0), (752, 0.0), (753, 0.0), (754, 0.0), (755, 0.0), (756, 0.0), (757, 0.0), (758, 0.0), (759, 0.0), (761, 0.0), (762, 0.0), (763, 0.0), (768, 0.0), (772, 0.0), (773, 0.0), (774, 0.0), (775, 0.0), (776, 0.0), (777, 0.0), (778, 0.0), (779, 0.0), (782, 0.0), (785, 0.0), (788, 0.0), (789, 0.0), (791, 0.0), (793, 0.0), (794, 0.0), (797, 0.0), (798, 0.0), (799, 0.0), (800, 0.0), (801, 0.0), (802, 0.0), (803, 0.0), (804, 0.0), (805, 0.0), (806, 0.0), (807, 0.0), (808, 0.0), (809, 0.0), (811, 0.0), (812, 0.0), (813, 0.0), (814, 0.0), (816, 0.0), (817, 0.0), (818, 0.0), (819, 0.0), (820, 0.0), (821, 0.0), (822, 0.0), (823, 0.0), (825, 0.0), (826, 0.0), (827, 0.0), (828, 0.0), (829, 0.0), (830, 0.0), (831, 0.0), (834, 0.0), (835, 0.0), (836, 0.0), (837, 0.0), (838, 0.0), (839, 0.0), (840, 0.0), (841, 0.0), (842, 0.0), (843, 0.0), (844, 0.0), (845, 0.0), (847, 0.0), (848, 0.0), (849, 0.0), (853, 0.0), (854, 0.0), (856, 0.0), (858, 0.0), (859, 0.0), (861, 0.0), (864, 0.0), (867, 0.0), (869, 0.0), (870, 0.0), (871, 0.0), (873, 0.0), (875, 0.0), (876, 0.0), (877, 0.0), (879, 0.0), (880, 0.0), (883, 0.0), (885, 0.0), (889, 0.0), (890, 0.0), (892, 0.0), (893, 0.0), (894, 0.0), (897, 0.0), (904, 0.0), (906, 0.0), (907, 0.0), (908, 0.0), (909, 0.0), (910, 0.0), (914, 0.0), (917, 0.0), (918, 0.0), (919, 0.0), (920, 0.0), (921, 0.0), (924, 0.0), (925, 0.0), (927, 0.0), (928, 0.0), (929, 0.0), (930, 0.0), (931, 0.0), (932, 0.0), (934, 0.0), (937, 0.0), (940, 0.0), (942, 0.0), (943, 0.0), (946, 0.0), (947, 0.0), (948, 0.0), (949, 0.0), (950, 0.0), (951, 0.0), (953, 0.0), (955, 0.0), (956, 0.0), (958, 0.0), (960, 0.0), (961, 0.0), (962, 0.0), (963, 0.0), (964, 0.0), (965, 0.0), (966, 0.0), (967, 0.0), (968, 0.0), (969, 0.0), (970, 0.0), (971, 0.0), (972, 0.0), (973, 0.0), (974, 0.0), (976, 0.0), (977, 0.0), (978, 0.0), (979, 0.0), (981, 0.0), (982, 0.0), (983, 0.0), (984, 0.0), (986, 0.0), (987, 0.0), (988, 0.0), (989, 0.0), (991, 0.0), (992, 0.0), (993, 0.0), (994, 0.0), (995, 0.0), (996, 0.0), (997, 0.0), (998, 0.0), (999, 0.0), (1000, 0.0), (1001, 0.0), (1004, 0.0), (1005, 0.0), (1007, 0.0), (1009, 0.0), (1010, 0.0), (1011, 0.0), (1013, 0.0), (1014, 0.0), (1015, 0.0), (1018, 0.0), (1019, 0.0), (1020, 0.0), (1021, 0.0), (1022, 0.0), (1023, 0.0), (1025, 0.0), (1029, 0.0), (1030, 0.0), (1032, 0.0), (1034, 0.0), (1035, 0.0), (1036, 0.0), (1038, 0.0), (1040, 0.0), (1041, 0.0), (1042, 0.0), (1045, 0.0), (1046, 0.0), (1047, 0.0), (1048, 0.0), (1049, 0.0), (1050, 0.0), (1051, 0.0), (1052, 0.0), (1053, 0.0), (1055, 0.0), (1056, 0.0), (1058, 0.0), (1059, 0.0), (1060, 0.0), (1063, 0.0), (1066, 0.0), (1067, 0.0), (1068, 0.0), (1070, 0.0), (1071, 0.0), (1073, 0.0), (1074, 0.0), (1075, 0.0), (1076, 0.0), (1077, 0.0), (1078, 0.0), (1079, 0.0), (1080, 0.0), (1081, 0.0), (1082, 0.0), (1083, 0.0), (1084, 0.0), (1085, 0.0), (1086, 0.0), (1087, 0.0), (1088, 0.0), (1091, 0.0), (1092, 0.0), (1093, 0.0), (1094, 0.0), (1096, 0.0), (1098, 0.0), (1099, 0.0), (1100, 0.0), (1101, 0.0), (1102, 0.0), (1103, 0.0), (1105, 0.0), (1106, 0.0), (1107, 0.0), (1110, 0.0), (1111, 0.0), (1112, 0.0), (1113, 0.0), (1114, 0.0), (1115, 0.0), (1117, 0.0), (1118, 0.0), (1120, 0.0), (1121, 0.0), (1122, 0.0), (1124, 0.0), (1126, 0.0), (1127, 0.0), (1128, 0.0), (1129, 0.0), (1131, 0.0), (1132, 0.0), (1133, 0.0), (1134, 0.0), (1135, 0.0), (1136, 0.0), (1137, 0.0), (1138, 0.0), (1139, 0.0), (1140, 0.0), (1141, 0.0), (1142, 0.0), (1143, 0.0), (1144, 0.0), (1145, 0.0), (1146, 0.0), (1147, 0.0), (1148, 0.0), (1150, 0.0), (1151, 0.0), (1153, 0.0), (1154, 0.0), (1155, 0.0), (1156, 0.0), (1157, 0.0), (1158, 0.0), (1161, 0.0), (1162, 0.0), (1165, 0.0), (1166, 0.0), (1168, 0.0), (1170, 0.0), (1174, 0.0), (1177, 0.0), (1178, 0.0), (1180, 0.0), (1181, 0.0), (1183, 0.0), (1187, 0.0), (1188, 0.0), (1190, 0.0), (1191, 0.0), (1193, 0.0), (1195, 0.0), (1196, 0.0), (1198, 0.0), (1199, 0.0), (1201, 0.0), (1202, 0.0), (1203, 0.0), (1204, 0.0), (1205, 0.0), (1206, 0.0), (1207, 0.0), (1208, 0.0), (1210, 0.0), (1211, 0.0), (1212, 0.0), (1213, 0.0), (1215, 0.0), (1216, 0.0), (1217, 0.0), (1218, 0.0), (1219, 0.0), (1222, 0.0), (1224, 0.0), (1225, 0.0), (1226, 0.0), (1227, 0.0), (1228, 0.0), (1229, 0.0), (1230, 0.0), (1231, 0.0), (1232, 0.0), (1233, 0.0), (1234, 0.0), (1235, 0.0), (1236, 0.0), (1237, 0.0), (1240, 0.0), (1241, 0.0), (1242, 0.0), (1243, 0.0), (1244, 0.0), (1245, 0.0), (1246, 0.0), (1247, 0.0), (1249, 0.0), (1251, 0.0), (1252, 0.0), (1257, 0.0), (1258, 0.0), (1260, 0.0), (1262, 0.0), (1263, 0.0), (1264, 0.0), (1266, 0.0), (1267, 0.0), (1271, 0.0), (1272, 0.0), (1274, 0.0), (1275, 0.0), (1278, 0.0), (1279, 0.0), (1280, 0.0), (1281, 0.0), (1282, 0.0), (1283, 0.0), (1284, 0.0), (1285, 0.0), (1286, 0.0), (1287, 0.0), (1288, 0.0), (1289, 0.0), (1290, 0.0), (1291, 0.0), (1292, 0.0), (1293, 0.0), (1296, 0.0), (1297, 0.0), (1299, 0.0), (1300, 0.0), (1302, 0.0), (1304, 0.0), (1305, 0.0), (1306, 0.0), (1307, 0.0), (1311, 0.0), (1312, 0.0), (1313, 0.0), (1314, 0.0), (1316, 0.0), (1317, 0.0), (1318, 0.0), (1319, 0.0), (1320, 0.0), (1323, 0.0), (1324, 0.0), (1325, 0.0), (1327, 0.0), (1329, 0.0), (1330, 0.0), (1334, 0.0), (1335, 0.0), (1337, 0.0), (1340, 0.0), (1343, 0.0), (1344, 0.0), (1348, 0.0), (1350, 0.0), (1352, 0.0), (1353, 0.0), (1355, 0.0), (1356, 0.0), (1357, 0.0), (1359, 0.0), (1360, 0.0), (1364, 0.0), (1366, 0.0), (1367, 0.0), (1369, 0.0), (1371, 0.0), (1372, 0.0), (1374, 0.0), (1376, 0.0), (1378, 0.0), (1379, 0.0), (1380, 0.0), (1381, 0.0), (1382, 0.0), (1383, 0.0), (1386, 0.0), (1387, 0.0), (1389, 0.0), (1390, 0.0), (1392, 0.0), (1394, 0.0), (1395, 0.0), (1396, 0.0), (1400, 0.0), (1402, 0.0), (1403, 0.0), (1404, 0.0), (1406, 0.0), (1407, 0.0), (1408, 0.0), (1409, 0.0), (1411, 0.0), (1413, 0.0), (1415, 0.0), (1416, 0.0), (1417, 0.0), (1418, 0.0), (1419, 0.0), (1421, 0.0), (1422, 0.0), (1425, 0.0), (1427, 0.0), (1430, 0.0), (1431, 0.0), (1432, 0.0), (1434, 0.0), (1436, 0.0), (1437, 0.0), (1438, 0.0), (1441, 0.0), (1442, 0.0), (1443, 0.0), (1444, 0.0), (1445, 0.0), (1446, 0.0), (1447, 0.0), (1448, 0.0), (1449, 0.0), (1451, 0.0), (1452, 0.0), (1454, 0.0), (1456, 0.0), (1457, 0.0), (1458, 0.0), (1459, 0.0), (1460, 0.0), (1462, 0.0), (1463, 0.0), (1464, 0.0), (1465, 0.0), (1467, 0.0), (1469, 0.0), (1470, 0.0), (1471, 0.0), (1473, 0.0), (1475, 0.0), (1477, 0.0), (1478, 0.0), (1479, 0.0), (1481, 0.0), (1482, 0.0), (1484, 0.0), (1492, 0.0), (1493, 0.0), (1494, 0.0), (1495, 0.0), (1498, 0.0), (1499, 0.0), (1500, 0.0), (1501, 0.0), (1503, 0.0), (1504, 0.0), (1505, 0.0), (1508, 0.0), (1509, 0.0), (1510, 0.0), (1511, 0.0), (1513, 0.0), (1514, 0.0), (1516, 0.0), (1518, 0.0), (1519, 0.0), (1520, 0.0), (1521, 0.0), (1522, 0.0), (1524, 0.0), (1525, 0.0), (1529, 0.0), (1530, 0.0), (1533, 0.0), (1534, 0.0), (1536, 0.0), (1538, 0.0), (1540, 0.0), (1542, 0.0), (1544, 0.0), (1545, 0.0), (1547, 0.0), (1548, 0.0), (1551, 0.0), (1552, 0.0), (1553, 0.0), (1554, 0.0), (1556, 0.0), (1559, 0.0), (1561, 0.0), (1562, 0.0), (1565, 0.0), (1568, 0.0), (1569, 0.0), (1570, 0.0), (1571, 0.0), (1572, 0.0), (1573, 0.0), (1575, 0.0), (1576, 0.0), (1578, 0.0), (1579, 0.0), (1581, 0.0), (1583, 0.0), (1584, 0.0), (1585, 0.0), (1586, 0.0), (1587, 0.0), (1588, 0.0), (1589, 0.0), (1590, 0.0), (1591, 0.0), (1592, 0.0), (1593, 0.0), (1594, 0.0), (1595, 0.0), (1596, 0.0), (1597, 0.0), (1598, 0.0), (1599, 0.0), (1600, 0.0), (1602, 0.0), (1604, 0.0), (1605, 0.0), (1607, 0.0), (1609, 0.0), (1611, 0.0), (1613, 0.0), (1614, 0.0), (1615, 0.0), (1616, 0.0), (1617, 0.0), (1618, 0.0), (1619, 0.0), (1620, 0.0), (1622, 0.0), (1623, 0.0), (1625, 0.0), (1626, 0.0), (1628, 0.0), (1631, 0.0), (1632, 0.0), (1633, 0.0), (1637, 0.0), (1638, 0.0), (1639, 0.0), (1641, 0.0), (1643, 0.0), (1644, 0.0), (1645, 0.0), (1646, 0.0), (1647, 0.0), (1648, 0.0), (1649, 0.0), (1651, 0.0), (1653, 0.0), (1654, 0.0), (1655, 0.0), (1656, 0.0), (1658, 0.0), (1659, 0.0), (1660, 0.0), (1661, 0.0), (1663, 0.0), (1665, 0.0), (1666, 0.0), (1668, 0.0), (1670, 0.0), (1671, 0.0), (1673, 0.0), (1674, 0.0), (1675, 0.0), (1676, 0.0), (1678, 0.0), (1680, 0.0), (1681, 0.0), (1682, 0.0), (1683, 0.0), (1688, 0.0), (1689, 0.0), (1690, 0.0), (1691, 0.0), (1692, 0.0), (1694, 0.0), (1695, 0.0), (1696, 0.0), (1698, 0.0), (1699, 0.0), (1701, 0.0), (1702, 0.0), (1704, 0.0), (1705, 0.0), (1706, 0.0), (1707, 0.0), (1708, 0.0), (1711, 0.0), (1712, 0.0), (1715, 0.0), (1716, 0.0), (1717, 0.0), (1718, 0.0), (1719, 0.0), (1720, 0.0), (1721, 0.0), (1722, 0.0), (1723, 0.0), (1724, 0.0), (1725, 0.0), (1726, 0.0), (1728, 0.0), (1729, 0.0), (1730, 0.0), (1733, 0.0), (1734, 0.0), (1735, 0.0), (1736, 0.0), (1737, 0.0), (1738, 0.0), (1740, 0.0), (1741, 0.0), (1742, 0.0), (1743, 0.0), (1746, 0.0), (1747, 0.0), (1748, 0.0), (1749, 0.0), (1750, 0.0), (1752, 0.0), (1754, 0.0), (1755, 0.0), (1756, 0.0), (1757, 0.0), (1758, 0.0), (1759, 0.0), (1760, 0.0), (1761, 0.0), (1762, 0.0), (1763, 0.0), (1764, 0.0), (1767, 0.0), (1768, 0.0), (1770, 0.0), (1771, 0.0), (1772, 0.0), (1773, 0.0), (1775, 0.0), (1776, 0.0), (1778, 0.0), (1779, 0.0), (1780, 0.0), (1781, 0.0), (1782, 0.0), (1783, 0.0), (1784, 0.0), (1785, 0.0), (1786, 0.0), (1787, 0.0), (1789, 0.0), (1790, 0.0), (1791, 0.0), (1792, 0.0), (1793, 0.0), (1794, 0.0), (1795, 0.0), (1796, 0.0), (1797, 0.0), (1799, 0.0), (1800, 0.0), (1801, 0.0), (1802, 0.0), (1803, 0.0), (1805, 0.0), (1806, 0.0), (1807, 0.0), (1808, 0.0), (1809, 0.0), (1811, 0.0), (1813, 0.0), (1815, 0.0), (1816, 0.0), (1817, 0.0), (1818, 0.0), (1821, 0.0), (1822, 0.0), (1824, 0.0), (1826, 0.0), (1829, 0.0), (1830, 0.0), (1831, 0.0), (1832, 0.0), (1833, 0.0), (1834, 0.0), (1835, 0.0), (1837, 0.0), (1838, 0.0), (1839, 0.0), (1840, 0.0), (1841, 0.0), (1842, 0.0), (1843, 0.0), (1844, 0.0), (1845, 0.0), (1846, 0.0), (1848, 0.0), (1850, 0.0), (1852, 0.0), (1853, 0.0), (1854, 0.0), (1856, 0.0), (1858, 0.0), (1861, 0.0), (1862, 0.0), (1863, 0.0), (1865, 0.0), (1866, 0.0), (1867, 0.0), (1869, 0.0), (1870, 0.0), (1874, 0.0), (1875, 0.0), (1876, 0.0), (1877, 0.0), (1879, 0.0), (1881, 0.0), (1882, 0.0), (1885, 0.0), (1887, 0.0), (1888, 0.0), (1889, 0.0), (1890, 0.0), (1891, 0.0), (1892, 0.0), (1893, 0.0), (1894, 0.0), (1895, 0.0), (1896, 0.0), (1897, 0.0), (1898, 0.0), (1899, 0.0), (1900, 0.0), (1902, 0.0), (1903, 0.0), (1904, 0.0), (1905, 0.0), (1907, 0.0), (1908, 0.0), (1909, 0.0), (1910, 0.0), (1911, 0.0), (1912, 0.0), (1913, 0.0), (1919, 0.0), (1922, 0.0), (1923, 0.0), (1924, 0.0), (1927, 0.0), (1928, 0.0), (1929, 0.0), (1930, 0.0), (1931, 0.0), (1932, 0.0), (1933, 0.0), (1934, 0.0), (1936, 0.0), (1937, 0.0), (1938, 0.0), (1939, 0.0), (1940, 0.0), (1942, 0.0), (1944, 0.0), (1945, 0.0), (1946, 0.0), (1947, 0.0), (1948, 0.0), (1949, 0.0), (1951, 0.0), (1952, 0.0), (1956, 0.0), (1958, 0.0), (1960, 0.0), (1962, 0.0), (1963, 0.0), (1964, 0.0), (1965, 0.0), (1967, 0.0), (1968, 0.0), (1969, 0.0), (1970, 0.0), (1971, 0.0), (1973, 0.0), (1974, 0.0), (1975, 0.0), (1978, 0.0), (1979, 0.0), (1980, 0.0), (1981, 0.0), (1982, 0.0), (1984, 0.0), (1985, 0.0), (1986, 0.0), (1987, 0.0), (1988, 0.0), (1989, 0.0), (1990, 0.0), (1991, 0.0), (1994, 0.0), (1995, 0.0), (1996, 0.0), (1997, 0.0), (1999, 0.0), (2004, 0.0), (2009, 0.0), (2011, 0.0), (2013, 0.0), (2014, 0.0), (2016, 0.0), (2020, 0.0), (2022, 0.0), (2023, 0.0), (2025, 0.0), (2026, 0.0), (2027, 0.0), (2029, 0.0), (2032, 0.0), (2033, 0.0), (2034, 0.0), (2035, 0.0), (2036, 0.0), (2037, 0.0), (2039, 0.0), (2040, 0.0), (2042, 0.0), (2044, 0.0), (2047, 0.0), (2048, 0.0), (2049, 0.0), (2050, 0.0), (2051, 0.0), (2052, 0.0), (2053, 0.0), (2054, 0.0), (2057, 0.0), (2058, 0.0), (2060, 0.0), (2061, 0.0), (2063, 0.0), (2064, 0.0), (2065, 0.0), (2066, 0.0), (2073, 0.0), (2074, 0.0), (2075, 0.0), (2076, 0.0), (2077, 0.0), (2078, 0.0), (2079, 0.0), (2080, 0.0), (2081, 0.0), (2082, 0.0), (2084, 0.0), (2085, 0.0), (2086, 0.0), (2087, 0.0), (2088, 0.0), (2089, 0.0), (2091, 0.0), (2093, 0.0), (2094, 0.0), (2095, 0.0), (2096, 0.0), (2103, 0.0), (2104, 0.0), (2105, 0.0), (2107, 0.0), (2108, 0.0), (2109, 0.0), (2113, 0.0), (2114, 0.0), (2115, 0.0), (2117, 0.0), (2118, 0.0), (2119, 0.0), (2120, 0.0), (2121, 0.0), (2122, 0.0), (2123, 0.0), (2125, 0.0), (2127, 0.0), (2128, 0.0), (2130, 0.0), (2131, 0.0), (2132, 0.0), (2133, 0.0), (2134, 0.0), (2135, 0.0), (2136, 0.0), (2138, 0.0), (2140, 0.0), (2141, 0.0), (2142, 0.0), (2143, 0.0), (2144, 0.0), (2145, 0.0), (2149, 0.0), (2152, 0.0), (2153, 0.0), (2154, 0.0), (2155, 0.0), (2157, 0.0), (2158, 0.0), (2159, 0.0), (2161, 0.0), (2162, 0.0), (2164, 0.0), (2165, 0.0), (2166, 0.0), (2168, 0.0), (2169, 0.0), (2170, 0.0), (2171, 0.0), (2173, 0.0), (2174, 0.0), (2177, 0.0), (2180, 0.0), (2181, 0.0), (2182, 0.0), (2184, 0.0), (2185, 0.0), (2186, 0.0), (2187, 0.0), (2192, 0.0), (2195, 0.0), (2196, 0.0), (2197, 0.0), (2198, 0.0), (2201, 0.0), (2202, 0.0), (2203, 0.0), (2204, 0.0), (2205, 0.0), (2206, 0.0), (2207, 0.0), (2208, 0.0), (2216, 0.0), (2219, 0.0), (2220, 0.0), (2222, 0.0), (2225, 0.0), (2226, 0.0), (2227, 0.0), (2228, 0.0), (2229, 0.0), (2230, 0.0), (2231, 0.0), (2232, 0.0), (2233, 0.0), (2234, 0.0), (2235, 0.0), (2236, 0.0), (2237, 0.0), (2240, 0.0), (2241, 0.0), (2243, 0.0), (2244, 0.0), (2245, 0.0), (2247, 0.0), (2248, 0.0), (2249, 0.0), (2250, 0.0), (2251, 0.0), (2252, 0.0), (2253, 0.0), (2254, 0.0), (2256, 0.0), (2258, 0.0), (2259, 0.0), (2260, 0.0), (2261, 0.0), (2262, 0.0), (2266, 0.0), (2268, 0.0), (2269, 0.0), (2272, 0.0), (2273, 0.0), (2274, 0.0), (2275, 0.0), (2276, 0.0), (2277, 0.0), (2278, 0.0), (2279, 0.0), (2280, 0.0), (2281, 0.0), (2282, 0.0), (2283, 0.0), (2284, 0.0), (2285, 0.0), (2286, 0.0), (2287, 0.0), (2288, 0.0), (2291, 0.0), (2293, 0.0), (2294, 0.0), (2295, 0.0), (2300, 0.0), (2301, 0.0), (2302, 0.0), (2303, 0.0), (2304, 0.0), (2306, 0.0), (2307, 0.0), (2310, 0.0), (2313, 0.0), (2315, 0.0), (2316, 0.0), (2322, 0.0), (2323, 0.0), (2324, 0.0), (2325, 0.0), (2327, 0.0), (2328, 0.0), (2329, 0.0), (2330, 0.0), (2331, 0.0), (2332, 0.0), (2333, 0.0), (2335, 0.0), (2336, 0.0), (2338, 0.0), (2339, 0.0), (2340, 0.0), (2342, 0.0), (2343, 0.0), (2344, 0.0), (2348, 0.0), (2350, 0.0), (2352, 0.0), (2354, 0.0), (2355, 0.0), (2356, 0.0), (2357, 0.0), (2360, 0.0), (2361, 0.0), (2362, 0.0), (2363, 0.0), (2364, 0.0), (2366, 0.0), (2367, 0.0), (2368, 0.0), (2370, 0.0), (2374, 0.0), (2377, 0.0), (2378, 0.0), (2381, 0.0), (2382, 0.0), (2384, 0.0), (2385, 0.0), (2386, 0.0), (2387, 0.0), (2388, 0.0), (2390, 0.0), (2391, 0.0), (2392, 0.0), (2394, 0.0), (2395, 0.0), (2396, 0.0), (2398, 0.0), (2400, 0.0), (2401, 0.0), (2402, 0.0), (2403, 0.0), (2404, 0.0), (2405, 0.0), (2406, 0.0), (2407, 0.0), (2408, 0.0), (2409, 0.0), (2410, 0.0), (2412, 0.0), (2413, 0.0), (2414, 0.0), (2417, 0.0), (2418, 0.0), (2419, 0.0), (2421, 0.0), (2422, 0.0), (2423, 0.0), (2424, 0.0), (2426, 0.0), (2427, 0.0), (2428, 0.0), (2429, 0.0), (2430, 0.0), (2431, 0.0), (2433, 0.0), (2434, 0.0), (2435, 0.0), (2436, 0.0), (2438, 0.0), (2440, 0.0), (2442, 0.0), (2444, 0.0), (2446, 0.0), (2447, 0.0), (2448, 0.0), (2449, 0.0), (2450, 0.0), (2451, 0.0), (2452, 0.0), (2453, 0.0), (2454, 0.0), (2455, 0.0), (2459, 0.0), (2461, 0.0), (2462, 0.0), (2466, 0.0), (2468, 0.0), (2469, 0.0), (2471, 0.0), (2472, 0.0), (2473, 0.0), (2474, 0.0), (2476, 0.0), (2477, 0.0), (2478, 0.0), (2479, 0.0), (2480, 0.0), (2481, 0.0), (2483, 0.0), (2484, 0.0), (2485, 0.0), (2489, 0.0), (2490, 0.0), (2491, 0.0), (2492, 0.0), (2493, 0.0), (2495, 0.0), (2498, 0.0), (2499, 0.0), (2500, 0.0), (2501, 0.0), (2503, 0.0), (2504, 0.0), (2506, 0.0), (2508, 0.0), (2511, 0.0), (2514, 0.0), (2515, 0.0), (2516, 0.0), (2517, 0.0), (2518, 0.0), (2519, 0.0), (2521, 0.0), (2522, 0.0), (2524, 0.0), (2525, 0.0), (2530, 0.0), (2531, 0.0), (2533, 0.0), (2534, 0.0), (2535, 0.0), (2536, 0.0), (2537, 0.0), (2540, 0.0), (2541, 0.0), (2542, 0.0), (2544, 0.0), (2545, 0.0), (2546, 0.0), (2550, 0.0), (2554, 0.0), (2555, 0.0), (2558, 0.0), (2559, 0.0), (2561, 0.0), (2562, 0.0), (2563, 0.0), (2567, 0.0), (2568, 0.0), (2569, 0.0), (2570, 0.0), (2571, 0.0), (2572, 0.0), (2573, 0.0), (2574, 0.0), (2576, 0.0), (2577, 0.0), (2578, 0.0), (2579, 0.0), (2580, 0.0), (2581, 0.0), (2582, 0.0), (2586, 0.0), (2588, 0.0), (2590, 0.0), (2592, 0.0), (2593, 0.0), (2596, 0.0), (2599, 0.0), (2600, 0.0), (2601, 0.0), (2605, 0.0), (2606, 0.0), (2607, 0.0), (2608, 0.0), (2609, 0.0), (2611, 0.0), (2614, 0.0), (2616, 0.0), (2619, 0.0), (2620, 0.0), (2621, 0.0), (2622, 0.0), (2624, 0.0), (2625, 0.0), (2629, 0.0), (2632, 0.0), (2633, 0.0), (2634, 0.0), (2635, 0.0), (2639, 0.0), (2640, 0.0), (2642, 0.0), (2645, 0.0), (2646, 0.0), (2648, 0.0), (2649, 0.0), (2650, 0.0), (2651, 0.0), (2652, 0.0), (2653, 0.0), (2655, 0.0), (2656, 0.0), (2657, 0.0), (2658, 0.0), (2659, 0.0), (2660, 0.0), (2661, 0.0), (2662, 0.0), (2663, 0.0), (2664, 0.0), (2665, 0.0), (2666, 0.0), (2668, 0.0), (2669, 0.0), (2671, 0.0), (2672, 0.0), (2673, 0.0), (2674, 0.0), (2675, 0.0), (2676, 0.0), (2677, 0.0), (2678, 0.0), (2679, 0.0), (2680, 0.0), (2681, 0.0), (2682, 0.0), (2684, 0.0), (2685, 0.0), (2686, 0.0), (2689, 0.0), (2690, 0.0), (2691, 0.0), (2692, 0.0), (2693, 0.0), (2695, 0.0), (2696, 0.0), (2697, 0.0), (2700, 0.0), (2702, 0.0), (2703, 0.0), (2704, 0.0), (2705, 0.0), (2706, 0.0), (2707, 0.0), (2708, 0.0), (2709, 0.0), (2710, 0.0), (2711, 0.0), (2714, 0.0), (2718, 0.0), (2719, 0.0), (2720, 0.0), (2721, 0.0), (2722, 0.0), (2724, 0.0), (2725, 0.0), (2728, 0.0), (2732, 0.0), (2733, 0.0), (2734, 0.0), (2735, 0.0), (2737, 0.0), (2738, 0.0), (2739, 0.0), (2740, 0.0), (2741, 0.0), (2742, 0.0), (2745, 0.0), (2746, 0.0), (2747, 0.0), (2748, 0.0), (2749, 0.0), (2750, 0.0), (2751, 0.0), (2752, 0.0), (2753, 0.0), (2754, 0.0), (2755, 0.0), (2756, 0.0), (2757, 0.0), (2758, 0.0), (2759, 0.0), (2761, 0.0), (2762, 0.0), (2763, 0.0), (2764, 0.0), (2765, 0.0), (2766, 0.0), (2767, 0.0), (2769, 0.0), (2770, 0.0), (2772, 0.0), (2774, 0.0), (2775, 0.0), (2776, 0.0), (2779, 0.0), (2780, 0.0), (2782, 0.0), (2783, 0.0), (2784, 0.0), (2785, 0.0), (2786, 0.0), (2787, 0.0), (2792, 0.0), (2793, 0.0), (2796, 0.0), (2797, 0.0), (2798, 0.0), (2799, 0.0), (2801, 0.0), (2802, 0.0), (2804, 0.0), (2805, 0.0), (2806, 0.0), (2808, 0.0), (2809, 0.0), (2812, 0.0), (2814, 0.0), (2815, 0.0), (2818, 0.0), (2819, 0.0), (2820, 0.0), (2822, 0.0), (2823, 0.0), (2824, 0.0), (2825, 0.0), (2829, 0.0), (2830, 0.0), (2831, 0.0), (2832, 0.0), (2837, 0.0), (2840, 0.0), (2841, 0.0), (2843, 0.0), (2844, 0.0), (2845, 0.0), (2847, 0.0), (2848, 0.0), (2849, 0.0), (2850, 0.0), (2851, 0.0), (2852, 0.0), (2853, 0.0), (2854, 0.0), (2855, 0.0), (2856, 0.0), (2858, 0.0), (2859, 0.0), (2860, 0.0), (2862, 0.0), (2865, 0.0), (2866, 0.0), (2867, 0.0), (2868, 0.0), (2869, 0.0), (2870, 0.0), (2872, 0.0), (2874, 0.0), (2876, 0.0), (2878, 0.0), (2879, 0.0), (2880, 0.0), (2881, 0.0), (2882, 0.0), (2883, 0.0), (2884, 0.0), (2885, 0.0), (2886, 0.0), (2887, 0.0), (2888, 0.0), (2889, 0.0), (2892, 0.0), (2893, 0.0), (2895, 0.0), (2896, 0.0), (2897, 0.0), (2898, 0.0), (2899, 0.0), (2900, 0.0), (2901, 0.0), (2902, 0.0), (2903, 0.0), (2904, 0.0), (2905, 0.0), (2906, 0.0), (2908, 0.0), (2909, 0.0), (2910, 0.0), (2912, 0.0), (2913, 0.0), (2915, 0.0), (2916, 0.0), (2917, 0.0), (2918, 0.0), (2919, 0.0), (2920, 0.0), (2921, 0.0), (2923, 0.0), (2925, 0.0), (2926, 0.0), (2927, 0.0), (2929, 0.0), (2930, 0.0), (2932, 0.0), (2934, 0.0), (2935, 0.0), (2937, 0.0), (2938, 0.0), (2939, 0.0), (2940, 0.0), (2941, 0.0), (2942, 0.0), (2947, 0.0), (2949, 0.0), (2950, 0.0), (2951, 0.0), (2952, 0.0), (2954, 0.0), (2956, 0.0), (2958, 0.0), (2959, 0.0), (2960, 0.0), (2961, 0.0), (2962, 0.0), (2964, 0.0), (2967, 0.0), (2968, 0.0), (2969, 0.0), (2970, 0.0), (2971, 0.0), (2973, 0.0), (2974, 0.0), (2976, 0.0), (2977, 0.0), (2978, 0.0), (2979, 0.0), (2980, 0.0), (2982, 0.0), (2985, 0.0), (2986, 0.0), (2987, 0.0), (2989, 0.0), (2990, 0.0), (2991, 0.0), (2992, 0.0), (2993, 0.0), (2994, 0.0), (2997, 0.0), (2999, 0.0), (3001, 0.0), (3002, 0.0), (3004, 0.0), (3007, 0.0), (3008, 0.0), (3009, 0.0), (3010, 0.0), (3011, 0.0), (3013, 0.0), (3014, 0.0), (3015, 0.0), (3017, 0.0), (3018, 0.0), (3020, 0.0), (3021, 0.0), (3023, 0.0), (3028, 0.0), (3031, 0.0), (3032, 0.0), (3033, 0.0), (3035, 0.0), (3036, 0.0), (3037, 0.0), (3038, 0.0), (3039, 0.0), (3041, 0.0), (3043, 0.0), (3045, 0.0), (3046, 0.0), (3049, 0.0), (3051, 0.0), (3053, 0.0), (3054, 0.0), (3055, 0.0), (3058, 0.0), (3059, 0.0), (3060, 0.0), (3064, 0.0), (3065, 0.0), (3067, 0.0), (3070, 0.0), (3072, 0.0), (3073, 0.0), (3075, 0.0), (3077, 0.0), (3079, 0.0), (3082, 0.0), (3083, 0.0), (3084, 0.0), (3087, 0.0), (3089, 0.0), (3090, 0.0), (3092, 0.0), (3093, 0.0), (3095, 0.0), (3096, 0.0), (3097, 0.0), (3098, 0.0), (3099, 0.0), (3101, 0.0), (3102, 0.0), (3104, 0.0), (3105, 0.0), (3106, 0.0), (3107, 0.0), (3108, 0.0), (3109, 0.0), (3112, 0.0), (3113, 0.0), (3116, 0.0), (3117, 0.0), (3121, 0.0), (3122, 0.0), (3123, 0.0), (3124, 0.0), (3125, 0.0), (3127, 0.0), (3128, 0.0), (3129, 0.0), (3130, 0.0), (3132, 0.0), (3133, 0.0), (3134, 0.0), (3136, 0.0), (3139, 0.0), (3140, 0.0), (3145, 0.0), (3146, 0.0), (3147, 0.0), (3148, 0.0), (3149, 0.0), (3150, 0.0), (3151, 0.0), (3152, 0.0), (3154, 0.0), (3155, 0.0), (3156, 0.0), (3157, 0.0), (3159, 0.0), (3161, 0.0), (3162, 0.0), (3163, 0.0), (3168, 0.0), (3169, 0.0), (3172, 0.0), (3174, 0.0), (3179, 0.0), (3181, 0.0), (3182, 0.0), (3183, 0.0), (3184, 0.0), (3185, 0.0), (3186, 0.0), (3187, 0.0), (3188, 0.0), (3189, 0.0), (3190, 0.0), (3191, 0.0), (3192, 0.0), (3193, 0.0), (3194, 0.0), (3195, 0.0), (3196, 0.0), (3197, 0.0), (3198, 0.0), (3199, 0.0), (3200, 0.0), (3201, 0.0), (3205, 0.0), (3206, 0.0), (3207, 0.0), (3209, 0.0), (3210, 0.0), (3211, 0.0), (3214, 0.0), (3215, 0.0), (3216, 0.0), (3218, 0.0), (3221, 0.0), (3222, 0.0), (3224, 0.0), (3225, 0.0), (3226, 0.0), (3228, 0.0), (3229, 0.0), (3230, 0.0), (3231, 0.0), (3234, 0.0), (3235, 0.0), (3236, 0.0), (3237, 0.0), (3240, 0.0), (3241, 0.0), (3242, 0.0), (3245, 0.0), (3246, 0.0), (3247, 0.0), (3248, 0.0), (3249, 0.0), (3250, 0.0), (3251, 0.0), (3253, 0.0), (3254, 0.0), (3256, 0.0), (3257, 0.0), (3258, 0.0), (3259, 0.0), (3261, 0.0), (3262, 0.0), (3263, 0.0), (3264, 0.0), (3265, 0.0), (3266, 0.0), (3269, 0.0), (3271, 0.0), (3273, 0.0), (3274, 0.0), (3277, 0.0), (3279, 0.0), (3281, 0.0), (3284, 0.0), (3286, 0.0), (3288, 0.0), (3289, 0.0), (3290, 0.0), (3292, 0.0), (3293, 0.0), (3294, 0.0), (3295, 0.0), (3296, 0.0), (3298, 0.0), (3300, 0.0), (3302, 0.0), (3303, 0.0), (3304, 0.0), (3305, 0.0), (3311, 0.0), (3314, 0.0), (3315, 0.0), (3316, 0.0), (3319, 0.0), (3320, 0.0), (3322, 0.0), (3324, 0.0), (3325, 0.0), (3327, 0.0), (3328, 0.0), (3329, 0.0), (3330, 0.0), (3331, 0.0), (3333, 0.0), (3334, 0.0), (3335, 0.0), (3336, 0.0), (3338, 0.0), (3339, 0.0), (3340, 0.0), (3341, 0.0), (3342, 0.0), (3343, 0.0), (3344, 0.0), (3345, 0.0), (3349, 0.0), (3350, 0.0), (3351, 0.0), (3352, 0.0), (3353, 0.0), (3354, 0.0), (3355, 0.0), (3356, 0.0), (3357, 0.0), (3360, 0.0), (3361, 0.0), (3363, 0.0), (3368, 0.0), (3370, 0.0), (3371, 0.0), (3372, 0.0), (3373, 0.0), (3375, 0.0), (3376, 0.0), (3378, 0.0), (3379, 0.0), (3380, 0.0), (3383, 0.0), (3384, 0.0), (3385, 0.0), (3386, 0.0), (3389, 0.0), (3391, 0.0), (3393, 0.0), (3395, 0.0), (3398, 0.0), (3400, 0.0), (3401, 0.0), (3403, 0.0), (3405, 0.0), (3407, 0.0), (3408, 0.0), (3409, 0.0), (3411, 0.0), (3413, 0.0), (3414, 0.0), (3415, 0.0), (3416, 0.0), (3417, 0.0), (3418, 0.0), (3419, 0.0), (3423, 0.0), (3424, 0.0), (3425, 0.0), (3426, 0.0), (3427, 0.0), (3428, 0.0), (3429, 0.0), (3431, 0.0), (3432, 0.0), (3434, 0.0), (3435, 0.0), (3436, 0.0), (3439, 0.0), (3440, 0.0), (3441, 0.0), (3442, 0.0), (3443, 0.0), (3444, 0.0), (3445, 0.0), (3447, 0.0), (3448, 0.0), (3449, 0.0), (3450, 0.0), (3451, 0.0), (3453, 0.0), (3456, 0.0), (3458, 0.0), (3460, 0.0), (3461, 0.0), (3464, 0.0), (3466, 0.0), (3467, 0.0), (3470, 0.0), (3471, 0.0), (3472, 0.0), (3473, 0.0), (3475, 0.0), (3477, 0.0), (3479, 0.0), (3480, 0.0), (3481, 0.0), (3482, 0.0), (3483, 0.0), (3484, 0.0), (3485, 0.0), (3486, 0.0), (3487, 0.0), (3488, 0.0), (3489, 0.0), (3490, 0.0), (3491, 0.0), (3493, 0.0), (3494, 0.0), (3495, 0.0), (3496, 0.0), (3500, 0.0), (3503, 0.0), (3506, 0.0), (3507, 0.0), (3508, 0.0), (3511, 0.0), (3512, 0.0), (3513, 0.0), (3514, 0.0), (3515, 0.0), (3516, 0.0), (3517, 0.0), (3518, 0.0), (3519, 0.0), (3520, 0.0), (3522, 0.0), (3523, 0.0), (3527, 0.0), (3528, 0.0), (3531, 0.0), (3534, 0.0), (3535, 0.0), (3536, 0.0), (3537, 0.0), (3539, 0.0), (3541, 0.0), (3543, 0.0), (3544, 0.0), (3545, 0.0), (3546, 0.0), (3548, 0.0), (3549, 0.0), (3550, 0.0), (3551, 0.0), (3553, 0.0), (3554, 0.0), (3555, 0.0), (3559, 0.0), (3561, 0.0), (3562, 0.0), (3564, 0.0), (3565, 0.0), (3567, 0.0), (3568, 0.0), (3569, 0.0), (3575, 0.0), (3577, 0.0), (3579, 0.0), (3580, 0.0), (3581, 0.0), (3582, 0.0), (3583, 0.0), (3585, 0.0), (3586, 0.0), (3587, 0.0), (3588, 0.0), (3589, 0.0), (3592, 0.0), (3593, 0.0), (3594, 0.0), (3595, 0.0), (3597, 0.0), (3599, 0.0), (3601, 0.0), (3602, 0.0), (3603, 0.0), (3605, 0.0), (3608, 0.0), (3609, 0.0), (3610, 0.0), (3611, 0.0), (3614, 0.0), (3616, 0.0), (3617, 0.0), (3618, 0.0), (3621, 0.0), (3623, 0.0), (3624, 0.0), (3625, 0.0), (3626, 0.0), (3630, 0.0), (3631, 0.0), (3632, 0.0), (3634, 0.0), (3636, 0.0), (3637, 0.0), (3638, 0.0), (3642, 0.0), (3643, 0.0), (3646, 0.0), (3649, 0.0), (3651, 0.0), (3653, 0.0), (3657, 0.0), (3661, 0.0), (3663, 0.0), (3664, 0.0), (3665, 0.0), (3666, 0.0), (3667, 0.0), (3668, 0.0), (3669, 0.0), (3670, 0.0), (3671, 0.0), (3674, 0.0), (3676, 0.0), (3678, 0.0), (3680, 0.0), (3681, 0.0), (3682, 0.0), (3683, 0.0), (3684, 0.0), (3685, 0.0), (3686, 0.0), (3687, 0.0), (3688, 0.0), (3689, 0.0), (3691, 0.0), (3692, 0.0), (3693, 0.0), (3694, 0.0), (3698, 0.0), (3701, 0.0), (3703, 0.0), (3704, 0.0), (3705, 0.0), (3706, 0.0), (3709, 0.0), (3711, 0.0), (3712, 0.0), (3713, 0.0), (3714, 0.0), (3718, 0.0), (3719, 0.0), (3722, 0.0), (3724, 0.0), (3725, 0.0), (3729, 0.0), (3731, 0.0), (3732, 0.0), (3733, 0.0), (3734, 0.0), (3736, 0.0), (3737, 0.0), (3738, 0.0), (3740, 0.0), (3741, 0.0), (3742, 0.0), (3743, 0.0), (3744, 0.0), (3746, 0.0), (3747, 0.0), (3748, 0.0), (3749, 0.0), (3750, 0.0), (3753, 0.0), (3754, 0.0), (3755, 0.0), (3757, 0.0), (3758, 0.0), (3759, 0.0), (3761, 0.0), (3763, 0.0), (3766, 0.0), (3767, 0.0), (3768, 0.0), (3769, 0.0), (3770, 0.0), (3771, 0.0), (3772, 0.0), (3773, 0.0), (3774, 0.0), (3775, 0.0), (3776, 0.0), (3777, 0.0), (3778, 0.0), (3780, 0.0), (3781, 0.0), (3784, 0.0), (3785, 0.0), (3786, 0.0), (3788, 0.0), (3790, 0.0), (3791, 0.0), (3792, 0.0), (3793, 0.0), (3794, 0.0), (3796, 0.0), (3797, 0.0), (3798, 0.0), (3799, 0.0), (3800, 0.0), (3802, 0.0), (3803, 0.0), (3804, 0.0), (3805, 0.0), (3806, 0.0), (3807, 0.0), (3810, 0.0), (3812, 0.0), (3813, 0.0), (3816, 0.0), (3818, 0.0), (3820, 0.0), (3822, 0.0), (3823, 0.0), (3825, 0.0), (3826, 0.0), (3827, 0.0), (3828, 0.0), (3829, 0.0), (3830, 0.0), (3832, 0.0), (3833, 0.0), (3837, 0.0), (3841, 0.0), (3842, 0.0), (3843, 0.0), (3845, 0.0), (3846, 0.0), (3847, 0.0), (3848, 0.0), (3849, 0.0), (3850, 0.0), (3852, 0.0), (3853, 0.0), (3854, 0.0), (3857, 0.0), (3858, 0.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we print the top-10"
      ],
      "metadata": {
        "id": "YT6qxYoCJxi1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NB the first movie is Star Wars itself\n",
        "# Exclude it and select the top 10 similar movies\n",
        "top_k_similar = similarity_scores[1:11]\n",
        "\n",
        "# Convert indices back to movie names\n",
        "top_k_similar_ids = [(tfidf_features.index[i], score) for i, score in top_k_similar]\n",
        "\n",
        "# Output the results\n",
        "print(f\"Top 10 similar movies to {metadata[metadata['movie_id']==item_id]['name'].values[0]}:\")\n",
        "for movie_id, score in top_k_similar_ids:\n",
        "    print(f\"Title: {metadata[metadata['movie_id']==movie_id]['name'].values[0]}, Similarity Score: {score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3qiTAUW_uYO",
        "outputId": "a555388e-ee49-40bd-fd45-dd52922bebda"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 similar movies to Star Wars: Episode IV - A New Hope (1977):\n",
            "Title: Star Wars: Episode VI - Return of the Jedi (1983), Similarity Score: 0.4726571038951565\n",
            "Title: Star Wars: Episode V - The Empire Strikes Back (1980), Similarity Score: 0.4335392852988003\n",
            "Title: First Kid (1996), Similarity Score: 0.12776183015002765\n",
            "Title: Topsy-Turvy (1999), Similarity Score: 0.10763980156127986\n",
            "Title: Shanghai Noon (2000), Similarity Score: 0.10130248189765484\n",
            "Title: Black Sunday (La Maschera Del Demonio) (1960), Similarity Score: 0.0952227515187248\n",
            "Title: Sleeping Beauty (1959), Similarity Score: 0.08853496379109525\n",
            "Title: Star Trek V: The Final Frontier (1989), Similarity Score: 0.08412621888340621\n",
            "Title: Princess Caraboo (1994), Similarity Score: 0.08321747918144712\n",
            "Title: Coming Home (1978), Similarity Score: 0.0814412634666697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classifier as Content-based RecSys"
      ],
      "metadata": {
        "id": "vwJvKRU7J1cE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation\n",
        "\n",
        "Here we extract and prepare the movie embeddings for the movies that the user has liked and disliked, based on their TF-IDF representations.\n",
        "\n",
        "1. **Converting the Sparse Matrix to Dense**:\n",
        "   - **`movie_embs`**: The sparse `tfidf_matrix` is converted into a dense array using the `toarray()` method. This results in a full matrix where each row represents a movie's TF-IDF embedding, making it easier to process the embeddings for further analysis.\n",
        "\n",
        "2. **Extracting Embeddings for Liked Movies**:\n",
        "   - **`likes`**: The movie IDs of the movies that user 1 has liked (where the `bin_rat` is 1) are extracted from the `df` DataFrame.\n",
        "   - **`like_indices`**: The indices of these movies in the `tfidf_features` DataFrame are found using the `get_loc()` method for each movie ID in the `likes` list.\n",
        "   - **`like_embeddings`**: The embeddings corresponding to the liked movies are extracted from the `movie_embs` dense matrix using the `like_indices`. This results in an array of TF-IDF embeddings for the liked movies.\n",
        "\n",
        "3. **Extracting Embeddings for Disliked Movies**:\n",
        "   - **`dislikes`**: Similarly, the movie IDs of the movies that user 1 has disliked (where the `bin_rat` is 0) are extracted from the `df` DataFrame.\n",
        "   - **`dislike_indices`**: The indices of the disliked movies are found using the `get_loc()` method, just like with the liked movies.\n",
        "   - **`dislike_embeddings`**: The embeddings for the disliked movies are extracted from the `movie_embs` matrix using the `dislike_indices`.\n",
        "\n",
        "4. **Printing the Shapes**:\n",
        "   - The shapes of the `like_embeddings` and `dislike_embeddings` arrays are printed to confirm how many movies were liked and disliked by user 1, and how many embeddings were retrieved for each.\n",
        "\n"
      ],
      "metadata": {
        "id": "OrvpFG3eNOYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sparse to dense tfidf_matrix\n",
        "movie_embs = tfidf_matrix.toarray()\n",
        "\n",
        "# let's gather user 1 like embeddings\n",
        "likes = df[(df['user_id'] == user_id) & (df['bin_rat'] == 1)]['movie_id']\n",
        "like_indices = [tfidf_features.index.get_loc(movie_id) for movie_id in likes]\n",
        "like_embeddings = movie_embs[like_indices]\n",
        "\n",
        "print(like_embeddings.shape)\n",
        "\n",
        "# let's gather user 1 dislike embeddings\n",
        "dislikes = df[(df['user_id'] == user_id) & (df['bin_rat'] == 0)]['movie_id']\n",
        "dislike_indices = [tfidf_features.index.get_loc(movie_id) for movie_id in dislikes]\n",
        "dislike_embeddings = movie_embs[dislike_indices]\n",
        "\n",
        "print(dislike_embeddings.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiA4h57nDtWL",
        "outputId": "33904a68-80d2-4e53-cc12-d01cd370ff72"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(134, 24526)\n",
            "(165, 24526)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "like_embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3kijIbHH8Hh",
        "outputId": "b70c8420-3085-47e5-933d-404fc92c90bf"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format the input\n",
        "\n",
        "Here we prepare the input features and labels for training a machine learning model (likely a classifier) to predict whether a user would like or dislike a movie based on the movie embeddings.\n",
        "\n",
        "1. **Combining the Embeddings**:\n",
        "   - **`X`**: The embeddings for the movies that the user liked and disliked are combined into a single array. Each movie's embedding is represented as a numpy array, and the liked movies' embeddings (`like_embeddings`) are combined with the disliked movies' embeddings (`dislike_embeddings`). The resulting `X` is a 2D array where each row corresponds to a movie's TF-IDF embedding.\n",
        "\n",
        "2. **Creating the Labels**:\n",
        "   - **`y`**: A label array is created where movies that the user liked are labeled as 1 (positive class), and movies that the user disliked are labeled as 0 (negative class). The labels are created by concatenating a list of 1s (for likes) and a list of 0s (for dislikes), with the length of each list matching the number of liked and disliked movies.\n",
        "\n",
        "3. **Printing the Shapes**:\n",
        "   - The shapes of the `X` (input features) and `y` (labels) arrays are printed to confirm the dimensions. `X` should have a shape of `(number of liked + disliked movies, number of features)` and `y` should have a shape of `(number of movies,)`.\n"
      ],
      "metadata": {
        "id": "3aYUnzB9NrpK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the input features: user like (positive class), user dislike (negative class)\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "\n",
        "# Combine embeddings\n",
        "X = np.array([np.array(emb) for emb in like_embeddings] + [np.array(emb) for emb in dislike_embeddings])\n",
        "# create labels (positive and negative)\n",
        "y = np.array(([1]) * len(likes) + ([0]) * len(dislikes))\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bulnHPP0D2ta",
        "outputId": "b6c1ec73-1b77-49a2-8190-e13c73481d06"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(299, 24526)\n",
            "(299,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us use the KNN Classifier"
      ],
      "metadata": {
        "id": "ZvFvEw3sxn2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Classifier\n",
        "\n",
        "At this step, we user the **K-Nearest Neighbors (KNN)** algorithm for a recommendation task, using it to classify whether a user is likely to like or dislike a movie based on movie embeddings.\n",
        "\n",
        "1. **K-Nearest Neighbors Classifier (KNN)**:\n",
        "   - The **KNeighborsClassifier** is a supervised machine learning algorithm that makes predictions based on the similarity between data points. It works by finding the **k** nearest neighbors to a given data point in the feature space and classifying the data point based on the majority class among those neighbors.\n",
        "   \n",
        "   - In our context:\n",
        "     - Each movie is represented by a feature vector (its TF-IDF embedding).\n",
        "     - The classifier learns from the embeddings of movies the user has liked (positive class) and disliked (negative class).\n",
        "     - For a new or unseen movie, the classifier uses the movie's embedding and compares it to the embeddings of the movies the user has already interacted with. The prediction is made based on the majority label (like or dislike) among the **k** nearest movies.\n",
        "\n",
        "2. **How we use the KNN Classifier**:\n",
        "   - **`cb_knn = KNeighborsClassifier(n_neighbors=20)`**: This line initializes the KNN classifier with 20 nearest neighbors (`n_neighbors=20`). This means the algorithm will consider the 20 most similar movies to classify the movie as either a like (1) or dislike (0).\n",
        "   \n",
        "   - **`cb_knn.fit(X, y)`**: The `fit()` method trains the KNN classifier using the movie embeddings (`X`) as input features and the userâ€™s ratings (likes and dislikes) as the labels (`y`). This allows the model to learn the relationship between movie embeddings and user preferences.\n",
        "\n",
        "### KNN in the Recommendation Task\n",
        "\n",
        "- **Task Objective**: The goal is to predict whether the user would like or dislike a given movie based on its features (i.e., its embedding).\n",
        "- **KNN's Role**: KNN is particularly well-suited for this task because it makes predictions based on the proximity (similarity) of movies in the feature space (defined by the TF-IDF embeddings).\n",
        "   - For example, after training, when given a new movie's embedding, KNN will find the 20 most similar movies in the feature space (based on cosine similarity or other distance metrics) and predict whether the user is likely to like or dislike the movie by taking a majority vote from the labels of those similar movies.\n"
      ],
      "metadata": {
        "id": "cEBYEUKpO2Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "cb_knn = KNeighborsClassifier(n_neighbors=20)\n",
        "cb_knn.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "eEXSmgTXxqs3",
        "outputId": "8a66d3f9-1d08-4832-cd8b-f2f07fc58c03"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=20)"
            ],
            "text/html": [
              "<style>#sk-container-id-23 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-23 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-23 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-23 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-23 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-23 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-23 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-23 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-23 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-23 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-23 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-23 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-23 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-23 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-23 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" checked><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KNeighborsClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KNeighborsClassifier(n_neighbors=20)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Recommendations for Unobserved Movies\n",
        "\n",
        "Once the recommendation model (the classifier) is trained, we now have to provide the recommendation list to the user; to do so, we predict the score of all the movies in our catalog, find the top-n, and provide them as suggestions.\n",
        "\n",
        "To do so, we need to:\n",
        "\n",
        "1. **Identify Unobserved Movies**:\n",
        "   - **`all_movie_ids`**: A set containing all unique movie IDs present in the `tfidf_features` index (i.e., all movies in the dataset).\n",
        "   - **`observed_movie_ids`**: A set of movie IDs that the user has rated, which includes both liked (`likes`) and disliked (`dislikes`) movies.\n",
        "   - **`unobserved_movie_ids`**: The difference between all movie IDs and the observed movie IDs, representing the movies that the user has not rated yet.\n",
        "\n",
        "2. **Get the indices for Unobserved Movies**:\n",
        "   - **`unobserved_indices`**: The indices of the unobserved movies are retrieved using the `get_loc()` method from `tfidf_features.index`. These indices correspond to the positions of the unobserved movies in the TF-IDF feature matrix.\n",
        "\n",
        "3. **Extract the Embeddings for Unobserved Movies**:\n",
        "   - **`unobserved_embeddings`**: The embeddings for the unobserved movies are extracted from the `movie_embs` dense matrix using the indices of the unobserved movies.\n",
        "\n",
        "4. **Predict the Scores**:\n",
        "   - **`scores`**: The `predict_proba()` method of the trained KNN classifier (`cb_knn`) is used to predict the probability of each unobserved movie being liked or disliked by the user. This returns a probability distribution for each unobserved movie across the two classes (like or dislike).\n",
        "\n"
      ],
      "metadata": {
        "id": "4WyYW27VSPIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify unobserved movies\n",
        "# they are movies that have never been rated by users\n",
        "all_movie_ids = set(tfidf_features.index)\n",
        "observed_movie_ids = set(likes + dislikes)\n",
        "unobserved_movie_ids = all_movie_ids - observed_movie_ids\n",
        "\n",
        "# Get indices for unobserved movies\n",
        "unobserved_indices = [tfidf_features.index.get_loc(movie_id) for movie_id in unobserved_movie_ids]\n",
        "\n",
        "# Get the embeddings\n",
        "unobserved_embeddings = movie_embs[unobserved_indices]  # Convert to dense array\n",
        "\n",
        "print('I\\'m generating the recommendations...')\n",
        "\n",
        "# Predict scores for unobserved movies using our content based recsys\n",
        "scores = cb_knn.predict_proba(unobserved_embeddings)\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjxCDA0Zx3Zc",
        "outputId": "d9ba4dff-e61e-465b-9e1d-3dd66be873f1"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm generating the recommendations...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check what is inside the variable scores"
      ],
      "metadata": {
        "id": "CGjkoR3RSupL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGLTT--dyU8X",
        "outputId": "486d968d-9228-45a9-c4c0-1b8739dc6015"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.65, 0.35],\n",
              "       [0.6 , 0.4 ],\n",
              "       [0.9 , 0.1 ],\n",
              "       ...,\n",
              "       [0.65, 0.35],\n",
              "       [0.55, 0.45],\n",
              "       [0.5 , 0.5 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And let's check the shpe"
      ],
      "metadata": {
        "id": "67DqUs61Sy42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TX8yyUQByaff",
        "outputId": "71ff4bea-6d7e-4ff3-c47e-c0901b0d0318"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3859, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating Top Movie Recommendations\n",
        "\n",
        "Finally, we get the top-10 of suggested movies.\n",
        "\n",
        "1. **Extracting the Probability of \"Like\"**:\n",
        "   - **`like_scores`**: The `scores` array returned by `predict_proba()` contains the predicted probabilities for both the \"like\" (positive) and \"dislike\" (negative) classes. The second column of the `scores` array corresponds to the probability that the user will \"like\" a movie. These probabilities are extracted by selecting all rows and the second column (`scores[:, 1]`).\n",
        "\n",
        "2. **Creating Movie Scores List**:\n",
        "   - **`movie_scores`**: A list of tuples is created, where each tuple contains a movie ID from the set of unobserved movies and its corresponding \"like\" score. This list pairs each movie with the likelihood that the user will like it.\n",
        "\n",
        "3. **Sorting the Movies by \"Like\" Scores**:\n",
        "   - **`sorted_movie_scores`**: The `movie_scores` list is sorted in descending order based on the \"like\" scores. This allows us to prioritize movies that the model predicts the user is most likely to enjoy.\n",
        "\n",
        "4. **Displaying the Top 10 Recommendations**:\n",
        "   - The top 10 movies are printed out by iterating through the sorted list. For each of the top 10 recommended movies:\n",
        "     - The movie name is retrieved from the `metadata` DataFrame using the `movie_id`.\n",
        "     - The movie name and its corresponding \"like\" score are displayed in a user-friendly format.\n"
      ],
      "metadata": {
        "id": "64Nv_3yiS8Yp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the probability of \"like\" from scores (second column)\n",
        "like_scores = scores[:, 1]\n",
        "\n",
        "# Create a list of movie IDs and their \"like\" scores\n",
        "movie_scores = list(zip(unobserved_movie_ids, like_scores))\n",
        "\n",
        "# Sort by \"like\" scores in descending order\n",
        "sorted_movie_scores = sorted(movie_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the top 10 recommendations\n",
        "print(f\"For user {user_id} we suggest...\")\n",
        "for i, (movie_id, score) in enumerate(sorted_movie_scores[0:10]):\n",
        "    movie_name = metadata[metadata['movie_id'] == movie_id]['name'].values[0]\n",
        "    print(f\"{i+1}): {movie_name}, Score: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1V3DzA7PvZz",
        "outputId": "a92691dc-0e89-4b0c-b14f-2d226eef0581"
      },
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For user 4593 we suggest...\n",
            "1): Running Man, The (1987), Score: 0.9000\n",
            "2): Death and the Maiden (1994), Score: 0.8000\n",
            "3): Central Station (Central do Brasil) (1998), Score: 0.8000\n",
            "4): King of the Hill (1993), Score: 0.7500\n",
            "5): Children of the Revolution (1996), Score: 0.7500\n",
            "6): Antz (1998), Score: 0.7500\n",
            "7): Battle of the Sexes, The (1959), Score: 0.7500\n",
            "8): Titus (1999), Score: 0.7500\n",
            "9): Anne Frank Remembered (1995), Score: 0.7000\n",
            "10): White Man's Burden (1995), Score: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible excercise: change the number of neighbors and check how the recommendation lists changens, both in terms of suggested movies and recommendation scores"
      ],
      "metadata": {
        "id": "3dxXGeom9_kw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now, let us use the Naive Bayesian Classifier"
      ],
      "metadata": {
        "id": "KFhUPW_c-K5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes Classifier\n",
        "\n",
        "Now, we train a **Naive Bayes classifier** to predict whether a user will like or dislike a movie based on the movie's TF-IDF embeddings.\n",
        "\n",
        "1. **Naive Bayes Classifier**:\n",
        "   - **Multinomial Naive Bayes (MultinomialNB)** is a probabilistic classifier that is particularly useful for classification tasks where the features are discrete or represent counts (like word counts in text classification). It is based on applying Bayes' Theorem with strong (naive) independence assumptions between the features.\n",
        "   \n",
        "   - **How it works**:\n",
        "     - It calculates the probability of each class (like or dislike) given the features (movie embeddings), assuming that each feature is conditionally independent given the class.\n",
        "     - The algorithm then predicts the class that maximizes the probability of the given features.\n",
        "     - In this case, the classifier is trained to predict whether a user will like (`1`) or dislike (`0`) a movie based on the TF-IDF embedding of the movie.\n",
        "\n",
        "2. **How the Naive Bayes Classifier is Used in our context**:\n",
        "   - **`clf = MultinomialNB()`**: This line initializes the **Multinomial Naive Bayes** classifier.\n",
        "   - **`clf.fit(X, y)`**: The `fit()` method is used to train the Naive Bayes classifier using the input features (`X`), which are the TF-IDF embeddings of the movies, and the labels (`y`), which indicate whether the user liked or disliked the movie. The classifier learns the relationship between the movie embeddings and the user's preferences.\n"
      ],
      "metadata": {
        "id": "Rlf1Q6c5ULLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "cb_nb = MultinomialNB()\n",
        "cb_nb.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "yzdJG8Dn_l0F",
        "outputId": "a953d161-4e59-4139-d5c6-1b3923730895"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-25 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-25 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-25 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-25 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-25 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"â–¸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-25 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"â–¾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-25 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-25 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-25 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-25 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-25 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-25 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-25 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-25 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-25 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-25 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-25 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-25 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-25\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before, we compute the recommendation scores for the unobserved movies"
      ],
      "metadata": {
        "id": "K_xo0wajU-9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify unobserved movies\n",
        "# they are movies that have never been rated by users\n",
        "all_movie_ids = set(tfidf_features.index)\n",
        "observed_movie_ids = set(likes + dislikes)\n",
        "unobserved_movie_ids = all_movie_ids - observed_movie_ids\n",
        "\n",
        "# Get indices for unobserved movies\n",
        "unobserved_indices = [tfidf_features.index.get_loc(movie_id) for movie_id in unobserved_movie_ids]\n",
        "\n",
        "# Get the embeddings\n",
        "unobserved_embeddings = movie_embs[unobserved_indices]  # Convert to dense array\n",
        "\n",
        "print('I\\'m generating the recommendations...')\n",
        "\n",
        "# Predict scores for unobserved movies using our content based recsys\n",
        "scores = cb_nb.predict_proba(unobserved_embeddings)\n",
        "\n",
        "print('Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGyx5Oat_nGW",
        "outputId": "912012ce-7176-4fb9-d098-909cdfdddd2a"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm generating the recommendations...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5laDAEq_tPP",
        "outputId": "52e8e557-7d51-4e32-a149-381a99a2b198"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63438702, 0.36561298],\n",
              "       [0.60722228, 0.39277772],\n",
              "       [0.68614468, 0.31385532],\n",
              "       ...,\n",
              "       [0.61397919, 0.38602081],\n",
              "       [0.58245863, 0.41754137],\n",
              "       [0.34123119, 0.65876881]])"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And find the top-10 of recommendations"
      ],
      "metadata": {
        "id": "dXWaFriYVEKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the probability of \"like\" from scores (second column)\n",
        "like_scores = scores[:, 1]\n",
        "\n",
        "# Create a list of movie IDs and their \"like\" scores\n",
        "movie_scores = list(zip(unobserved_movie_ids, like_scores))\n",
        "\n",
        "# Sort by \"like\" scores in descending order\n",
        "sorted_movie_scores = sorted(movie_scores, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Print the top 10 recommendations\n",
        "print(f\"For user {user_id} we suggest...\")\n",
        "for i, (movie_id, score) in enumerate(sorted_movie_scores[0:10]):\n",
        "    movie_name = metadata[metadata['movie_id'] == movie_id]['name'].values[0]\n",
        "    print(f\"{i+1}): {movie_name}, Score: {score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7eSp-Kb_wf7",
        "outputId": "16d0ea4b-21b1-485e-942d-f0fb6f262d91"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For user 4593 we suggest...\n",
            "1): Winslow Boy, The (1998), Score: 0.7031\n",
            "2): Sunshine (1999), Score: 0.6983\n",
            "3): Wilde (1997), Score: 0.6948\n",
            "4): Oscar and Lucinda (a.k.a. Oscar & Lucinda) (1997), Score: 0.6923\n",
            "5): Ideal Husband, An (1999), Score: 0.6906\n",
            "6): Kolya (1996), Score: 0.6873\n",
            "7): Color of Paradise, The (Rang-e Khoda) (1999), Score: 0.6854\n",
            "8): Breaker Morant (1980), Score: 0.6758\n",
            "9): Sense and Sensibility (1995), Score: 0.6745\n",
            "10): Mansfield Park (1999), Score: 0.6740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q56c_m_uEdf1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}